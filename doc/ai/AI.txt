https://github.com/THUDM/ChatGLM-6B


https://modelscope.cn/




python

>>> from transformers import AutoTokenizer, AutoModel
>>> tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
>>> model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½ï¼Œæˆ‘å«å¤§å†›æ™¨èµ›ï¼Œå«çˆ¸çˆ¸", history=[])
>>> print(response)
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
>>> response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
>>> print(response)


  

ä¸¤å°æ—¶æ­å»ºå±äºè‡ªå·±çš„AI(ChatGLM)



å‡†å¤‡ï¼ˆæ³¨å†Œï¼‰:

https://modelscope.cn/

å¯ä»¥ç™½å«–60å¤šä¸ªå°æ—¶çš„é…ç½®

8æ ¸ 32GB æ˜¾å­˜16G
é¢„è£… ModelScope Library
é¢„è£…é•œåƒ ubuntu20.04-cuda11.3.0-py37-torch1.11.0-tf1.15.5-1.5.0





æ­å»º:

https://github.com/THUDM/ChatGLM-6B



>>> from transformers import AutoTokenizer, AutoModel
>>> tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
>>> model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
>>> print(response)

å¼‚å¸¸1:
pip install cpm_kernels

tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)ï¼š



APIæ¨¡å¼:
pwd 
/mnt/workspace

git clone https://github.com/THUDM/ChatGLM-6B


pip install fastapi uvicorn

cd /mnt/workspace/ChatGLM-6B

python api.py

curl -X POST "http://127.0.0.1:8000" -H 'Content-Type: application/json' -d '{"prompt": "ä½ æ˜¯è°", "history": []}'
curl -X POST "http://127.0.0.1:8000" -H 'Content-Type: application/json' -d '{"prompt": "èµ›èµ›æ˜¯è°", "history": []}'
curl -X POST "http://127.0.0.1:8000" -H 'Content-Type: application/json' -d '{"prompt": "æ™¨æ™¨æ˜¯è°", "history": []}'


response, history = model.chat(tokenizer, "ä½ å¥½ç»™æˆ‘å†™æœ¬ä¹¦", history=[])


echo "evaluate" | sudo dd of=/mnt/workspace/ChatGLM-6B/ptuning/evaluate.sh



I.å¾®è°ƒ
cd /mnt/workspace/ChatGLM-6B/ptuning


II.å‡†å¤‡è®­ç»ƒçš„æ•°æ®:ä¸‹è½½åœ°å€ä¼šå˜
ä» Google Drive æˆ–è€… Tsinghua Cloud ä¸‹è½½å¤„ç†å¥½çš„ ADGEN æ•°æ®é›†ï¼Œå°†è§£å‹åçš„ AdvertiseGen ç›®å½•æ”¾åˆ°æœ¬ç›®å½•ä¸‹ã€‚
https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md
https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1


 
curl   -O https://cloud.tsinghua.edu.cn/seafhttp/files/8e027752-3322-43d7-9e22-13c9a78a233e/AdvertiseGen.tar.gz

tar -zxvf AdvertiseGen.tar.gz

cd /mnt/workspace/
ä¸Šä¼ è‡ªå·±çš„è®­ç»ƒæ•°æ®

cp   /mnt/workspace/dev.json /mnt/workspace/ChatGLM-6B/ptuning/AdvertiseGen/dev.json
cp   /mnt/workspace/train.json /mnt/workspace/ChatGLM-6B/ptuning/AdvertiseGen/train.json
dev.json  train.json

å®‰è£…ä¾èµ–:
pip install rouge_chinese nltk jieba datasets



cd /mnt/workspace/ChatGLM-6B/ptuning
bash train.sh

å¼‚å¸¸2ï¼š

root@eais-bjtryzm9xivr28qvprxr-7c8cfdfd44-2j4rx:/mnt/workspace/ChatGLM-6B/ptuning# bash train.sh
Traceback (most recent call last):
  File "main.py", line 29, in <module>
    from rouge_chinese import Rouge
ModuleNotFoundError: No module named 'rouge_chinese'

 å®‰è£…ä¾èµ–è§£å†³ ï¼š pip install rouge_chinese nltk jieba datasets

å¼‚å¸¸3: 
 RuntimeError: CUDA Error: no kernel image is available for execution on the device
â€œè°ƒæ•´ quantization_bit æ¥è¢«åŸå§‹æ¨¡å‹çš„é‡åŒ–ç­‰çº§ï¼Œä¸åŠ æ­¤é€‰é¡¹åˆ™ä¸º FP16 ç²¾åº¦åŠ è½½â€

bash train.sh
cp   train.sh train_bak.sh

vi train.sh
åˆ é™¤   --quantization_bit 4










PRE_SEQ_LEN  : soft prompt é•¿åº¦
LR :å­¦ä¹ ç‡
quantization_bit 
THUDM/chatglm-6b

------------------------------


PRE_SEQ_LEN=128
LR=2e-2

CUDA_VISIBLE_DEVICES=0 python3 main.py \
    --do_train \
    --train_file AdvertiseGen/train.json \
    --validation_file AdvertiseGen/dev.json \
    --prompt_column content \
    --response_column summary \
    --overwrite_cache \
    --model_name_or_path THUDM/chatglm-6b \
    --output_dir output/adgen-chatglm-6b-pt-$PRE_SEQ_LEN-$LR \
    --overwrite_output_dir \
    --max_source_length 64 \
    --max_target_length 64 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --predict_with_generate \
    --max_steps 3000 \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate $LR \
    --pre_seq_len $PRE_SEQ_LEN \
    --quantization_bit 4

---------------------------------------

GPUä½¿ç”¨

watch -n 0.5 nvidia-smi




bash train.sh
cp   train.sh train_bak.sh

vi train.sh
åˆ é™¤   --quantization_bit 4


çº¦ç­‰äº30åˆ†é’Ÿä¸€æ¡è®°å½•ï¼š


300 8
120 5

æ˜¾å¡GPUé…ç½® Tesla P100ï¼š16G
Every 0.5s: nvidia-smi                                                                                                                                    eais-bjtryzm9xivr28qvprxr-7c8cfdfd44-2j4rx: Mon May 15 12:05:33 2023

Mon May 15 12:05:33 2023
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  On   | 00000000:00:08.0 Off |                  Off |
| N/A   51C    P0   140W / 250W |  13843MiB / 16280MiB |     96%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+

 


cp   evaluate.sh evaluate_bak.sh

vi evaluate.sh 

åˆ é™¤      --quantization_bit 4



PRE_SEQ_LEN=128
CHECKPOINT=adgen-chatglm-6b-pt-128-2e-2
STEP=3000

CUDA_VISIBLE_DEVICES=0 python3 main.py \
    --do_predict \
    --validation_file AdvertiseGen/dev.json \
    --test_file AdvertiseGen/dev.json \
    --overwrite_cache \
    --prompt_column content \
    --response_column summary \
    --model_name_or_path THUDM/chatglm-6b \
    --ptuning_checkpoint ./output/$CHECKPOINT/checkpoint-$STEP \
    --output_dir ./output/$CHECKPOINT \
    --overwrite_output_dir \
    --max_source_length 64 \
    --max_target_length 64 \
    --per_device_eval_batch_size 1 \
    --predict_with_generate \
    --pre_seq_len $PRE_SEQ_LEN \
    --quantization_bit 4


--model_name_or_path THUDM/chatglm-6b
--ptuning_checkpoint $CHECKPOINT_PATH

/mnt/workspace/ChatGLM-6B/ptuning

bash evaluate.sh


cp   api.py api_bak.py
tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)


tokenizer = AutoTokenizer.from_pretrained("/mnt/workspace/ChatGLM-6B", trust_remote_code=True)


config = AutoConfig.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True, pre_seq_len=128)
model = AutoModel.from_pretrained("THUDM/chatglm-6b", config=config, trust_remote_code=True)
prefix_state_dict = torch.load(os.path.join(CHECKPOINT_PATH, "pytorch_model.bin"))
new_prefix_state_dict = {}
for k, v in prefix_state_dict.items():
    if k.startswith("transformer.prefix_encoder."):
        new_prefix_state_dict[k[len("transformer.prefix_encoder."):]] = v
model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)


model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)

æ­¤å¤„éœ€è¦ä¿®æ”¹

model = model.quantize(128)
model = model.half().cuda()
model.transformer.prefix_encoder.float()
model = model.eval()

response, history = model.chat(tokenizer, "ä½ æ˜¯è°", history=[])

print(response)


cp   web_demo.py web_demo_bak.py

/root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b



du -h â€“max-depth=1 *



I.

https://github.com/xusenlinzy/api-for-open-llm





curl "http://localhost/console/api/installed-apps/1014949b-123d-4b43-9aee-030a46f67308/chat-messages" ^





curl "http://localhost/console/api/installed-apps/1014949b-123d-4b43-9aee-030a46f67308/chat-messages" ^





prompt =f"å·²çŸ¥ä¿¡æ¯:\nå®œä¿¡æ™¨æ™¨æœ€å¸…\næ ¹æ®å·²çŸ¥ä¿¡æ¯å›ç­”é—®é¢˜:\nå®œä¿¡è°æœ€å¸…"


prompt =f"å·²çŸ¥ä¿¡æ¯:\nå®œä¿¡äº§å“æœ‰ï¼Œç±»å›ºæ”¶ã€åŸºé‡‘ã€ä¿é™©ç­‰\næ ¹æ®å·²çŸ¥ä¿¡æ¯å›ç­”é—®é¢˜:\nå®œä¿¡äº§å“éƒ½æœ‰ä»€ä¹ˆ"


response, history = model.chat(tokenizer, prompt, history=[])



>>> from transformers import AutoTokenizer, AutoModel
>>> tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
>>> model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
>>> print(response)
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
>>> response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
>>> print(response)
æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:
 
1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚
2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚
3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚
4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚
5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚
6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚
 
å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚







ä¿®æ”¹è„šæœ¬web_demo.py
#model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().cuda()
model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True).half().quantize(8).cuda()


I.GPTçš„å…¨ç§°ï¼Œ
æ˜¯Generativeç”Ÿæˆå¼ Pre-Trainedé¢„è®­ç»ƒ Transformerè½¬æ¢å™¨ï¼ˆç”Ÿæˆå¼é¢„è®­ç»ƒè½¬æ¢å™¨ Transformeræ¨¡å‹ï¼‰

æ˜¯ä¸€ç§åŸºäºäº’è”ç½‘çš„ã€å¯ç”¨æ•°æ®æ¥è®­ç»ƒçš„ã€æ–‡æœ¬ç”Ÿæˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹


GPT-3 175Bæ¨¡å‹
billionçš„ç¼©å†™,1B=10äº¿


1750äº¿å‚æ•°


II.å‘é‡ï¼ˆæœ‰å¤§å°æœ‰æ–¹å‘ï¼‰


1.æ ‡é‡ (Scalar)æ ‡é‡æ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å€¼ï¼Œå®ƒè¡¨ç¤ºæŸç§é‡çš„å¤§å°ã€‚å®ƒæ²¡æœ‰æ–¹å‘ï¼Œåªæœ‰å¤§å°ã€‚
ä¾‹å¦‚ï¼Œæ¸©åº¦ã€è´¨é‡å’Œè·ç¦»éƒ½å¯ä»¥ç”¨æ ‡é‡è¡¨ç¤º

2.å‘é‡ (Vector) : å‘é‡æ˜¯ä¸€ç»„æœ‰åºçš„æ•°å€¼ï¼Œè¡¨ç¤ºæŸç§é‡çš„å¤§å°å’Œæ–¹å‘

3.å¼ é‡ (Tensor) :å¼ é‡æ˜¯æ ‡é‡å’Œå‘é‡çš„æ³›åŒ–å®ƒæ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œå¯ä»¥è¡¨ç¤ºå¤šç§å¤æ‚çš„æ•°æ®ç»“æ„ã€‚
å¼ é‡çš„é˜¶è¡¨ç¤ºå¼ é‡çš„ç»´æ•°ã€‚
ä¾‹å¦‚ï¼Œé›¶é˜¶å¼ é‡å°±æ˜¯æ ‡é‡ï¼Œä¸€é˜¶å¼ é‡å°±æ˜¯å‘é‡ã€‚äºŒé˜¶å¼ é‡å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªçŸ©é˜µã€‚




II.è¯å‘é‡(è¯å’Œè¯çš„è·ç¦»)
è¯å‘é‡å°±æ˜¯è¯çš„å‘é‡åŒ–ï¼Œèµ‹å­ä¸€ä¸ª(è¯/å­—)ä¸€ç³»åˆ—çš„å–å€¼ï¼Œæ¯ä¸ªå€¼ä»£è¡¨äº†åœ¨è¿™ä¸ªç»´åº¦/æ–¹å‘ä¸Šçš„å–å€¼/åˆ†ã€‚



ç‹— >>>  [1åè¯ï¼Œ0.1å½¢å®¹è¯....., 0æ¤ç‰©,-1çŒ«]

ä½ å¤ªç‹—äº†(å½¢å®¹è¯)

GTP-3 175Bç‰ˆæœ¬æ¨¡å‹ä¸­ï¼Œè¯å‘é‡é•¿åº¦ä¸º12288

ä¸€ä¸ªè¯ï¼Œåœ¨12288ç»´åº¦çš„æ„æ€


ä¸ºä»€ä¹ˆè¦è¯å‘é‡ï¼Ÿè®©è¯­è¨€æ–‡å­—â€œå¯è®¡ç®—â€


II.token æ„æ€æ˜¯å­è¯
token æ„æ€æ˜¯å­è¯ï¼Œ æ¯”å•è¯å°ä¸€åœˆï¼Œçº¦ç­‰äº0.75ä¸ªå•è¯


tokenè¡¨æ•°é‡:50257

å¥½å¤„ï¼š
1.åº”å¯¹æ–°è¯ç½•è§å­—
2.å…±äº«å•è¯é—´çš„ç›¸åŒè¯­ä¹‰ç»“æ„
3.å¤šè¯­è¨€



II.æœ€åŸºæœ¬çš„è®¡ç®—è¿‡ç¨‹æ˜¯
é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ï¼Œå¦‚æ­¤è¿­ä»£ï¼Œç›´è‡³è¾“å‡ºå®Œæˆ




II.transformer å˜å‹å™¨è½¬æ¢å™¨




è¾“å…¥æ–‡æœ¬>>ç¼–ç å™¨éƒ¨åˆ†(ç¼–ç å™¨1ã€ç¼–ç å™¨2)>>è¾“å…¥æ–‡æœ¬çš„è¯­ä¹‰å‘é‡>>è§£ç å™¨éƒ¨åˆ†(è§£ç å™¨1ã€è§£ç å™¨2)


II.è¶…å‚æ•°
è¶…å‚æ•°æ˜¯äº‹å…ˆè®¾å®šçš„
å‚æ•°æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨å­¦ä¹ åˆ°çš„

1.è¯æ±‡è¡¨å¤§å°/tokenæ•°é‡
50257

2.è¯å‘é‡å¤§å°
12288

3.è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦(token)
2048

4.ä½ç½®å‘é‡å¤§å°
12288
å’Œè¯å‘é‡ä¸ä¸€æ ·ï¼Œåœ¨0-2047ä¸ªè¾“å…¥åºåˆ—ï¼Œæœ‰2048ä¸ªä½ç½®ï¼Œæ¯ä¸ªä½ç½®æœ‰12288ä¸ªå«ä¹‰å–å€¼

5.è§£ç å™¨å±‚æ•°:
ç¼–ç å™¨ã€è§£ç å™¨éƒ½æœ‰å¤šå±‚ã€‚
96å±‚

6.è§£ç å™¨å±‚/éšè—å±‚å¤§å°
12288

7.è‡ªä¸»åŠ›å¤´æ•°
åœ¨æ¯ä¸€å±‚è§£ç å™¨æ•æ‰æ³¨æ„åŠ›çš„å¤´æ•°
96ä¸ª


8.æ³¨æ„åŠ›ç»´åº¦æ•°
12288/96 =128
è§£ç å™¨å±‚/è‡ªä¸»åŠ›å¤´æ•°=æ³¨æ„åŠ›ç»´åº¦æ•°




II.å‚æ•°

GPTæ¨¡å‹ä¸­çš„å‚æ•°å¤§å¤šè¡¨ç¤ºä¸ºä¸€ä¸ªæˆ–å¤šä¸ªæƒé‡çŸ©é˜µã€‚

å‚æ•°å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ¨¡å‹çš„ä¸åŒå°±è¡¨ç°åœ¨å‚æ•°çš„ä¸åŒä¸Šã€‚


----------------------------------------------------------------
ç¬¬å››èŠ‚è¯¦ç»†


I.è¯¦ç»†è§£é‡Š

II.æ€»ä½“ç»“æ„
1.è¾“å…¥æ–‡æœ¬åºåˆ—
2.è¾“å…¥å¤„ç†(é¢„å¤„ç†ã€[åˆ†è¯ã€åˆ†token]ã€å‘é‡åµŒå…¥/å‘é‡åŒ–)
3.è§£ç å™¨æ ˆ(å¤šå±‚(96å±‚ã€æ·±åº¦ç¥ç»ç½‘ç»œã€ä¸åŸå§‹transformerè§£ç å™¨æœ‰æ‰€å˜åŒ–))
4.è¾“å‡ºå¤„ç†ã€‚(æœ€ç»ˆä»»åŠ¡å¤„ç†ã€è¿­ä»£å¾ªç¯)
5.è¾“å‡ºæ–‡æœ¬åºåˆ—




è¾“å…¥æ–‡æœ¬åºåˆ—>è¾“å…¥å¤„ç†>è§£ç å™¨æ ˆ>è¾“å‡ºå¤„ç†>è¾“å‡ºæ–‡æœ¬åºåˆ—


II.è¾“å…¥å¤„ç†
1.åˆ†è¯/token
2.å‘é‡åµŒå…¥(çŸ©é˜µç›¸åŠ )
3.è¯å‘é‡+ä½ç½®å‘é‡

ä¾‹:æˆ‘æ˜¯ä¸€ä¸ª

åˆ†è¯ã€å½¢æˆtokenåºåˆ—
token:"æˆ‘" ã€ "æ˜¯"  ã€ "ä¸€ä¸ª"


æŸ¥æ‰¾tokenå¯¹åº”çš„è¯å‘é‡ã€ä½ç½®å¯¹åº”çš„ä½ç½®å‘é‡ï¼Œâ€œåµŒå…¥â€åˆ°åºåˆ—ä¸­

è¯å‘é‡çŸ©é˜µ:3*12288
æˆ‘:è¯å‘é‡12288
æ˜¯:è¯å‘é‡12288
ä¸€ä¸ª:è¯å‘é‡12288

ä½ç½®å‘é‡çŸ©é˜µ: 3*12288
æˆ‘:ä½ç½®å‘é‡12288
æ˜¯:ä½ç½®å‘é‡12288
ä¸€ä¸ª:ä½ç½®å‘é‡12288


"è¯å‘é‡+ä½ç½®å‘é‡" (çŸ©é˜µåŠ æ³•) å½¢æˆè¾“å…¥éƒ¨åˆ†çš„ï¼š æ•°æ®çŸ©é˜µ/å¼ é‡

çŸ©é˜µç›¸åŠ ï¼šè¡Œåˆ—ä¸€è‡´æ‰èƒ½ç›¸åŠ  ä¸¤ä¸ª3*12288(çº¿æ€§ä»£æ•°)


çŸ©é˜µç›¸ä¹˜çŸ©é˜µä¹˜æ³•ï¼š
1.AçŸ©é˜µä¹˜BçŸ©é˜µæ¡ä»¶ï¼šAçš„åˆ—æ•°  =Bè¡Œæ•°
2.Mè¡ŒNåˆ—çš„çŸ©é˜µ åªèƒ½å’Œ Nè¡ŒKåˆ—çš„çŸ©é˜µç›¸ä¹˜ã€‚
3.ä¸ç¬¦åˆäº¤æ¢å¾‹:AçŸ©é˜µ*BçŸ©é˜µï¼Œä¸ä»£è¡¨B*Aä¹Ÿå¯ä»¥
4.Açš„ç¬¬ä¸€è¡Œ(ç«–è¿‡æ¥)ä¸Bçš„ç¬¬ä¸€åˆ—ä¸€å¯¹ä¸€ç›¸ä¹˜ï¼Œç„¶åç›¸åŠ ï¼Œå½¢æˆç¬¬ä¸€ä¸ªå…ƒç´ ã€‚
5.A(3,2)*B(2,3) = C(2,2)






II.è§£ç å™¨æ ˆ

è§£ç å™¨æ ˆ:(è§£ç å™¨1>>è§£ç å™¨2>>è§£ç å™¨3)


III.è‡ªæ³¨æ„åŠ›å­å±‚
è‡ªæ³¨æ„åŠ›å¤´1ã€è‡ªæ³¨æ„åŠ›å¤´2ã€è‡ªæ³¨æ„åŠ›å¤´N:(96ä¸ª)   æ³¨æ„åŠ›çš„è®¡ç®—å’Œå¤„ç†
å¤šå¤´å‘é‡æ‹¼æ¥       å¤šå¤´æ³¨æ„åŠ›è¾“å‡ºæ‹¼åœ¨ä¸€èµ·
å…¨è¿æ¥çº¿æ€§å±‚       çº¿æ€§è½¬æ¢(çŸ©é˜µç›¸ä¹˜)  y=Wx+B
æ¿€æ´»å‡½æ•°           å¼•å…¥éçº¿æ€§åŒ–ï¼› æ¿€æ´»å‡½æ•°(GRLUã€RELU)
æ®‹å·®è¿æ¥           è¾“å‡º+è¾“å…¥ï¼Œ é¿å…ä¿¡æ¯ä¸¢å¤±(æ‹¿åŸå§‹ä¿¡æ¯+è®¡ç®—åçš„ä¿¡æ¯)
å½’ä¸€åŒ–å±‚           é¿å…å€¼è¿‡å¤§è¿‡å°ï¼Œæé«˜ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ã€‚å¤§éƒ¨åˆ†å€¼è½åœ¨-1åˆ°1ä¹‹é—´

III.å‰é¦ˆç¥ç»ç½‘ç»œå­å±‚
å…¨è¿æ¥æ‰©å¼ çº¿æ€§å±‚
æ¿€æ´»å‡½æ•°
å…¨è¿æ¥æ”¶ç¼©çº¿æ€§å±‚
æ®‹å·®è¿æ¥
å½’ä¸€åŒ–å±‚

-----------------------

æ ‡å‡†çš„transformerç»“æ„
I.è§£ç å™¨N
II.è‡ªæ³¨æ„åŠ›å±‚
II.ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›å±‚
II.å‰é¦ˆç¥ç»ç½‘ç»œå±‚

GPTæ²¡æœ‰ç¼–ç å™¨ï¼Œæ‰€ä»¥æ²¡è¿™ä¸€å±‚



------------------------

1.æ³¨æ„åŠ›æœºåˆ¶ï¼šè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—ä¹‹é—´çš„æ³¨æ„åŠ›

2.è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼šè¾“å…¥åºåˆ—è‡ªèº«





------------------------

å¤šå¤´è‡ªå›å½’è‡ªæ³¨æ„åŠ›æœºåˆ¶



è‡ªæ³¨æ„åŠ›å¤´N
QçŸ©é˜µè®¡ç®—  KçŸ©é˜µè®¡ç®—  VçŸ©é˜µè®¡ç®—
QKè½¬ç½®ç›¸ä¹˜/ç‚¹ç§¯è®¡ç®—(çŸ©é˜µç›¸ä¹˜å‹ç¼©ç»´åº¦)
ç¼©æ”¾
æ©ç çŸ©é˜µç›¸ä¹˜
softmax
ä¸VçŸ©é˜µç›¸ä¹˜


1.æ³¨æ„åŠ›æœºåˆ¶ï¼šè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—ä¹‹é—´çš„æ³¨æ„åŠ›(è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å…³ç³»)
 AI å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå‡†ç¡®åº¦ï¼Œä½¿å…¶æ›´å¥½åœ°å®Œæˆå„ç§ä»»åŠ¡ã€‚
åœ¨å¤„ç†è¾“å…¥æ•°æ®æ—¶å¯¹ä¸åŒéƒ¨åˆ†è¿›è¡ŒåŠ æƒï¼Œä»¥ä¾¿æ›´é›†ä¸­åœ°å…³æ³¨é‚£äº›è¢«è®¤ä¸ºæœ€æœ‰æ„ä¹‰æˆ–æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
ç±»ä¼¼äºäººç±»å¤§è„‘å¯¹é‡è¦ä¿¡æ¯çš„é€‰æ‹©æ€§å¤„ç†æ–¹å¼ã€‚
å›¾åƒè¯†åˆ«ä¸­ï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å›¾ç‰‡ä¸­å“ªäº›éƒ¨åˆ†ä¸ç›®æ ‡ç›¸å…³
è¯­éŸ³è¯†åˆ«ä¸­ï¼Œæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥ä½¿æ¨¡å‹æ›´å¥½åœ°ç†è§£è¯´è¯è€…è¯´çš„æ˜¯å“ªäº›å•è¯


2.è‡ªæ³¨æ„åŠ›æœºåˆ¶:è¾“å…¥åºåˆ—è‡ªèº«

3.è‡ªå›å½’/å•å‘/å› æœï¼šåªèƒ½çœ‹åˆ°è‡ªå·±å·¦è¾¹çš„å­—

4.å¤šå¤´ï¼šåˆ†æˆå¤šä¸ªå¤´ï¼Œåˆ†åˆ«å–æ³¨æ„ä¸åŒçš„è¯­ä¹‰è¡¨ç¤º


GPTæ²¡æœ‰è¾“å‡ºåºåˆ—ï¼Œåªèƒ½å…³æ³¨è¾“å…¥åºåˆ—ï¼Œè‡ªå·±çŒœæµ‹è¾“å‡ºåºåˆ—



I.è¾“å…¥åºåˆ—çš„ qã€kã€v çŸ©é˜µè®¡ç®—

è¾“å…¥:3*12288

æ¯ä¸ªæƒé‡çŸ©é˜µéƒ½æœ‰è‡ªå·±çš„12288*128çš„çŸ©é˜µ

QçŸ©é˜µ(é—®é¢˜çŸ©é˜µ):12288*128
KçŸ©é˜µ(ç´¢å¼•çŸ©é˜µ):12288*128
VçŸ©é˜µ(ç­”æ¡ˆçŸ©é˜µ):12288*128


query:å½“å‰è®¡ç®—çš„å­—å½“æˆé—®é¢˜æç»™KçŸ©é˜µ
key:æ˜¯é¢å¯¹QçŸ©é˜µé—®é¢˜ï¼Œç­”æ¡ˆç´¢å¼•çš„KçŸ©é˜µ
value:ç­”æ¡ˆçš„å†…å®¹æ˜¯VçŸ©é˜µ


>Qé—®é¢˜çŸ©é˜µ(æƒé‡çŸ©é˜µ)  è®¡ç®—åï¼Œå½“æˆé—®é¢˜æç»™Kç´¢å¼•çŸ©é˜µï¼Œkç´¢å¼•çŸ©é˜µè®¡ç®—åï¼Œè®¡ç®—Vç­”æ¡ˆçŸ©é˜µ


I.è®¡ç®—å„è¯ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡/è·ç¦»

I.ç»Ÿä¸€åšä¸ªé™¤æ³•ï¼Œé¿å…å€¼è¿‡å¤§
è¯åµŒå…¥ç»´åº¦çš„å¹³æ–¹æ ¹

I.è‡ªå›å½’å¤„ç†ï¼Œé¿å…â€œå‰§é€â€å½±å“

I.æ¦‚ç‡åŒ–ï¼Œå½¢æˆçœŸæ­£çš„æƒé‡

I.å¾—åˆ°ç­”æ¡ˆæ³¨æ„åŠ›æœ€ç»ˆç»“æœ



æ¯å±‚è¾“å‡ºä¸€ä¸ª 3 *128 çš„çŸ©é˜µä¸€å…±96å±‚



å¤šå¤´å‘é‡æ‹¼æ¥:(ä¸Šä¸€æ­¥å¾—åˆ°96ä¸ª3*128çš„çŸ©é˜µï¼Œæœ¬å±‚è¿›è¡Œè¿æ¥å¾—åˆ°3*12288çŸ©é˜µ)

3*12288


12288*12288


---------------------


å‰é¦ˆç¥ç»ç½‘ç»œå­å±‚

I.å…¨è¿æ¥æ‰©å¼ çº¿æ€§å±‚
I.æ¿€æ´»å‡½æ•°
I.å…¨è¿æ¥æ”¶ç¼©çº¿æ€§å±‚
I.æ®‹å·®è¿æ¥
I.å½’ä¸€åŒ–å±‚


I.å…¨è¿æ¥æ‰©å¼ çº¿æ€§å±‚
è¯­ä¹‰æ ‡è¯†æ‹“å±•åˆ°æ›´é«˜çº¬åº¦ç©ºé—´(æ‰©å¼ 4å€)
3*12288çš„è¾“å…¥çŸ©é˜µ
ä¹˜ä»¥æœ¬å±‚12288*4*12288
å¾—åˆ°3*(4*12288)




I.æ¿€æ´»å‡½æ•°
I.å…¨è¿æ¥æ”¶ç¼©çº¿æ€§å±‚
æŠŠæ‰©äº†4å€çš„ç¼©å°

ä¸Šä¸€æ­¥çš„ç»“æœï¼š3*(4*12288)
ä¹˜ä»¥æœ¬å±‚(4*12288)*12288

å¾—åˆ°ï¼š3*12288
å­¦ä¹ åˆ°äº†æ›´å¤šï¼Œæ›´é«˜çº¬åº¦çš„è¾“å…¥åºåˆ—çš„è¯­ä¹‰è¡¨ç¤º


I.æ®‹å·®è¿æ¥

I.å½’ä¸€åŒ–å±‚

æ ¹æ®è‡ªæ³¨æ„åŠ›å­å±‚å’Œå‰é¦ˆç¥ç»ç½‘ç»œå­å±‚

å¾—åˆ°
å’Œè¾“å…¥åºåˆ—å®Œå…¨ç›¸å…³çš„
æ•è·è¿‡æ·±å±‚è¯­ä¹‰çš„
è¿™æ ·çš„ä¸€ä¸ªè¯­ä¹‰è¡¨è¾¾

---
å‰é¦ˆ æ•æ‰æ›´æ·±å±‚çš„å…³ç³»

è‡ªæ³¨æ„ å…³æ³¨ tokenä¹‹é—´çš„å…³ç³»


æ¯ä¸€å±‚æœ‰96ä¸ªå¤´ï¼Œä¸€å…±æœ‰96å±‚




20230720

ç¬¬å››èŠ‚è¯¦ç»†


å…¨è¿æ¥çº¿æ€§å±‚ çº¿æ€§è½¬åŒ–(çŸ©é˜µç›¸ä¹˜) y=Wx+B





å¯¹äºè¾“å…¥å‘é‡ x å’Œæƒé‡çŸ©é˜µ Wï¼Œå…¨è¿æ¥çº¿æ€§å±‚çš„è¾“å‡º y å¯ä»¥è¡¨ç¤ºä¸º y = Wx + bï¼Œå…¶ä¸­ b æ˜¯åç½®å‘é‡ã€‚




æ•æ‰ï¼Œè¾“å…¥åºåˆ—ä¹‹é—´ç›¸äº’å…³ç³»




æ›´æ·±å±‚çš„ï¼Œ


I.è¾“å‡ºå¤„ç†éƒ¨åˆ†

çº¿æ€§å±‚
Softmax
é‡‡æ ·ç­–ç•¥å¤„ç†
è¿­ä»£è¾“å‡º


II.çº¿æ€§å±‚
è®¡ç®—è¾“å‡ºæ¦‚ç‡å€¼

è¾“å…¥ 3*12288

æƒé‡å‚æ•°:12288*50257
12288(è¯å‘é‡å¤§å°)*50257(tokenæ•°é‡ã€è¯æ±‡è¡¨å¤§å°)

è®¡ç®—è¾“å‡ºæ¦‚ç‡å€¼

3*12288  * 12288*50257

å¾—åˆ°ï¼š3*50257


â€œæˆ‘æ˜¯ä¸€ä¸ªâ€

"æˆ‘"åè¾¹å‡ºç°é‚£ä¸ªè¯çš„æ¦‚ç‡æœ€å¤§ã€‚
"æˆ‘æ˜¯"åè¾¹å‡ºç°é‚£ä¸ªè¯çš„æ¦‚ç‡æœ€å¤§ã€‚


II.Softmax
è°ƒæ•´æ¦‚ç‡æƒé‡ï¼Œæ€»å’Œä¸º1



II.é‡‡æ ·ç­–ç•¥å¤„ç†
ç¡®å®šä¸‹ä¸€ä¸ªå­—
"å‡ ä¸ªå­—æ¦‚è§ˆéƒ½ä¸€æ ·æ—¶ï¼Œé€‰é‚£ä¸ª"

éšæœºæ•°ç­‰æ–¹æ³•ç¡®å®šä¸‹ä¸€ä¸ªå­—


II.è¿­ä»£è¾“å‡º
è¿­ä»£å¤„ç†

æ”¾å…¥è§£ç å™¨å°¾ç«¯ï¼Œå†è¿›è¡Œä¸‹ä¸€ä¸ªä¸€éƒ¨åˆ†å¤„ç†ï¼Œè¾“å‡ºä¸‹ä¸‹ä¸ªå­—ã€‚




I.ä»è¾“å…¥(è¯å‘é‡çŸ©é˜µ)åˆ°è¾“å‡º(æ¦‚ç‡æƒé‡çŸ©é˜µ)

â€œæˆ‘æ˜¯ä¸€ä¸ªâ€




20230720

ç¬¬å››èŠ‚è¯¦ç»† 40ï¼š00



I.è¾“å…¥å¤„ç†

è¯å‘é‡çŸ©é˜µï¼š12288
è¯ä½ç½®å‘é‡çŸ©é˜µï¼š 12288
ç›¸åŠ 




I.è§£ç å™¨96å±‚ï¼š

IIã€‚è‡ªæ³¨æ„åŠ›å­å±‚ï¼š
IIIã€‚è‡ªæ³¨æ„åŠ›å¤´96ä¸ª
IIIIã€‚qkvçŸ©é˜µ é—®é¢˜ç´¢å¼•ç­”æ¡ˆçŸ©é˜µä¸‰ä¸ª  128
III.å¤šå¤´å‘é‡æ‹¼æ¥96å±‚æ‹¼æ¥
III.å…¨è¿æ¥(é™ç»´)
III.æ¿€æ´»å‡½æ•°ï¼šå¼•å…¥éçº¿æ€§åŒ–
III.æ®‹å·®é“¾æ¥ï¼šé¿å…å’Œè¾“å…¥æœ‰è¾ƒå¤§å‡ºå…¥
III.Softmaxå½’ä¸€åŒ–å±‚(0,1)(é¿å…å€¼è¿‡å¤§è¿‡å°)



II.å‰é¦ˆç¥ç»ç½‘ç»œå±‚
III.å…¨è¿æ¥ æ‹“å¼  çº¿æ€§å±‚ å‡ç»´ 12288*12288*4
III.æ¿€æ´»å‡½æ•°ï¼šå¼•å…¥éçº¿æ€§åŒ–
III.å…¨è¿æ¥ æœç´¢ çº¿æ€§å±‚ é™ç»´ (4*12288)*12288
III.æ®‹å·®é“¾æ¥ï¼šé¿å…å’Œè¾“å…¥æœ‰è¾ƒå¤§å‡ºå…¥
III.softmaxå½’ä¸€åŒ–(0,1)(é¿å…å€¼è¿‡å¤§è¿‡å°)


I.è¾“å‡ºå¤„ç†
II.çº¿æ€§å±‚
50257 è¯å‘é‡çŸ©é˜µã€‹ã€‹æ¦‚ç‡æƒé‡çŸ©é˜µ
II.å½’ä¸€åŒ–å¤„ç†(é¿å…å€¼è¿‡å¤§è¿‡å°)
II.é‡‡æ ·ç­–ç•¥  ï¼šç¡®å®šä¸‹ä¸€ä¸ªå­—
II.è¿­ä»£è¾“å‡ºï¼š æŠŠä¸‹ä¸€ä¸ªå­—æ”¾å…¥è¾“å…¥åºåˆ—





20230802ç¬¬äº”éƒ¨åˆ†


ç®—æ³•è¿‡ç¨‹æ˜¯å…¬å¼€çš„

æ¨¡å‹æ€§èƒ½ï¼Œç­”æ¡ˆæ˜¯å¦å‡†ç¡®å–å†³äºå‚æ•°æ˜¯å¦æ­£ç¡®ã€‚


è®­ç»ƒè¿‡ç¨‹-ä»0åˆ°1


1.æ¨¡å‹çš„åˆå§‹å‚æ•°ä¸ºéšæœºå–å¾—
è¶…å‚æ•°æ˜¯äººä¸ºè®¾ç½®çš„ã€‚
å‚æ•°æ˜¯éšæœºå–å¾—ã€‚



I.ç¬¬äº”éƒ¨åˆ† è®­ç»ƒè¿‡ç¨‹

1.æ¨¡å‹çš„åˆå§‹å‚æ•°ä¸ºéšæœºå–å¾—

2.è®¡ç®—æ¨¡å‹è¾“å‡ºä¸çœŸå®æ•°æ®çš„å·®è·(æŸå¤±å€¼å’Œæ¢¯åº¦)

3.æ ¹æ®æŸå¤±å€¼ï¼Œåå‘é€å±‚è°ƒæ•´æƒé‡å‚æ•°

4.æ¨ç†æ˜¯è®­ç»ƒçš„å‰åŠéƒ¨åˆ†

5.ç›¸æ¯”æ¨ç†ï¼Œè®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºæ›´å¤§



II.æŸå¤±å€¼å’Œæ¢¯åº¦å¦‚ä½•è®¡ç®—

é¢„æµ‹ç»“æœ(çŸ©é˜µ)

ç›®æ ‡ã€one-hotç¼–ç (çŸ©é˜µ)



1.æŸå¤±å€¼loss:ç”¨äºè¡¡é‡æ¨¡å‹çš„æ€§èƒ½
äº¤å‰ç†µæŸå¤±(cross-entropy loss):

é¢„æµ‹ç»“æœå–å¯¹æ•°>ä¸ç›®æ ‡çŸ©é˜µé€ä½ç½®ç›¸ä¹˜>æ±‚å’Œ
>å–åæ•°>é™¤åºåˆ—é•¿åº¦>è®­ç»ƒé›†æ±‚å’Œå–å¹³å‡æ•°>å¹³å‡æŸå¤±å€¼

2.èµ·å§‹æ¢¯åº¦ï¼šå‚æ•°è°ƒæ•´åå‘ä¼ æ’­çš„èµ·ç‚¹ï¼Œè¡¨ç°ä¸ºä¸€ä¸ªçŸ©é˜µã€æ¯ä¸ªå‚æ•°åº”è¯¥è°ƒæ•´çš„å€¼(åŠ å‡ã€æ­£è´Ÿ)

ç›®æ ‡çŸ©é˜µå‡å»é¢„æµ‹ç»“æœçŸ©é˜µï¼Œå°±æ˜¯è¯¥è®­ç»ƒè¿‡ç¨‹çš„èµ·å§‹æ¢¯åº¦ã€‚



II.æ¢¯åº¦å¦‚ä½•åå‘ä¼ æ’­-é“¾å¼æ³•åˆ™

é“¾å¼æ³•åˆ™chain ruleæ˜¯å¾®ç§¯åˆ†ä¸­çš„ä¸€ç§åŸºæœ¬è§„åˆ™ï¼Œç”¨äºè®¡ç®—è´Ÿè·å‡½æ•°çš„å¯¼æ•°ã€‚
åœ¨ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ ä¸­ï¼Œé“¾å¼æ³•åˆ™ç»å¸¸ç”¨äºæ±‚è§£æŸå¤±å‡½æ•°å…³äºæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œ
ä»è€Œå®ç°æ¢¯åº¦ä¸‹é™å’Œå‘ç°ä¼ æ’­ç®—æ³•ã€‚


èµ·å§‹åœ°å›¾æ¥è‡ªé¢„æµ‹ç»“æœä¸ç›®æ ‡çš„å·®å€¼çŸ©é˜µï¼Œåç»­æ¥ç€ä¸‹ä¸€å±‚çš„è¾“å…¥çŸ©é˜µæ¢¯åº¦ã€‚

æ¿€æ´»å‡½æ•°ã€softmaxã€å½’ä¸€åŒ–æ“ä½œç­‰çš„æ¢¯åº¦è®¡ç®—ï¼Œä¸å…·ä½“æ“ä½œå‡½æ•°ç›¸å…³ã€‚


åæ‰§å‘é‡æ¢¯åº¦ç­‰äºé€åˆ—æ±‚å’Œè¾“å‡ºçŸ©é˜µæ¢¯åº¦ã€‚

å‚æ•°çŸ©é˜µæ¢¯åº¦ç­‰äºè¾“å…¥çŸ©é˜µè½¬ç½®ä¹˜è¾“å‡ºçŸ©é˜µæ¢¯åº¦

è¾“å…¥çŸ©é˜µæ¢¯åº¦ç­‰äºè¾“å‡ºçŸ©é˜µæ¢¯åº¦ä¹˜å‚æ•°çŸ©é˜µçš„è½¬ç½®




II.å‚æ•°å¦‚ä½•è°ƒæ•´--å­¦ä¹ ç‡

å‚æ•°æ›´æ–°ç®—æ³•æœ‰å¾ˆå¤šã€ä¾‹å¦‚éšæœºæ¢¯åº¦ä¸‹é™ã€å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç­‰ï¼ŒGPTç”¨çš„æ˜¯Adamç®—æ³• (Adaptive moment estimation)


æœ€åŸºæœ¬çš„æ›´æ–°ç®—æ³•å°±æ˜¯å°†å‚æ•°çŸ©é˜µå‡å»æ¢¯åº¦çŸ©é˜µï¼Œå½¢æˆæ–°çš„å‚æ•°çŸ©é˜µã€‚åæ‰§å‘é‡ä¹Ÿä¸€æ ·ï¼Œå‡å»æ¢¯åº¦å‘é‡ã€‚



å­¦ä¹ ç‡æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œä¸€èˆ¬ä¼šå°†å­¦ä¹ ç‡ä¸æ¢¯åº¦çŸ©é˜µç›¸ä¹˜ï¼Œå†å»
ä¸å‚æ•°çŸ©é˜µã€åæ‰§å‘é‡ç›¸å‡ï¼Œå‡å°å‚æ•°è°ƒæ•´çš„æ­¥é•¿ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚



Adamç®—æ³•ä¼šæ›´å¤æ‚ï¼Œä¼šè®¡ç®—æ¢¯åº¦çš„å‡å€¼å’Œæ–¹å·®ï¼ŒåŒæ—¶ä¼šåŠ¨æ€çš„è°ƒæ•´å­¦ä¹ ç‡ï¼Œä»è€Œä½¿æ¨¡å‹æ›´å¿«çš„
æ”¶æ•›å’Œæé«˜ç¨³å®šæ€§ã€‚




II.æœ€ç»ˆè®­ç»ƒè¿‡ç¨‹--è®­ç»ƒé›†(æ‰¹æ¬¡)

è®­ç»ƒæ—¶ï¼Œæ¯ä¸€ä¸ªè¾“å…¥åºåˆ—éƒ½ä¼šå–æœ€å¤§çš„åºåˆ—é•¿åº¦ï¼Œæ¯”å¦‚GPT3 175B æ˜¯2048ä¸ª token

å¤šä¸ªè®­ç»ƒåºåˆ—ä¼šåˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªè®­ç»ƒé›†æˆ–è®­ç»ƒæ‰¹æ¬¡ï¼ŒGPT3 175çš„æ‰¹æ¬¡å¤§å°æ˜¯3.2M token

å­¦ä¹ ç‡æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œä¸€èˆ¬ä¼šå°†å­¦ä¹ ç‡ä¸æ¢¯åº¦çŸ©é˜µç›¸ä¹˜ï¼Œå†å»ä¸å‚æ•°çŸ©é˜µã€åæ‰§å‘é‡ç›¸å‡ï¼Œ
å‡å°å‚æ•°è°ƒæ•´çš„æ­¥é•¿ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚GPT3 175Bçš„åˆå§‹å­¦ä¹ ç‡æ˜¯ 0.6*10-4


æ¯ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­ï¼Œæ¯ä¸€ä¸ªè¾“å…¥åºåˆ—ä¼šæ‰§è¡Œå‰å‘è®¡ç®—å’Œåå‘ä¼ æ’­è¿‡ç¨‹ï¼Œè®°å½•ä¸‹å„ä¸ª
å‚æ•°çŸ©é˜µçš„æ¢¯åº¦ã€‚å½“æ‰€æœ‰çš„è¾“å…¥åºåˆ—éƒ½æ‰§è¡Œå®Œæˆåï¼Œä¼šå¯¹æ¯ä¸ªåºåˆ—å½¢æˆçš„æ¢¯åº¦è¿›è¡Œ
æ±‚å’Œï¼Œå¹¶é™¤ä»¥åºåˆ—æ•°é‡ï¼Œå¾—åˆ°å¹³å‡æ¢¯åº¦å€¼ï¼Œç„¶åè¿›è¡Œä¸€æ¬¡ç»Ÿä¸€çš„å‚æ•°è°ƒæ•´ã€‚




II.æ€»ç»“  å‚æ•°çš„å…¨ç”Ÿå‘½å‘¨æœŸ
å‚æ•°æ˜¯æ ¸å¿ƒï¼Œå‚æ•°çš„è§„æ¨¡ï¼Œ

1.å‚æ•°çš„äº§ç”Ÿ--è®­ç»ƒ
éšæœºåˆå§‹åŒ–
å¤šæ¬¡è¿­ä»£è®­ç»ƒï¼Œæœ€ç»ˆé€¼è¿‘å‡†ç¡®å€¼

2.å‚æ•°çš„ä½¿ç”¨--æ¨ç†
å¤§é‡çš„çŸ©é˜µç›¸ä¹˜

3.å‚æ•°çš„å¾®è°ƒ
todo




I.åç»­

II.æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹
å‡ºå‚å‰ ï¼š SFTã€ RM  ã€PPO
å‡ºå‚å ï¼š å„ç§FT ã€ embedding

II.æ¨¡å‹çš„ROL ã€åŠŸè€—
ä¸ºä»€ä¹ˆé˜¿å°”ç‰¹æ›¼è¯´ï¼Œå¤§æ¨¡å‹å·²ç»èµ°åˆ°äº†å°½å¤´?
æ¨¡å‹çš„é—¨æ§›å’Œå¤©èŠ±æ¿

II.prompt ã€æ¶Œç°ã€é¡¿æ‚Ÿã€æ¿€å‘

II.è·¨æ¨¡æ€æ¨¡å‹

II.æ·±åº¦ç¥ç»ç½‘ç»œä¸ç”Ÿç‰©ç¥ç»ç½‘ç»œ




I.p6 ChatGPTè¯¦ç»†è§£é‡Š-ç•ªå¤–ç¯‡-ä¸ºä»€ä¹ˆ 12åˆ†é’Ÿå·¦å³

II.è®­ç»ƒæµç¨‹:
II.LossæŸå¤±å€¼å’Œæ¢¯åº¦çŸ©é˜µå¦‚ä½•è®¡ç®—

III.æŸå¤±å€¼(Loss):ç”¨æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ æŸå¤±å€¼è¶Šå¤§ï¼Œæ€§èƒ½è¶Šå·®ï¼Œè¶Šæ¥è¿‘0è¶Šå¥½
äº¤å‰ç†µæŸå¤±(Cross-Entropy Loss):é¢„æµ‹ç»“æœå–å¯¹æ•°->ä¸ç›®æ ‡çŸ©é˜µé€ä½ç½®ç›¸ä¹˜->æ±‚å’Œ->å–åæ•°->é™¤åºåˆ—é•¿åº¦->è®­ç»ƒé›†æ±‚å’Œå–å¹³å‡æ•°->å¹³å‡æŸå¤±å€¼ã€‚
æŸå¤±å€¼(Loss):ç”¨æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½
äº¤å‰ç†µæŸå¤±(Cross-Entropy Loss):é¢„æµ‹ç»“æœå–å¯¹æ•°->ä¸ç›®æ ‡çŸ©é˜µé€ä½ç½®ç›¸ä¹˜->æ±‚å’Œ->å–åæ•°->é™¤åºåˆ—é•¿åº¦->è®­ç»ƒé›†æ±‚å’Œå–å¹³å‡æ•°->å¹³å‡æŸå¤±å€¼ã€‚

æŸå¤±å€¼è¶Šå¤§ï¼Œæ€§èƒ½è¶Šå·®ï¼Œè¶Šæ¥è¿‘0è¶Šå¥½


èµ·å§‹æ¢¯åº¦ï¼šå‚æ•°è°ƒæ•´åå‘ä¼ æ’­èµ·ç‚¹ã€è¡¨ç°ä¸ºä¸€ä¸ªçŸ©é˜µã€æ¯ä¸ªå‚æ•°åº”è¯¥è°ƒæ•´çš„å€¼(åŠ å‡/æ­£è´Ÿ)ã€‚

ç›®æ ‡çŸ©é˜µå‡å»é¢„æµ‹ç»“æœçŸ©é˜µï¼Œå°±æ˜¯è¯¥è®­ç»ƒè¿‡ç¨‹çš„èµ·å§‹æ¢¯åº¦ã€‚


æ¢¯åº¦(çŸ©é˜µ)ï¼šèµ·å§‹çŸ©é˜µå’Œå‡†ç¡®å‚æ•°çŸ©é˜µçš„å·®å€¼ï¼Œæ¯ä¸ªç‚¹çš„å·®å€¼(æ˜¯ä¸€ä¸ªçŸ©é˜µ)

å‚æ•°è°ƒæ•´/åå‘ä¼ æ’­çš„ä¸€ä¸ªèµ·ç‚¹å°±æ˜¯èµ·å§‹æ¢¯åº¦

æ¢¯åº¦å¦‚ä½•åå‘ä¼ æ’­-é“¾å¼æ³•åˆ™



æ¢¯åº¦å¦‚ä½•åå‘ä¼ æ’­-é“¾å¼æ³•åˆ™
ç•ªå¤–ç¯‡-ä¸ºä»€ä¹ˆ 12åˆ†é’Ÿå·¦å³














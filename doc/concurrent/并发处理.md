操作系统原理:

http://www.matools.com/api/java8
https://docs.oracle.com/javase/8/docs/api/index.html


I.第一讲 原子性、可见性、有序性：并发bug的源头


只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发问题是可以理解的
缓存导致的可见性、线程切换带来的原子性、编译优化带来的有序性。


I.第二讲 JMM：看java如何解决可见性和有序性


volatile、synchronized、final+六项happens-before规则
 



synchronized 
修饰静态方法时，锁定当前类的class对象

非静态方法，锁定当前实例对象this



15 Lock和Condition下:dubbo如何用管程实现异步转同步
我们讲到了javaSDK并发包里的lock有别与synchronized隐士锁的三个特性
：能够响应中断、支持超时和非阻塞地获取锁。那今天我们接着再来详细聊聊javasdk并发
包里condition，condition实现了管程模型里面的条件变量。

在管程里我们提到过java语言内置的管程里只有一个条件变量
，而lockcondition实现的管程是支持多个条件变量的。这是二者的一个重要区别

在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。
例如，实现一个阻塞对垒，就需要两个条件变量。

那如何利用两个条件变量快速实现阻塞队列呢

一个阻塞队列，需要两个条件变量，一个队列不空，另一个是队列不满
这个例子我们前面在介绍管程的时候详细说过，这里就不赘述。相关
的代码，我这里重新列出来，你可以温故知新一下。

不过，这里你需要注意，lock和condition实现的管程，线程等待和通知需要调用 await()
signal、signalAll,他们的寓意和waitnotify notifyall相同。但是不一样的是
lock 和condition实现的管程里只能使用前面的await signal signalall而后面的
wait notify notify all只有在synchronized实现管程里才能使用。如果一步小心在
lock condition实现的管程里调用了wait notify notifyall那程序可就彻底玩完了。

javasdk并发包里lock和condition不过就是管程的一种实现而已。管程你已经很熟悉了
那lock和condition的使用自然是小菜一碟。下面我们就来看看在指明项目dubbo中
lock和condition是怎么用的。不过在开始介绍源码之前，我们还要先介绍两个概念：同步和异步

同步和异步
我们平时写的代码，基本都是同步的。但最近几年，异步编程大火。那同步和异步的区别到底是什么
呢？通俗点来讲就是调用方式是否需要等待结果，如果需要等待结果，就是同步；如果不需要等待结果，就是异步。

比如在下面的代码里，有一个计算圆周率小数点后100万位的方法牌m，这个方法可能需要
执行两礼拜，如果调用pait1
后，线程一直等着计算结果，等两立牌后结果返回，就可以执行printyg了，这个属于同步；如果调用pai之后
线程不用等待计算结果，立刻就可以执行printf这个就属于异步。

同步，是java代码默认的处理方式。如果你想让你的程序支持异步，可以通过下面两种方式来
实现：
  1.调用方创建一个子线程，在子线程中执行方法调用，这种调用我们称为异步调用；
  2.方法实现的时候，创建一个新的线程执行主要逻辑，主线程直接return，这种方法我们一般称为
  异步方法
  
dubbo源码分析
其实在编程领域，异步场景还是挺多的，比如tcp协议本身就是异步的，我们工作中经常用到
的rpc调用，在tcp协议层面，发送完RPC之后，线程是不会等待RPC的响应结果的。可能
你会觉得奇怪，平时工作中的rpc调用大多数都是同步的啊，
其实很简单，一定是有人帮你做了异步转同步的事情。例如目前RPC dubbo就给我们
做了异步转同步的事情，那它是怎么做的呢？下面我们就来分析下dubbo源码

对于下面一个简单RPC调用，默认情况下sayhello方法，是个同步方法，也即是说，执行
service。sayhello的时候，线程会停下来。
如果你将dump出来的话，会是下图这个样子，你会发现调用线程阻塞了，线程状态
是timed waiting .本来发送请求时异步的，但是调用线程阻塞了，说明dubbo帮我们
做了异步转同步的事情。通过调用栈，你能看到线程是阻塞在defualtFuture.get方法上，所以
我们可以推断：dubbo异步转同步的功能应该是通过defaultFuture这个类实现的。

不过为了理清前后关系，还是有必要分析下调用defualtFutureget之前发生了什么
 dubboInvolker的108行调用了DefaultFuture.get这一银行很关键，我们稍微修改了一下列在
 了下面。这一行先调用了request这个方法其实就是发送rpc请求，之后通过gety方法等待RPC返回结果。

DefaultFuture这个类是很关键，我把相关的代码精简之后，列到了下面。不过在看代码之前，
你还是由必要重复一下我们的需求：当RPC返回结果之前，阻塞调用线程，让调用线程等待；
当RPC返回结果后，唤醒调用线程，让调用线程重新执行。不知道你有没有似曾相识的感觉，
这不就是经典的等待-通知机制吗，这个时候想必你的脑海里应该能够浮现出管程的解决方法了。
有了自己的方案之后，我们再来看看dubbo是怎么实现的。

调用线程通过调用get方法等待RPC返回结果，这个方法里面，你看到的都是熟悉的面孔
：调用lock获取锁，在finally里面调用unlock释放锁，获取锁后，通过经典的再循环
中调用await方法来实现等待。

当rpc结果返回时，会调用do Received 方法，这个方法里面，调用lock获取锁，在
finally里面调用unlock释放锁，获取锁后通过调用signal来通知调用线程，结果已经返回
，不用继续等待了。

至此，dubbo里面的异步转同步的源码就分析完了，有没有觉得还挺简单的？最近这几年，工作
中需要异步处理的越来越多了，其中有一个主要原因就是有些API本事就是异步API 。例如
websocket也是一个异步的通信协议，如果基于这个协议实现一个简单的rpc你也会遇到
异步转同步的问题。现在很多公有云的API本身也是异步的，例如创建云主机，就是一个异步的
API，调用虽然成功了，但是云主机并没有创建成功，你需要调用另外一个api去轮训云主机的状态
。如果你需要在项目内部封装创建云主机的API，你也会面临异步转同步的问题，因为同步api更易用。

总结

lock condition 是管程的一种实现，所以能否用好lcok和condition 要看你对管程模型理解
得怎么样。管程技术前面我们已经专门用一篇文章做了介绍，你可以结合着来学，理论联系实践

lock confition实现的管程相对于synchronized实现的管程来说更加灵活、功能也更丰富。

结果我自己的经验，我认为了解原理比了解实现更能让你快速学好并发编程，所以没有介绍太多
javasdk并发包里锁和条件变量时如何实现的。但如果你对实现感兴趣，可以参考java并发
编程的艺术艺术中的第五章 java中的锁。里面详细介绍了实现原理，我觉得写得非常好。





16 Semaphore :如何快速实现一个限流器
PV 信号量 semaphore

Semaphore 现在普遍翻译为信号量，以前也曾被翻译成信号灯，因为类似现实生活里
的红绿灯，车辆能不能通行，要看是不是绿灯。同样在编程世界里，线程能不能执行，也要看
信号量是不是允许。

信号量是由大名鼎鼎的计算机科学家迪杰斯特拉DIJKSTRA于1965年提出，在这之后的15年
，信号量一直都是并发编程领域的终结者，知道1980年管程被提出来，我们才有了第二选
则。目前几乎所有支持并发编程的语言都支持信号量机制，所以学号信号量还是很有必要的。

下面我们首先介绍信号量模型，之后介绍如何使用信号量，最后我们再用信号量来实现一个限流器。

信号量模型还是很简单的，可以简单概况为：一个计数器、一个等待队列，三个方法（init、up、down）。在
信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它
们，这三个方法分别是：init、down和up。你可以结

这三个方法详细的语义具体如下所示
init:设置计数器的初始值。
down:计数器的值减一；如果此时计数器的值小于0，则当前线程被阻塞，否则当前线程可以继续执行。
up：计数器的值加一；如果此时计数器的值小于或者等于0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。

这里提到的init、down、up三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。
在javasdk里面，信号量是由模型javauitl.concurrent.Symaphore实现的
，Semaphore这个类能够保证这三个方法都是原子操作。

semaphore.acquire 减一
semphore. release 加一

这里再插一句，信号量模型里面，down up这两个操作历史上最早称为P操作和V操作，
所以信号量模型也被称为PV原语。另外，还有些人喜欢用semWait和semSignal来称呼他们
，虽然叫法不同，但是语义都是相同的。在javaSDK并发包里，down和up对应的则是
acquire和release()


如何使用信号量
通过上文，你应该发现信号量的模型还是很简单的，那具体该如何使用呢？其实你想想红绿灯
就可以了。十字路口的红绿灯可以控制交通，得益于他的一个关键规则：车辆在通过路口前必须
先检查是否是绿灯，只有绿灯才能通过。这个规则和我前面提到的锁规则是不是很类似。

其实，信号量使用的也是类似的。这里我们还是用累加器的例子来说明信号量的使用吧。在累加器
的利器里。count+1的操作是个临界区，值运行一个线程执行，也即是说保证互斥。那这种
情况用信号量怎么控制呢

其实很简单，就像我们用互斥锁一样，只需要在进入临界区之前执行一个down操作，推出临界
区之前执行一下up操作就可以了。下面是java代码的示例，acquire就是信号量里的down
操作，release就是信号量里的up操作o

下面我们再来分析一下，信号量是如何保证互斥的。假设两个线程T1和T2同事访问addone方法
，当它们同事调用acquire的时候，由于acquire是一个原子操作，所以只能由一个
线程把信号量里的计数器减为0，另外一个线程T2则是将计数器减为-1。对于线程
T1，信号量里面的计数器的值是0，大于等于0，所以线程T1会继续执行；对于线程T2，信号量
里面的计数器的值是-1，晓宇0，按照信号量模型里对down操作的描述，线程T2将被阻塞。
所以此时只有线程T1会进入临界区执行count+1
当线程T1执行release操作，也就是up操作的时候，信号量里计数器的值是-1，加1之后的值是0，
小于等于0，按照信号量模型里对up操作的描述，此时等待队列中的T2将会被唤醒。
于是T2在T1执行完临界区代码之后才获得了进入临界区执行的机会，从而保证了互斥性。


快速实现一个限流器
上面的例子，我们用信号量实现了一个最简单的互斥锁功能。估计你会觉得奇怪，既然有java
SDK里面提供的lcok，为啥还要提供一个Semaphore其实实现一个互斥锁，仅仅是
semaphore的部分功能，semaphore还有一个功能是lcok不容易实现的，那就是
semaphore可以允许多个线程访问一个临界区。

现实中还有这种需求？有的。比较常见的需求就是我们工作中遇到的各种池化资源，例如
连接池、对象池、线程池等等。其中，你可可能最熟悉数据库连接池，在同一时刻，一定是允许多个线程
同时使用连接池的，当然，每个连接在被释放前，是不允许其他线程使用的。

其实前不久，我在工作中也遇到了一个对象池的需求。所谓对象池呢，值得是一次性创建出N个对象
，之后所有线程重复利用这N个对象，当然对象在被释放前，也是不允许其他线程使用的。
对象池，可以用list保存示例对象，这个很简单。但管家你是限流器的设计，这里的限流，指
的是不允许多余N个线程同时进入临界区。那如何快读实现一个这样的限流器呢？这种场景，
我立刻就想到了信号量的解决方案。
  
  
  信号量的计数器，在上面的例子中，我们设置成了1，这个1表示只允许一个线程进入临界区，
但如果我们把计数器的值设置成对象池里对象的个数N，就能完美解决对象池的限流问题了。


我们用一个list来保持对象实例，用semaphore 实现限流器。关键的代码是objpool里面的
exec方法，这个方法里面实现了限流的功能。在这个方法里面，我们首先调用acquire方法
与之匹配的是在finally里面调用了release方法，假设对象池的大小是10，信号量的计数器
初始化为10，那么前10个线程调用aquire方法，都能继续支持，相当于通过了信号灯，
而其他线程则会阻塞在acquire方法上。对于通过信号灯的线程，我们为每个线程分配了一个
对象T这个分配工作时通过pool.remove实现的，分配完之后会执行一个回调函数hunc，
而函数的参数正是前面分配的对象t；执行完回调函数之后，他们就会释放对象 这个释放工作时通过pooladd实现的
同时调用release方法来更新信号量的计数器。如果此时
信号量里计数器的值小于等于0，那么说明有线程在等待，此时会自动唤醒等待的线程。

简言之，使用信号量，我们可以轻松实现一个限流器，使用起来还是非常简单的。

总结:

信号量在java语言里面名气并不算大，但是在其他语言里却是很有知名度的。java在并发编程
领域走的很快，重点支持的还是管程模型。管程模型理论上解决了信号量模型的一些不足，主要
提现在易用性和工程方面，例如用信号量解决我们曾经提到过的阻塞队列问题，就比管程模型
麻烦很多，你如果感兴趣，可以课下了解尝试一下。



17 ReadWriteLock:如何快速实现一个完备的缓存

前面我们介绍了管程和信号量这两个同步原语在Java语言中的实现，理论上用着两个同步原语
中任何一个都可以解决所有的并发问题。那Java SDK并发包里为什么还有很多其他的工作类呢？
原因很简单：分场景优化性能，提升易用性。

今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经常
会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。缓存
之所以能提升性能，一个重要的条件就是缓存的数据一定是读多写少的，例如元数据和技术数据
基本上不会发生变化，但是使用它们的地方却很多。
 
针对读多写少这种并发场景，javasdk并发包提供了读写锁  readwritelock ，非常容易使用
并且性能很好。

那什么是读写锁呢？
 读写锁，并不是java语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条
 基本原则：
 
 1.允许多个线程同时读共享变量；
 2.只允许一个线程写共享变量;
 3.如果一个写线程正在执行写操作，此时禁止读线程读共享变量。
 
 读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的
 ，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个
 线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。
 
 快速实现一个缓存
 下面我们就实践起来，用ReadWriteLock快速实现一个通用的缓存工具类。
 在下面的代码中，我们声明一个cache类，其中类型操作K代表缓存里key的类型
 V代表缓存里value类型。缓存的数据保持在cache类内部的hashmap里
 ，hashmap不是线程安全的，这里我们使用读写锁readwritelock来保证其线程安全。
 readwritelock是一个接口，它的实现类是reentrantreadwritelock，通过名字你应该就能
 判断出来，它是支持可重入的。下面我们通过rwl创建一把读锁和一把写锁。
 Cache这个工具类，我们提供了两个方法，一个是读缓存方法get，拎一个是写缓存方法
 put。读缓存需要用到读锁，读锁的使用和前面我们介绍的lcok的使用时相同的，都是
 tryfinally这个编程范式。写缓存则需要用到写锁，写锁的使用和读锁是类似的。这样看来，读写锁
 的使用还是非常简单的。
 
 如果你曾经使用过缓存的话，你应该知道使用缓存首先要解决缓存数据的初始化问题。缓存数据的
 初始化，可以此阿勇一次性加载的方式，也可以使用按需加载的方式。

  如果源头数据的数据量不大，就可以采用一次性加载的方式，这种方式最简单
  只需在应用启动的时候把源头数据查询出来，依次调用类似上面示例代码中的put方法就可以了
  
  如果源头数据量非常大，那么就需要按需加载了，按需加载也叫懒加载，指的是只有当应用查询
  缓存，并且数据不再缓存里的时候，才出发加载源头相关数据进行缓存的操作。下面你可以结合稳重
  示意图来看看如何利用readwritelock来实现缓存的按需加载。

   实现缓存的按需加载
   文中下面的这段代码实现了按需加载的功能，这里我们假设缓存的源头是数据库。需要注意的
   是，如果缓存中没有缓存目标对象，那么就需要从数据库中加载，然后写入缓存，写缓存需要用
   到写锁，所以在代码中，我们调用w.lock 来获取写锁。
   
   另外，还需要注意的是，在获取写锁之后，我们并没有直接去查询数据库，而是在代码
   重新验证了一次缓存中是否存在，再次验证如果还是不存在，我们采取查询数据库并更新本地缓存。
   为什么我们要再次验证呢?
   原因是在高并发下的场景，有可能会有多线程竞争写锁。假设缓存是空的，没有缓存任何东西，
   如果此时有三个线程T1T2T3同时调用get方法，并且参数可以也是相同的。那么它们
   会同事执行到代码，但此时只有一个线程能够获得写锁，假设是线程1，线程T1获取写锁
   之后查询数据库并更新缓存，最终释放写锁。此时线程T2和T3会再有一个线程能够获取写锁
   ，假设是T2，如果不采用再次验证的方式，此时T2会再次查询数据库。T2释放写锁之后
   ，T3也会再次查询一次数据库。而实际上线程T2已经把缓存的值设置好了，T2T3完全没有
   必要再次查询数据库。所以再次验证的方式，能够避免高并发场景下重复查询数据的问题。
   
   读写锁的升级与降级
   上面按需加载的示例代码中，在1获取读锁，在3释放读锁，
    锁升级。可以readwritelock并不支持这种升级。在上面的代码示例中，读锁还没有释放
    此时获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会被唤醒。
    锁的升级是不允许的，这个你一定要注意。
    
   不过，虽然锁的升级是不允许的，但是锁的降级确实允许的。
   ReentrantReadWriteLcol的官方示例，率做改动。
     获取读锁的时候线程还是持有写锁的，这种锁支持降级是支持的。
   总结 
   
   读写锁类似ReentrantLock,也支持公平模式和非公平模式。读锁和写锁都实现了lcok接口
   所以除了支持lock外，还支持trylock lockInterruptibyl等方法也都是支持的
   interrupty。但是有一点需要注意，那就是只有写锁支持条件变量，读锁是不支持条件变量的。
   读锁调用newCondition会抛出unsupportedOperationException
 
   今天我们用ReadWriteLock实现了一个简单的缓存，这个缓存虽然解决了缓存的初始化问题，
   但是没有解决缓存数据与源头数据的同步问题，这里的数据同步值得是保证存储数据和源头数据
   的一致性。解决数据同步问题的一个最简单的方案就是超时机制。所说义超市机制值得是加载进huanc
   的数据不是长久有效的，而是有实效的，当缓存的数据超时时候，也即是超时，这条
   在缓存中就失效了。而访问缓存中失效的数据，会触发缓存重新从源头把数据加载进缓存。
   
   当然也可以在源头数据发生变化时，快速反馈给缓存，但这个就依赖具体场景了。例如
   mysql作为数据源头，可以通过近实时解析binlog来识别数据是否发生了变化，如果发生了
   变化就将最新的数据推送给缓存。另外，还有一些方法采取的是数据库和缓存的双写方案。
   总之，具体采用哪种方法，还是要看应用的场景。
   
   课后思考


stamptedLock



18 StampedLock:有没有比读写锁更快的锁？

我们介绍了读写锁，学习完之后你应该已经知道“读写锁允许多个线程同时读共享变量
，适用于读多写少的场景”。那在读多写少的场景中，还有没有更快的技术方案呢
，还真有，java8这个版本里，提供了一种叫做StampedLock锁，它的性能就比读写锁还要好。

下面我们就来介绍一下StampedLock的使用方法、内部工作原理以及在使用过程中需要注意
的事项。

StamedLock支持三种锁模式
我们先来看看在使用上StampedLock和上一篇文章讲的ReadWriteLock有哪些区别。

ReadWriteLock支持两种模式:一种是读锁，一种是写锁。而StampedLock支持三种模式，
分别是：写锁、悲观读锁和乐观读。其中，写锁、悲观读锁的语义和ReadWriteLock的
写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁
锁，写锁和悲观锁是互斥的。不同的是：StampedLock里的写锁和悲观读锁加锁成功
之后，都会返回一个stamp；然后解锁的时候，需要传入这个stamp。相关代码

StampedLock的性能之所以比ReadWrite还要好，其关键是Stampedlock支持乐观
读的方式。ReadWriteLock支持多个线程同时读，但是当多个线程同时读的时候，所有的写
操作会被阻塞；而StampedLock提供的乐观读，是允许一个线程获取写锁的，也就是说不是
所有的写操作都是被阻塞。

注意这里，我们用的是乐观读这个词，而不是乐观读锁，是要提醒你，乐观读这个操作
是无锁的，所以相比较readWritelock的读锁，乐观读的性能更好一些。

文中下面这段代码是出自java sdk 官方示例，并略作了修改。在distanceFromOrigin()这个
方法汇总，首先通过调用tryOptimisticRead获取了一个stamp,这里的
tryOptimisticRead就是我们前面提到的乐观读。之后将共享变量X和Y读入方法的局部变量
中，不过需要注意的是，由于tryOptimisticRead是无锁的，所以共享变量X和Y读入方法
局部变量时，x和y有可能被其他线程修改了。因此最后读完之后，还需要再次验证一下是否
存在写操作，这个验证操作是通过调用validatestamp来实现的

在上面这个代码示例中，如果执行乐观读操作的期间，存在写操作，会把乐观读升级为悲观读
锁。这个做法挺合理的，否则你就需要在一个循环里反复执行乐观读，直到执行乐观读操作的
期间没有写操作 只有这样才能保证X和Y的正确性和一致性，而循环读会浪费大量的CPU
。升级为悲观读锁，代码简练且不易出错，减一你在具体时间时也采用这样的方法。

进一步理解乐观读

如果你曾经用过数据库的乐观锁，可能会发现StamepdLock的乐观读和数据库的乐观锁有异曲同工
之妙。的确是这样的，就拿我个人来说，我是先解除的数据库里的乐观锁，然后才解除的
Stamepedlock，我就觉得我前期数据库里乐观锁的学习对于后面理解stampedlock的乐观
读有很大帮助，所以这里有必要再介绍一下数据库里的乐观锁。

还记得我第一次使用数据库乐观锁的场景是这样的：在ERP的生产模块里，会有多个人通过
ERP系统提供的UI同时修改同一条生产订单，那如何保证生产订单数据是并发安全的呢？我采用
的方案就是乐观锁。


乐观锁的实现很简单，在生产订单的表productdoc里增加了一个数值型版本号字段version,
每次更新productdoc这个表的时候，都将version字段加1。生产订单的UI再
展示的时候，需要查询数据库，此时将这个version字段和其他业务字段一起返回给生产订单UI
。假设用户查询的生产订单的ID=777，那么SQL类似

用户在生产订单UI执行保持操作的时候，后台利用SQL语句更新生产订单，此处我们假设该条生产
订单的version=9。


如果这条sql语句执行成功并且返回的条数等于1，那么说明从生产订单UI执行查询超到
执行保持操作期间，没有其他人修改过这条数据。因为如果这期间其他人修改过这条数据，那么
版本号字段一定会大于9。

你会发现数据量的乐观锁，查询的时候需要把version字段查出来，更新的时候要利用
version字段做验证。这个version字段就类似于stampedlock里面的stamp。这样对比着
看，相信你会更容易理解stampedlock里乐观读的用法。

stampedlock使用注意事项

对于读多写少的场景StampedLock性能很好，简单的应用场景基本上可以替代
ReadWriteLock,但是StamepdLock的功能仅仅是ReadWritelock的子集，在使用的时候
，还是有几个地方需要注意一下。

StamedLock在命名上并没有增加REENTRANT，想必你已经猜到stampedLock应该是不可
重入的。事实上，的确是这样的，stampedlock不支持重入。这个是在使用中必须要特别
注意的。

另外，stampedlock的悲观读锁、写锁多步支持条件变量，这个也需要你注意。

还有一点需要特别注意，那就是：如果线程阻塞在stampedlock的readlock或者
writelock时，此时调用该阻塞线程的interrupt方法，会导致cpu飙升。例如下面的
代码中，线程T1获取写锁之后将自己阻塞，线程T2尝试获取悲观读锁，也会阻塞；如果此时
调用线程T2DE INTERRUPT方法来终端线程T2的话，你会发现线程T2所在的CPU会飙升到100

所以，使用stampedlock一定不要调用终端操作，如果需要支持中断功能，一定使用可中断
的悲观读锁readlockInterruptibly和写锁writeLockInterruptibly()。这个规则一定
要记清楚。

总结
stampedlock的使用看上去有点复杂，但是如果你能理解乐观锁背后的原理，使用起来还是
比较流畅的。减一你认真揣摩java的官方示例，这个实例基本上就是一个最佳实践。我们把精简后。


课后思考
StampedLock支持锁的降级通过tryConvertToReadLock方法实现和升级通过
tryConvertToWriteLock方法实现，但是建议你要慎重使用。下面的代码也源自java的
官方示例，我们仅仅做了一点修改，因此了一个BUG，你来看看BUG处在哪里把




19 | CountDownLatch 和 CyclicBarrier :如何让多线程步调一致？

前几天老板突然匆匆忙忙过来，说队长系统最近越来越慢了，能不能快速优化一下。我了解了
队长系统的业务后，发现还是挺简单的，用户通过在线商城下单，会生成电子订单，保持在订单库
之后物流会生成派送单给用户发货，派送点保持在派送单库。为了防止漏拍送或者重复
派送，对账系统每天还会校验释放存在 异常订单。

对账系统的处理逻辑很简单，你可以参考下面的对账系统流程图。目前对账系统的处理逻辑是
首先查询订单，然后查询派送单，之后对比订单和派送单，将差异谢雨差异库。
对账系统的代码抽象之后，也很简单，核心代码如下，就是在一个单线程里面循环查询订单、
派送单，然后执行对账，最后将写入差异库。

利用并行优化对账系统
老板要我优化性能，那我就首先要找到这个对账系统的瓶颈所在。
目前的对账系统，由于订单量和派送单量巨大，所以查询未对账订单getPOrders和查询派送单
getdorders相对较慢，那有没有办法快速优化一下呢？目前对账系统是但现场执行的
，图形化后是下图这个样子。对于串行化的系统，优化性能首先想到的是能否利用多线程并行处理。

所以，这里你应该能够看出来这个对账系统里的瓶颈：查询未对账订单getporders和查询
派送单getdorders释放可以并行处理呢，显然是可以的，因为这两个操作并没有先后顺序
的依赖。这两个最好是的操作并行之后，执行过程如下图所示。对比一下单线程的执行示意图
，你会发现同等时间里，并行执行的吞吐量近乎单线程的2倍，优化效果还是相对明显的。

思路有了，下面我们再来看看如何用代码实现。下面的代码中，我们创建了两个线程T1和T2，
并行查询未对账订单getpoders和查询派送单getdorders这两个操作。在住
线程中执行对账操作check和差异写入save两个操作。不过需要注意的是：主线程需要等待
线程T1和T2执行完才能执行check和save这两个操作，为此我们通过调用
T1。join和t2.join来实现等待，当T1和T2线程推出时，调用T1。join和T2。join的zhuxianc就会从
阻塞态被唤醒，从而之后之后的撤ck和save

用CountDownLatch实现线程等待
经过上面的优化之后，基本上可以跟老板汇报收工了，但是还是有点美中不足，相信你也发现了
while循环里面每次多会创建新的线程，而创建线程可是个耗时的操作。所以最后是创建出来的线程
能够循环利用，估计这时你已经想到线程池了，是的，线程池就能解决这个问题。

而下面的代码就是用线程池优化后的：我们首先创建了一个固定大小为2的线程池，之后
while循环里面重复利用。一切上看去都很顺利，但是有个问题好像无解了,那就是主线程如何知道
getPoRDERhe getDorder两个操作什么时候执行完。前面主线程通过调用线程T1和T2的join
方法来等待T1和T2推出，但是在线程池的方案里，线程根本就不会推出，所以join方法已经失效了。

那如何解决这个问题呢？你可以开动脑经想出很多办法，最直接的办法就是弄一个计数器，初始
值设置成2，当执行完pos=getPorderS,这个操作之后将计数器减一，执行完DOS=getDorder之后
也将计数器减一，在主线程里，等待计数器等于0；当计数器等于0时，说明这两个查询插座执行完了。
等待计数器等于0其实就是一个条件变量，用管程实现起来也很简单。

不过我并不减一你在实际项目中去实现上面的方案，因为java并发包里已经提供给了实现类似
功能的工具类:countDownLath,我们直接使用就可以了
我们创建了一个CountDownLatch计数器初始值等于2，之后在线程操作里调用 latch.CountDown
主线程我们通过awati来等待等于0

进一步优化性能
经过上面的优化之后，长处一口气，终于可以交付了。不过在交付之前还需要再次审视一番，还有么有
优化的余地，仔细看还是有的。
前面我们

用CyclicBarrier实现线程同步
一是线程T1和T2要做到步调一致，另一个是要能够通知到线程T3。
你依然可以利用一个计数器来解决这两个难点，计数器初始化为2，线程T1和T2生产完一条
数据都将计数器减一，如果计数器大于0则线程T1或者T2等待。如果计数器等于0，则通知
T3，并唤醒等待的线程T1或者T2，与此同时，将计数器充值未2，这样线程T1和线程T2
生产下一条数据的时候就可以继续使用这个计数器了。

同样，还是建议你不要在实际项目中这么做，因为java并发包里也已经提供了相关的工具类
CYCLICbARRIE。在下面的代码中，我们首先创建了一个计数器初始值为2的cyclicBarrir
你需要注意的是创建cyclicBarrir的时候，我们还传入了一个回调函数，当计数器见到0的时候
会调用这个回调函数。

线程T1负责查询订单，当查出一条时，调用barrier,await来讲计数器减一，同事等等
计数器变为0；线程T2负责查询派送单，当查出一条时，也调用barrier.await来讲计数器
减一，同时等等计数器编程0；当1和2都调用了await的时候，计数器
会见到0，此时1和2 就可以执行下一条语句了，同时会调用barrier的回调函数来执行对账操作o

非常值得一提的是，cychlicbarrier的计数器有自动充值的功能，当减到0的时候，会自动重置
你的设置的初始值。这个功能用起来实在是太方便了。

总结
CountDownLathc和cyclicBarrir是java并发包提供的两个非常易用的线程同步工具，
这两个工具类用法的区别在这里还是有必要强调一下:CountDownLathc主要用来解决一个线程
等待讴歌线程的场景，可以类比领队等待游客。而CyclicBarrir是一组线程之间互相等待，更像不离不弃。
除此之外，countDownLatch的计数器是不能循环利用的，也就是说一旦计数器见到0，再有线程调用await
该线程会直接通过。但CyclicBarrier的计数器是可以循环利用的，而且具备自动重置的功能，一旦计数器见到0
会自动重置到你设置的初始值。除此之外，cyclicbarrier还可以这只回调函数，可以说是功能丰富。
线程池提供了Future特性，我们也可以利用future
特性来实现线程之间的等待，这个我们也会详细介绍



20 并发容器:都有哪些坑需要我们填

Java并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。

Java1.5 之前提供的同步容器虽然也能保证线程安全，但是性能很差，而Java5之后
提供的并发容器在性能方便则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比
二者来学习这部分的内容。

同步容器以其注意事项
Java中的容器主要可以分为四个大类：分别是List Map Set Queue,但并不是所有的
Java容器都是线程安全的。例如，我们常用的arraylist hashmap就不是线程安全的。在
介绍线程安全的容器之前，我们先思考这样一个问题：如果将非线程安全的容器编程线程安全
的容器？

在前面我们讲过实现死了其实很简单，只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。


下面我们就以Arraylist为例，我们如何将它变成线程安全的。在下面的代码中
SafeArrayList内部持有一个arraylist的实例c，所有访问c的方法我们都增加了
synchronized关键字，需要注意的是我们还增加了一个addIfNotExitst方法，这个方法也是用
synchronized来保证原子性。

看到这里，你可能会举一反三，然后想到：所有非线程安全的类是不是都可以用这种包装的
方式来实现线程安全呢？其实这一点不止你想到了，javasdk的开发人员也想到了，所以他们
在collections这个类中还提供了一套完备的包装类，比如下面的示例代码中，分别把
arraylist hashset hashmap包装成了线程安全的list set map

我们曾经多次强调，组合操作需要注意竞态条件问题，例如上面提到的，addIfNotExist方法
就包含组合操作。组合操作往往隐藏着静态条件问题，即便每个操作都能保证原子性，也并不能
保证组合操作的原子性，这个一定要注意。

在容器领域一个容易被忽略的坑是用迭代器变量容器，例如在下面的代码中，通过迭代器
遍历容器list，对每个元素调用foo方法，这就存在并发问题，这些组合的操作不具备原子性。


而正确的做法是下面这样，锁住list之后再执行遍历操作。如果你查看Collections内部的包装
类源码，你会发现包装类的公共方法锁的是对象的this，其实就是我们这里的list，所以锁住
list绝对是线程安全的。
上面我们提到的这些经过包装后线程安全容器，都是基于synchronized这个同步关键字实现的
，所以也被称为同步容器。java提供的同步容器还有vector、stack和hashtable,这三个
容器不是基于包装类的实现，但同样是基于synchronized实现，对着三个容器的遍历，
同样要加锁保证互斥。

并发容器及其注意事项
java在1。5版本之前所谓的线程安全的容器，主要指的就是同步容器。不过同步容器有个最大
的问题，那就是性能差，所有方法都用synchronized来保证互斥，串行度太高了。因此，java
在1。5及之后的版本提供了性能更高的容器，我们一般称为并发容器。

并发容器虽然数量非常多，但依然是前面我们提到的四大类：list map set queue，下面
的并发容器关系图，基本上把我们经常用的容器都覆盖到了。

List:
CopyOnWriteArrayList

Map
ConcurrentHashMap
ConcurrentSikeListMap

Set
ConcurrentSkipListSet
CopyOnWriteArraySet

Queue
I.BlockingDeque
II.LinkedBlockingDeque

I.BlockingQueue
ArrayBlockingQueue
LinkedBlockingQueue
SynchronousQueue
LinkedTransferQueue
PriorityBlockingQueue
DelayQueue


I.ConcurrentLinkedQueue
I.ConcurrentLinkedDeque

鉴于并发容器的数量太多，再加上篇幅限制，所以我并不会详细介绍他们的用法，只是把关键点介绍一下

（一）List
 
 List里面只有一个实现就是CopyOnWriteArrayList。CopyOnWrite,顾名思义就是写的
 时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁。
 那CopyOnWriteArrayList的实现原理是怎样的呢？下面我们就来简单介绍一下。
 
 CopyOnWriteArrayList内部维护了一个数组，成员变量array就指向这个内部数组，所有的
读操作都是基于array进行的，如下图所示，迭代器iterator遍历的就是array数组。

如果在遍历array的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList是如何
处理的呢？CopyOnWriteArrayList会将array复制一份，然后在新复制处理的数组上执行
增加元素的操作，执行完之后再将array指向这个新的数组。通过下图你可以看到，读写是可以
并行的，遍历操作一直都是基于原array执行，而写操作则是基于新array进行。

使用CopyOnWriteArrayList需要注意的坑主要有两个方面。一个是应用场景，
CopyOnWriteArrayList仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致
。例如上面的例子中，写入的新元素应不能立刻被遍历到。另一个需要注意的是，
CopyOnWriteArrayList迭代器是只读的，不支持增删改。因为迭代器遍历的仅仅是一个
快照，而对快照进行增删改是没有意义的。

二Map
Map接口的两个实现是ConcurrentHashMap和ConcurrentSkipListMap,他们从应用的
角度来看，主要区别在于ConcurrentHashMap的key是无须的，而
ConcurrentSkipListMap的key是有序的。所以如果你需要保证key的顺序，就只能使用
ConcurrentSkipListMap.

使用ConcurrentHashMap和ConcurrentSikpListMap需要注意的地方是，他们的key和
value都不能为空，否则会抛出NullPointerException这个运行时异常。下面这个表格总结
了Map相关的实现类对于key和value的要求，你可以对比学习。

ConcurrentSkipListMap里面的SkipList本身就是一种数据结构，中文一般都翻译为跳表
.跳表插入删除查询操作平均的时间复杂度是 O log n,理论上和并发线程没有关系
，所以在并发度非常高的情况下，若你对ConcurrentHashMap的性能还不满意，可以尝试
一下ConcurrentSkipListMap.

（三）Set
Set接口的两个实现是CopyOnWriteArraySet和ConcurrentSkipListSet,使用场景可以参考
前面讲述的CopyOnWriteArrayList和ConcurrentSkipListMap,他们的原理都是一样
的，这里就不再赘述了。

(四)Queue
Java并发包里面Queue这类并发容器是最复杂的，你可以从以下两个维度来分类。一个维度是
阻塞与非阻塞，所谓阻塞指的是当队列已满时，入队操作阻塞；当队列已空时，出兑操作阻塞
。另一个维度是单端与双端，单端指的是只能队尾入队，对首出队；而双端指的是对首队尾
皆可入队出队。java并发包里阻塞队列都用blocking关键字表示，单端队列使用queue标识
双端队列使用Deque标识。

这两个维度组合后，可以将Queue细分为四大类，分别是

1.单端阻塞队列：其实先有ArrayBlockingQueue、LinkedBlockingQueue
SynchronousQueue、LinkedTransferQueue、PriorityBlockingQueue和DelayQueue
内部一般会持有一个队列，这个队列可以是数组也可以是
链表 其实现是  LinedBlockingQueue设置还可以不持有队列  其实现是
SynchronousQueue,此时生产者线程的入队操作必须等待消费者线程的出队操作。而
LinkedTransferQueue融合LinedBlockingQueue和SynchronousQueue的功能，性能
比LinkedBlockingQueue更好，PriorityBlockingQueue支持按照优先级出队
；DelayQueue支持延时出队。

2.双端阻塞队列：其实现实LinedBlockingDeque.

3.单端非阻塞队列：其实现实ConcurrentLinkedQueue
4.双端非阻塞队列:其实现是ConcureentLinkedDeque
另外，使用队列时，需要格外注意队列释放支持有界。实际工作中，一般不建议使用无界队列，因为
数据量大了之后很容易导致OOM。上面我们提到的这些Queue中，只有ArrayBlockingqueue和
LinkedBlockingQueue是支持有界的，所以在使用其他无界队列时，一定要充分考虑是否
存在导致OOM的隐患。

总结
Java并发容器的内容很多，但鉴于篇幅有限，我们只是对一些关键点进行了梳理和介绍。

而在实际工作中，你不单要清楚每种容器的特性，还要能选对容器，这才是关键，至于每种容器
的用法，用的时候看一下API说明就可以了，这种容器的使用都不难。在文中，我们甚至都
没有介绍java容器的快速失败机制 fail fast，原因就在于当你选对容器的时候，根本不会
触发它。

课后思考
线上系统CPU突然飙升，你怀疑有同学在并发场景里使用了hashmap，因为在8之前
版本里并发执行put可能到最后CPU100，你觉得该如何验证你的猜测呢



21 |原子类:无锁工具类的典范
  前面我们多次提到一个累加器的例子，示例代码如下。在这个例子中，add10K这个方法不是
线程安全的，问题就处在变量count的可见性和count+1的原子性上。可见性问题可以
用volatile来解决，而原子性问题我们前面一直都是采用的互斥锁方案。

其实对于简单的原子性问题，还有一种无锁方案。javasdk并发包将这种无锁方案封装提炼
之后，实现了一系列的原子类。不过，在深入介绍原子类的实现之前，我们先看看如何利用原子类
解决累加器问题，这样你会对原子类有个初步认识。

在下面的代码中，我们将原来的long类型变量count替换为了原子类atomicLong原来的
count+=1替换成了count.getAndIncrement,仅需要这两处简单的改动就能使add
方法编程线程安全的，原子类的使用还是挺简单的。

无锁方案相对于互斥锁方案，最大的好处就是性能。互斥锁方法为了保护互斥性，需要执行加锁
，解锁操作，而加锁、解锁操作本身就消耗性能；同事拿不到锁的线程还会进入阻塞状态，
进而触发线程切换，线程切换对性能的消耗也很大。相比之下，无锁方案则完全没有加锁、解锁
的性能消耗，同事还能保证互斥性，既解决了问题，又没有带来新的问题，可谓绝佳方案。
那它是如何做到的呢

无锁方案的实现原理
其实原子类性能高的秘密很简单，硬件支持而已。CPU为了解决并发问题，提供了CAS执行
。CAS指令包含3个参数：共享变量的内存地址A、用于比较的值B和共享变量的新值C；并且只有
当内存中A处的值等于B时，才能将内存中地址A处的值更新为新值C。作为一条CPU指令，CAS指令本书
是能够保证原子性的。

你可以通过下面CAS指令的模拟代码来理解CAS的工作原理。下面的模拟程序中有两个参数
，一个是期望值expect，另一个是需要写入的新值newValue，只有当目前count的值和
期望值expect相等时，才会将count更新为newValue

你仔细地再次思考一下这句话。只有当目前count的值和期望值 expect 相等时，才会将
count更新为newValue

对于前面提到的累加器的例子，count+=1的一个核心问题是：基于内存中count的当前
值A计算出来的count+1为A+1，在将A+1写入内存的时候，很可能此时内存中count
已被其他线程更新过了，这样就会导致错误地覆盖其他线程写入的值。
也就是说，只有当内存中count的值等于期望值A时，才能将内存中count的值更新
为计算结果A+1，这不就是CAS的语义吗

使用CAS来解决并发问题，一般都会伴随着自旋，而所谓自旋，其实就是循环尝试。例如，
实现一个线程安全的count+1操作，cas+自旋的实现方案如下所示，首先计算
newValue=count+1 ,如果cascount new Value返回的值不等于count,则意味着线程
在执行完代码1处之后，执行代码2处之前，count的值被其他线程更新过。那此时该怎么处理
呢？可以采用自旋方案，就像下面代码中国展示的，可以重新读count的值来计算
newValue并尝试再次更新直到成功。

通过上面的示例代码，相比你已经发现了，CAS这种无锁方案，完全没有加锁，解锁操作，即便
两个线程完全同事执行addOne方法，也不会有线程被阻塞，所以相对于互斥锁方案来说，信工
好了很多。

但是在CAS方案中，有一个问题可能会常被你忽略，那就是ABA的问题，什么时候ABA问题呢

前面我们提到如果cas返回的值不等于count，意味着线程在执行完代码
1处之后，执行代码2处之前，count的值被其他线程更新过，那如果
cas返回的值等于count，是否就能够认为count的值北邮被其他线程更新过呢
？显然不是的，假设count原本是A，线程T1在执行完代码1处之后，执行代码2处之前，
有可能count被线程T2更新成了B，之后又被T3更新回了A，这样线程T1虽然看到的
一直是A，但是其他已经被其他线程更新偶了，这就是ABA问题。

可能大多数情况下我们并不关心ABA问题，例如数值的原子递增，但也不能所有情况下都不关心
，例如原子化的更新更对很可能就需要关心aba问题，因为两个A虽然相等，但是第二个
A的属性可能已经发生变化了。所以在使用CAS方案的时候，一定要先check一下。

看java如何实现原子化的count+=1
在本网开始部分，我们使用原子类AtomicLong的getAndIncrement方法替代了count+=1
，从而实现了线程安全。原子类AtomicLong的getAndIncrement方法内部就是基于
CAS实现的，下面我们来看看java是如何使用CAS来实现原子化的count+=1的。

在8版本中，getAndIncrement方法会转调unsafe,getAndAddLong方法。这里
this和valueOffset两个参数可以唯一确定共享变量的内存地址。

unsafe。getAndAddLong方法的源码如下，该方法首会在内存中读取共享变量的值，之后
循环调用compareAndSwapLong方法来尝试设置共享变量的值，知道成功为止。
compareAndSwapLong 是一个native方法，只有当内存中共享变量的值等于expected
时，才会将共享变量的值更为x,并且返回true否则返回false。
compareAndSwapLong的语义和CAS指令的语义的差别仅仅是返回值不同而已。

另外，需要你注意的是，getAndAddLong方法的实现，基本上就是CAS使用的经典范例。
所以请你再次体会下面这段抽象后的代码片段，它在很多无锁程序中经常出现。java提供
的原子类里面CAS一般被实现我compareadnset，compareANDSET的语义和CAS指令
的语义的差别仅仅是返回值不同而已，compareAndSet里面如果更新成功，则返回
true否则返回false

原子类概述

Java SDK并发包里提供的原子类内容很丰富，我们可以将他们分为五个类别：原子化的基本
数据类型、原子化的对象引用类型、原子化数组、原子化对象属性更新器和原子化的累加器。

这五个类别提供的方法基本上市相似的，并且每个类别都有若干原子类，你可以通通过下面的原子类
组成概览图来获得一个全局的印象。下面我们详细解答这五个类别



1.原子化的基本数据类型
相关的实现有 AtomicBoolean AtomicInterger 和 AtomicLong 提供的方法主要有以下这些
，详情你可以参考SDK的源代码，都很简单，这里就不详细介绍了。

2.原子化的对象引用类型
相关实现有AtomicReference AtomicStampedReference和
AtomicMarkableReference 利用它们可以实现对象引用的原子化更新。AtomicReference
提供的方法和原子化的基本数据类型差不多，这里不再赘述。不过需要注意的是，对象 引用的
更新需要重点关注ABA问题，AtomicStampedReference和 AtomicMarkableReference
这两个原子类可以解决ABA问题。

解决ABA问题的思路其实很简单，增加一个版本号维度就可以了，这个和我们在
介绍的乐观锁机制很类似，每次执行CAS操作，
附加再更新 一个版本号，只要保证版本号是递增的，那么即使A变成B之后再变回A
版本号也不会变回来。AtomicStampedReference实现的CAS方法就增加了版本号参数，
方法签名如下


AtomicMarkableReference的实现机制则更简单，将版本号简化成了一个博哦了安，方法签名如下

3.原子化数组
相关实现有 AtomicIntergerArray AtomicLongArray和AtomicReferenceArray，利用
这些原子类，我们可以原子化地更新数组里面的每一个元素。这些类提供的方法和原子化的基本
数据类型的区别仅仅是：每个方法多了一个数组的索引参数，所以这里也不再赘述了。

4.原子化对象属性更新器
相关实现有AtomicInterFieldUpdater、AtomicLongFiledUpdater和
AtomicReferenceFiledUpdater,利用它们可以原子化地更新对象的属性，这三个方法都是
利用反射机制实现的，创建更新器的方法如下：
需要注意的是，对象属性必须是volatile类型的，只有这样才能保证可见性；如果对象属性不是
volatile类型的，newUpdater方法会抛出IllegalArgumentException这个运行时异常。

你会发现newUpdater 的方法参数只有类的信息，没有对象的引用，而更新对象的属性，一定
需要对象的引用，那这个参数是在哪里传入的呢？实在原子操作的方法参数传入的。例如
compareAndSet这个原子操作，相比原子化的基本数据类型多了一个对象引用obj。原子
化对象属性更新器相关的方法，相比原子化的基本数据类型仅仅是多了对象引用参数，所以
这里也不再赘述了。

5.原子化的累加器
DoublAccumulator doubleAdder LongAccumulator 和longAdder,这四个类仅仅
用来执行累加操作，相比原子化的基本数据类型，速度更快，但是不支持compareAdnSet
方法。如果你仅仅需要累加操作，使用原子化的累加机器性能会更好。

总结

无锁方案相对于互斥锁方案，优点非常多，首先性能好，其次是基本不会出现死锁问题 但可能
出现ji e和活锁问题，因为自旋会反复重试。java提供的原子类大部分都实现了
compareAndSet方法，基于compareAndSet方法，你可以构建自己的无锁数据结构，
但是建议你不要这样做，这个工作最好还是让大师们去完成，原因是无锁算法没你想想的那么简单
。
java提供的原子类能够解决一切简单的原子性问题，但你可能会发现，上面我所有原子类的
方法都是针对一个共享变量的，如果你需要解决多个变量的原子性问题，减一还是使用互斥锁
方案。原子类虽好，但使用要慎之又慎。





22 | Executor与线程池:如何创建正确的线程池
虽然在java语言中创建线程看上去就像创建一个对象一样简单，只需要new Thread就可以
了，但实际上创建线程远不是创建一个对象那么简单。创建对象，仅仅是在JVM的堆里分配
一块内存而已。而创建一个线程，却需要调用操作系统内核API，然后操作系统要我线程
分配以系列的资源，这个成本就很高了，所以线程是一个重量级的对象，应该避免频繁创建和
销毁。

那如何避免呢？应对方案估计你已经知道了，那就是线程池。

线程池的需求是如此普遍，所以JAVA sdk并发包自然也少不了它。但是很多人在初次接触并发包
里线程池相关的工具类时，多少会都有点蒙，不知道该从哪里入手，我觉得根本原因在于
线程池和一般意义上的池化资源是不同的。一般意义上的池化资源，都是下面这样，当你需要
资源的时候就调用acquire方法来申请资源，用完之后就调用release释放资源。若你带着
这个固有模型来看并发包里线程池相关的工具类时，会很遗憾的发现他们完全匹配步上，
java提供的线程池里面压根就没申请现场和释放现场的方法。

线程池是一种生产者 消费者模式
为什么线程池没有采用一般意义上池化资源的设计方法呢？如果线程池采用一般意义上池化资源
的设计方法，应该是下面示例代码这样。你可以来思考一下，假设我们获取到一个空闲线程
T1，然后改如何使T1呢？你期望的可能使这样：通过调用T1的execute方法，传入一个
runnable对象来执行具体业务逻辑，就像通过构造函数thread创建线程一样。
可惜的是，你翻遍thread对象的所有方法，都不存在类似execute
这样的公共方法。

所以，线程池的设计，没有办法直接采用一般意义上的池化资源的设计方法。那线程池该如何设计
呢？目前业界线程池的设计，普遍采用的都是生产者-消费者模式。线程池的使用方式生产
者，线程池本书是消费者。在下面的示例代码中，我们创建了 一个非常简单的线程池
MythreadPool，你可以通过它来理解线程池的工作原理。
在MyThreadPool的内部，我们维护了一个阻塞队列workQueue和一组工作线程，工作线程
的个数由构造函数中的poolsize来指定。用户通过调用execute方法来提交Runnable
任务，execute方法的内部实现仅仅是将任务加入到workQueue中。MyThreadPool内部
维护的工作线程会消费workQueue中的任务并执行任务，相关的代码就是代码1处的while
循环。线程池主要的工作原理就这些，是不是还挺简单的。

如何使用Java中的线程池
java并发包里提供的线程池，远比我们上面的示例代码强大得多，当然也复杂得多。java提供
的线程池相关的工具类中，最核心的是ThreadPoolExecutor，通过名字你也能看出来，它
强调的是Executor，而不是一般意义上的池化资源。

ThreadPoolExecutor的构造函数非常复杂，如下面代码所示，这个最完备的构造函数有7个
参数。
下面我们介绍这些参数的意义，你可以把线程池类比为一个项目组，而线程就是项目组的成员。

corePoolSize:表示线程池保有的最小线程数。有些项目很闲，但是也不能把人都撤了，
至少要留corePoolSize个人坚守阵地。

maximumPoolSize：表示线程池创建的最大线程数。当项目很忙时，就需要加入，但是也
不能无限制地加，最多就加到maximumPoolSize个人。当项目闲下来时，就要撤人了
，最多能撤到corePoolSize个人。

keepAliveTime&unit：上面提到项目根据忙闲来增减人员，那在编程实践里，如何定义
忙和闲呢？很简单，一个线程如归哦在一段时间内，都没有执行任务，说明很闲，
keepAliveTime和unit这么久，而且线程池的线程数大于corePoolSize,
那么这个空闲的线程就要被回收了。

workQueue:工作队列，和上面示例代码的工作队列同义。

threadFactory：通过这个参数你可以自定义如何创建线程，例如你可以给线程指定一个有意义
的名字。

handler:通过这个参数你可以自定义任务的拒绝策略。如果线程池中所有的线程都在忙碌
，并且工作队列也满了(前提是工作队列时有界队列)，那么此时提交任务，线程池就会
拒绝接受。值域拒绝的策略，你可以通过handler这个参数来指定。ThreadPoolExecutor
已经提供了以下4种策略。
CallerRunsPolicy:提交任务的线程自己去执行该任务。
AbortPolicy:默认的拒绝策略，会throws RejectedExecutionException
DiscardPolicy:直接丢弃任务，没有任何异常抛出。
DicardOldestPolicy:丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后
把新任务加入到工作队列。

Java在1。6版本还增加了 allowCoreThreadTimeOut方法，它可以让所有
线程都支持超时，这意味着如果项目很闲，就会将项目组的成员都撤走。

使用线程池要注意些什么
考虑到ThreadPoolExecuto的构造函数实在是有些复杂，所以java并发包里提供了一个线程
池的静态工厂类Executors,利用Executors你可以快速创建线程池。不过目前大厂的编码
规范中基本上都不建议使用Executors了，所以这里我就不再花篇幅介绍了。

不建议使用Executors的最重要的原因是：Executors提供的很多方法默认使用的都是无界的
LinkedBlockingQueue,高负载情境下，无界队列很容易导致OOM，而OOM会导致所有
请求都无法处理，这是致命问题。所以强烈建议使用有界队列。

使用有界队列，当任务过多时，线程池会触发执行拒绝策略，线程池默认的解决策略会throw
RejectedExecutionException这是个运行时异常，对于运行时异常编译器并不强制catch
它，所以开发人员容易忽略。因此默认拒绝策略要慎重使用。如果线程池处理的任务非常重要
，建议自定义自己的拒绝策略；并且在实际工作中，自定义的拒绝策略往往和降级策略配合使用。

使用线程池，还要注意异常处理的问题，例如通过ThreadPoolExecutor对象的execute方法
提交任务时，如果任务在执行的过程中出现运行时异常，会导致执行任务的线程终止；不过
，最致命的是任务虽然异常了，但是你却获取不到任何通知，这会让你误以为任务都执行得
很张晨。虽然线程池提供了很多用于异常处理的方法，但是最稳妥和简单的方案还是捕获所有
异常并按需处理，你可以参考下面的示例代码。

总结

线程池在java并发编程领域非常重要，很多大厂的编码规范都要求必须通过线程池来管理线程。
线程池和普通的池化资源很很大不同，线程池实际上是生产者消费者模式的一种实现
理解生产者 消费者模式是理解线程池的关键所在。

创建线程池设计合适的线程数非常重要，



23 |Future:如何用多线程实现最优的烧水泡茶程序

在上一篇中我们详细介绍了
如何创建正确的线程池，那创建完线程池，我们改如何使用呢，在上一篇文章中，我们仅仅介绍
了ThreadPoolExceutor的void execute方法，利用这个方法
虽然可以提交任务，但是却没有办法获取任务的执行结果execute方法没有返回值。而
很多场景下，我们有都是需要获取任务的执行结果的。那ThreadPoolExecutor是否提供了相关
功能呢？必须的，那么重要的功能当然需要提供了。

下面我们就来介绍一下使用ThreadPoolExecutor的时候，如何获取任务执行结果。

如何获取任务执行结果
Java通过ThreadPoolExecutro提供的三个submit方法和一个FutureTask工具类来支持获得
任务执行结果的需求。下面我们先来介绍这三个submit方法，这三个方法的方法签名
如下

你会发现他们的返回值都是Future接口，Future接口有5个方法，我都列在
 


 
 我们详细介绍了如何创建正确的线程池,那创建完线程池,我们该如何使用呢
 在上一篇文章中,我们仅仅介绍了ThreadPoolExecutor的void
 execute(Runnable command)方法,利用这个方法虽然可以提交热舞,但
 是却没有办法获得任务的执行结果execute方法没有返回值.而很多场景
 下,我们又都是需要获取任务的执行结果的.那threadPoolExecutor是否提
 供了相关功能呢?必须的,这么重要的功能当然需要提供了.
 下面我们就来介绍一下使用ThreadPoolExecutor的时候,如何获取任务执行
 结果.
 
 如何获取任务执行结果.
 Java通过ThreadPoolExecutor提供的三个submit方法和一个
 FutureTask工具类来支持获得任务执行结果的需求.下面我们先来介绍这三个
 submit方法,这三个方法的方法签名如下.
 Future submit
 Future submit callble task
 Future submit Runable task result
 你会发现他们的返回值都是Future接口,Future接口有5个方法,我都列在
 下面了,他们分别是需要任务的方法cancel,判断任务是否已取消的方法
 isCancelled 判断任务是否已结果的方法isDone以及2个获取任务执行
 结果的get 和get timeout unit 其中最后一个gettimeout unit 支持
 超时机制.通过future接口的这5个方法你会发现,我们提交的任务不但能够
 获取任务执行结果,还可以取消任务.不过需要注意的是:这两个get方法
 都是阻塞式的,如果被调用的时候,任务还没有执行完,那么调用get方法
 的线程会阻塞,知道任务执行完才会被唤醒.
 boolean cancel
 boolean isCancelled
 isDone
 get
 get timeout timeunit
 
 
 这三个submit方法之间的区别在于方法参数不同,下面我们简要介绍一下.
 
 1.提交runnable任务submit 这个方法的参数是一个
 runnbale接口,runnable接口的run方法是没有返回值的,所以
 submit这个方法返回的future仅可以用来断言任务已
 经结束了,类易于threadjoin
 
 2.提交callbale任务的submit 这个方法的参数是一个callable接口,他只有一个
 call方法,并且这个方法是有返回值的,所以这个方法返回的futrue对象可以通过调用其get
 方法来获取任务的执行结果
 
 3.提交runnable任务以及结果引用submit
 这个方法很有意思,假设这个方法返回的future对象是f
 f.get返回的值就是传给submit方法的参数result.这个方法该怎么用
 呢 下面这段示例代码展示了它的经典用法.需要你注意的是Runnable接口
 实现类tas声明了一个有参数构造函数task创建task
 对象的时候传入了result对象,这样就能在类task的run方法中对
 result进行各种操作了.result相当于主线程和子线程之间的桥梁.通过他
 珠子线程可以共享数据.
 
 下面我们来介绍futuretask工具类.前面我们提到的future是一个接口
 而futuretask是一个实实在在的工具类,这个工具类有两个构造函数,他们的
 参数和前面介绍的submit方法类似,所以这里我就不再赘述了.
 futuretask
 futuretask runnable
 那如何使用futuretask呢 其实很简单,futuretask实现了runnable和
 futrue接口,由于实现了runnable接口所以可以讲futuretask对象作为
 任务提交给threadpoolexecutor去执行,也可以直接呗thread执行,又因为
 实现了future接口,所以也能用来获得任务的执行结果.下面的实例代码是
 将futuretask对象提交给threadpoolexecutor去执行.
 
 FutureTask对象直接被thread执行的实例代码如下所示.相信你已经发现
 了,立勇futuretask对象可以很容易获取子线程的执行结果.
 
 实现最优的烧水泡茶程序
 记得以前初中语文课文里有一篇著名数学家华罗庚先生的文章统筹方法
 这篇文章里介绍了一个烧水泡茶的例子,稳重提到最优的工序应该是下面这样.
 
 下面我们用程序来模拟一下这个最优工序.我们专栏签名曾经提到,并发变成
 可以总结为三个核心问题:分工同步和互斥.编写并发程序,首先要做的就是
 分工,所以分工值得是如何高效地拆解任务并分配给线程.对于烧水泡茶这个
 程序,一种最优的分工方法可以是下图所示的这样:用两个线程T1 T2来
 完成烧水泡茶程序,T1负责洗水壶 烧开水 泡茶这三刀工序,T2负责洗茶胡
 洗茶杯 那茶叶三刀工序,其中T1在执行泡茶这道工序时需要等待T2完成
 拿茶叶的工序.对于T1的这个等待动作,你应该可以相处很多种办法,例如
 threadjoin countDownlatch 甚至苏塞队列都可以解决,不过今天我们
 用future特性来实现

首先我们创建了两个futuretask 
 
 
 总结
 利用java并发并提供的future可以很容易获得一部任务的执行结果,无论异步
 任务是通过线程池 threadpoolexecuor执行的,还是通过手工创建子线程
 来执行的.future可以类比为显示世界里的提货单,比如去蛋糕店订生日蛋糕
 ,蛋糕店都是先给你一张提货单,你拿到提货单以后,没有必要一直在店里
 等着,可以先去干点其他事,比如看电影
 
 立勇多线程可以快速将一些串行的任务并行化,从而提高性能;如果任务之间
 有依赖关系,比如当前任务依赖前一个任务的执行结果,这种问题基本上都可以
 用future来解决.在分析这种问题的过程中,建议你用有向图描述一下任务
 之间的依赖关系,同时将线程的分工也做好,类似于烧水泡茶最优分工方案那
 幅图.对照来写代码,好处是更形象,且不易出错.
 
 

24 | CompletableFuture:异步编程没那么难
前面我们不止一次提到，用多线程优化性能，其实不过就是将串行操作变成并行操作。如果仔细
观察，你还会发现在串行转换成并行的过程中，一定会涉及到异步化，例如下面的示例代码
，现在是串行的，为了提升性能，我们得把它们并行化，那具体实施起来改怎么做呢。

还挺简单的，就像下面代码中这样，创建两个子线程去执行就可以了。你会发现下面的并行
方案，主线程无需等待 方法的执行结果，也就是说两个操作已经被异步化了。

异步化，是并行方案得以实施的基础，更深入地讲其实就是：利用多线程优化性能这个核心方案
得以实施的基础。看到这里，相信你应该就能理解异步编程最近几年为什么会大火了，因为
优化性能是互联网大厂的一个核心需求啊。java在1.8版本提供了CompletableFuture来支持
异步变长，CompletableFutre有可能是你见过最复杂的工具类了，不过功能也着实让人
感到震撼。

CompletableFuture异步变长的优势，这里我们用CompetableFuture重新实现
前面曾提及的烧水泡茶程序。首先还是需要先完成分工方案，在下面的程序中，我们分了3个
任务：任务1负责洗水壶、烧开水，任务2负责洗茶胡洗茶杯和拿茶叶，任务3负责泡茶。
其中任务3要等待任务1和任务2都完成后才能开始。这个分工如下图所示。

下面是代码实现，你先略过runAsync supplyAsync thenCombine这些不熟悉的
方案，从大局上看，你会发现：
1.无需手工维护线程，没有反锁的共收维护线程的工作，给任务分配线程的工作也不需要我们关注。

2.语义更清晰，例如f3=f1.thenCombine(f2,()->{})能够清晰地表述任务3要等待
任务1和任务2都完成后才能开始。

3.代码更简练并且专注于业务逻辑，几乎所有代码都是业务逻辑相关的。

CompetableFuture<Void> f1=CompetableFuture.runAsync(()->{
System.out.println("T1:洗水壶..");
sleep(1,TimeUnit.SECONDS);
System.out.println("T1:烧开水...");
sleep(15,TimeUnit.SECONDS)
})

CompletableFuture<String> f1=
ComletableFuture.supplyAsync(()->{
System.out.println("T2:洗茶壶");
sleep(1,TimeUnit.SECONDS);

System.out.println("T2:洗茶杯");
sleep(2,TimeUnit.seconds);
System.out.println("T2:拿茶叶");
sleep(1,TimeUnit.seconds);
return "龙井";
})

CompletableFuture<String> f3=
f1.thenCombine(f2,(__,tf)->{
System.out.println("T1:拿茶叶"+tf);
System.out.println("T1:泡茶");
return "上茶"+tf;
})
System.out.println(f3.join());

void sleep(int t,TimeUnit u){
try{
   u.sleep(t);
 }catch(InterruptedException e){
 }
}

领略了CompletableFuture异步编程的优势之后，下面我们详细介绍Completablefuture的
使用，首先是如何创建CompletableFuture对象。

创建CompletableFuture对象
创建CompletableFuture对象主要靠下面代码中展示的这4个静态方案，我们先看前两个。

在烧水泡茶的例子中，我们已经使用了runAsync(Runable runnable)和
supplyAsync(Supplier<U> supplier),他们之间的区别是：runnableiek的run（）
方法没有返回值，而supplier接口的get方法是有返回值的。
默认情况下 CompletableFuture会使用公共的forkJoinPool线程池，这个线程池默认创建
的线程数是CPU的核数 也可以通过JVM option:-Djava.util.comcurrent.ForJoinPool.common.parallelism来
设置ForkJoinPoll线程池的线程数。
如果所有CompletableFuture共享的一个线程池，那么一旦有任务执行一些很慢的
IO操作，就会导致线程池中所有线程都阻塞在IO操作上，从而造成线程饥饿，进而影响整
个系统的性能。所以，强烈建议你要根据不同的业务类型创建不同的线程池，以避免互相干扰。

static CompletableFuture<Void> runAsync(Runnable runnable)

static <U> CompletableFuture<U> supplyAsync(Supplier<u> supplier)

//可以指定线程池
static ComletableFuture<Void> runAsync(Runnable runnable,Executor executor)

static <U>CompletableFuture<U> supplyAssync(Supplier<U> supplier,executor executor)


创建完CompletableFuture对象之后，会自动 异步执行runnable.run方法或者
supplier.get方法，对于一个异步操作，你需要关注两个问题：一个是异步操作什么时候结束
另一个是如何获取异步操作的执行结果。因为completablefuture类实现了future接口
，所以这两个问题你都可以通过future接口来解决。另外completablefuture类还实现
了completionStage接口，这个接口内容实在是太丰富了，在1.8版本里有40个方法，这
些方法我们该如何理解呢？

如何理解CompletionStage接口
我觉得，你可以站在分工的角度类比一下工作流。任务是有时有序关系的，比如有串行关系，并行关系
汇聚关系等。 这样说可能有点抽象，这里还举例前面烧水泡茶的例子，其中洗水壶和烧开水
就是串行关系，洗水壶、烧开水和洗茶壶、洗茶杯这两句任务之间就是并行关系，而烧开水
、拿茶叶和泡茶就是汇聚关系

并行关系  串行关系 汇聚关系

CompletionStage接口可以清洗地描述任务之间的这种时序关系，例如前面提到的f3=
f1.thenCombine(f2,()->{})描述的就是一种汇聚关系。烧水泡茶程序中的汇聚关系是
一种AND聚合关系，这里的AND指的是所有依赖的任务（烧开水和拿茶叶）都完成后才开始
执行当前任务泡茶。既然有AND聚合关系，那就一定还有OR聚合关系，所以的OR指的
是依赖的任务只要有一个完成就可以执行当前任务。

在变成领域，还有一个绕不过去的山头，那就是异常处理，CompletionStage接口也可以方便
地描述异常处理。

1.描述串行关系 Compose组成 Accept接受同意 apply申请使用应用
CompletionStage接口里面描述串行关系，主要是thenApply thenAccept thenRun和
thenCompose这四个系列的接口。

thenApply系列函数里参数fn的类型是接口FunctionTR,这个接口里与
CompletionStage相关的方法是R applyT T,这个方法既能接受参数也支持返回值，所以
thenApply系列方法返回的是CompletionStage<R>

而thenAccept系列方法里参数consumer的类型是接口consumer,这个接口里与
CompletionStage相关的方法是R apply 这个方法技能接收参数也支持返回值，所以
thenApply系列方法返回的是CompletionStage








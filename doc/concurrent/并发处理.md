操作系统原理:

http://www.matools.com/api/java8
https://docs.oracle.com/javase/8/docs/api/index.html


I.第一讲 原子性、可见性、有序性：并发bug的源头


只要我们能够深刻理解可见性、原子性、有序性在并发场景下的原理，很多并发问题是可以理解的
缓存导致的可见性、线程切换带来的原子性、编译优化带来的有序性。


I.第二讲 JMM：看java如何解决可见性和有序性


volatile、synchronized、final+六项happens-before规则
 



synchronized 
修饰静态方法时，锁定当前类的class对象

非静态方法，锁定当前实例对象this



15 Lock和Condition下:dubbo如何用管程实现异步转同步
我们讲到了javaSDK并发包里的lock有别与synchronized隐士锁的三个特性
：能够响应中断、支持超时和非阻塞地获取锁。那今天我们接着再来详细聊聊javasdk并发
包里condition，condition实现了管程模型里面的条件变量。

在管程里我们提到过java语言内置的管程里只有一个条件变量
，而lockcondition实现的管程是支持多个条件变量的。这是二者的一个重要区别

在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。
例如，实现一个阻塞对垒，就需要两个条件变量。

那如何利用两个条件变量快速实现阻塞队列呢

一个阻塞队列，需要两个条件变量，一个队列不空，另一个是队列不满
这个例子我们前面在介绍管程的时候详细说过，这里就不赘述。相关
的代码，我这里重新列出来，你可以温故知新一下。

不过，这里你需要注意，lock和condition实现的管程，线程等待和通知需要调用 await()
signal、signalAll,他们的寓意和waitnotify notifyall相同。但是不一样的是
lock 和condition实现的管程里只能使用前面的await signal signalall而后面的
wait notify notify all只有在synchronized实现管程里才能使用。如果一步小心在
lock condition实现的管程里调用了wait notify notifyall那程序可就彻底玩完了。

javasdk并发包里lock和condition不过就是管程的一种实现而已。管程你已经很熟悉了
那lock和condition的使用自然是小菜一碟。下面我们就来看看在指明项目dubbo中
lock和condition是怎么用的。不过在开始介绍源码之前，我们还要先介绍两个概念：同步和异步

同步和异步
我们平时写的代码，基本都是同步的。但最近几年，异步编程大火。那同步和异步的区别到底是什么
呢？通俗点来讲就是调用方式是否需要等待结果，如果需要等待结果，就是同步；如果不需要等待结果，就是异步。

比如在下面的代码里，有一个计算圆周率小数点后100万位的方法牌m，这个方法可能需要
执行两礼拜，如果调用pait1
后，线程一直等着计算结果，等两立牌后结果返回，就可以执行printyg了，这个属于同步；如果调用pai之后
线程不用等待计算结果，立刻就可以执行printf这个就属于异步。

同步，是java代码默认的处理方式。如果你想让你的程序支持异步，可以通过下面两种方式来
实现：
  1.调用方创建一个子线程，在子线程中执行方法调用，这种调用我们称为异步调用；
  2.方法实现的时候，创建一个新的线程执行主要逻辑，主线程直接return，这种方法我们一般称为
  异步方法
  
dubbo源码分析
其实在编程领域，异步场景还是挺多的，比如tcp协议本身就是异步的，我们工作中经常用到
的rpc调用，在tcp协议层面，发送完RPC之后，线程是不会等待RPC的响应结果的。可能
你会觉得奇怪，平时工作中的rpc调用大多数都是同步的啊，
其实很简单，一定是有人帮你做了异步转同步的事情。例如目前RPC dubbo就给我们
做了异步转同步的事情，那它是怎么做的呢？下面我们就来分析下dubbo源码

对于下面一个简单RPC调用，默认情况下sayhello方法，是个同步方法，也即是说，执行
service。sayhello的时候，线程会停下来。
如果你将dump出来的话，会是下图这个样子，你会发现调用线程阻塞了，线程状态
是timed waiting .本来发送请求时异步的，但是调用线程阻塞了，说明dubbo帮我们
做了异步转同步的事情。通过调用栈，你能看到线程是阻塞在defualtFuture.get方法上，所以
我们可以推断：dubbo异步转同步的功能应该是通过defaultFuture这个类实现的。

不过为了理清前后关系，还是有必要分析下调用defualtFutureget之前发生了什么
 dubboInvolker的108行调用了DefaultFuture.get这一银行很关键，我们稍微修改了一下列在
 了下面。这一行先调用了request这个方法其实就是发送rpc请求，之后通过gety方法等待RPC返回结果。

DefaultFuture这个类是很关键，我把相关的代码精简之后，列到了下面。不过在看代码之前，
你还是由必要重复一下我们的需求：当RPC返回结果之前，阻塞调用线程，让调用线程等待；
当RPC返回结果后，唤醒调用线程，让调用线程重新执行。不知道你有没有似曾相识的感觉，
这不就是经典的等待-通知机制吗，这个时候想必你的脑海里应该能够浮现出管程的解决方法了。
有了自己的方案之后，我们再来看看dubbo是怎么实现的。

调用线程通过调用get方法等待RPC返回结果，这个方法里面，你看到的都是熟悉的面孔
：调用lock获取锁，在finally里面调用unlock释放锁，获取锁后，通过经典的再循环
中调用await方法来实现等待。

当rpc结果返回时，会调用do Received 方法，这个方法里面，调用lock获取锁，在
finally里面调用unlock释放锁，获取锁后通过调用signal来通知调用线程，结果已经返回
，不用继续等待了。

至此，dubbo里面的异步转同步的源码就分析完了，有没有觉得还挺简单的？最近这几年，工作
中需要异步处理的越来越多了，其中有一个主要原因就是有些API本事就是异步API 。例如
websocket也是一个异步的通信协议，如果基于这个协议实现一个简单的rpc你也会遇到
异步转同步的问题。现在很多公有云的API本身也是异步的，例如创建云主机，就是一个异步的
API，调用虽然成功了，但是云主机并没有创建成功，你需要调用另外一个api去轮训云主机的状态
。如果你需要在项目内部封装创建云主机的API，你也会面临异步转同步的问题，因为同步api更易用。

总结

lock condition 是管程的一种实现，所以能否用好lcok和condition 要看你对管程模型理解
得怎么样。管程技术前面我们已经专门用一篇文章做了介绍，你可以结合着来学，理论联系实践

lock confition实现的管程相对于synchronized实现的管程来说更加灵活、功能也更丰富。

结果我自己的经验，我认为了解原理比了解实现更能让你快速学好并发编程，所以没有介绍太多
javasdk并发包里锁和条件变量时如何实现的。但如果你对实现感兴趣，可以参考java并发
编程的艺术艺术中的第五章 java中的锁。里面详细介绍了实现原理，我觉得写得非常好。





16 Semaphore :如何快速实现一个限流器
PV 信号量 semaphore

Semaphore 现在普遍翻译为信号量，以前也曾被翻译成信号灯，因为类似现实生活里
的红绿灯，车辆能不能通行，要看是不是绿灯。同样在编程世界里，线程能不能执行，也要看
信号量是不是允许。

信号量是由大名鼎鼎的计算机科学家迪杰斯特拉DIJKSTRA于1965年提出，在这之后的15年
，信号量一直都是并发编程领域的终结者，知道1980年管程被提出来，我们才有了第二选
则。目前几乎所有支持并发编程的语言都支持信号量机制，所以学号信号量还是很有必要的。

下面我们首先介绍信号量模型，之后介绍如何使用信号量，最后我们再用信号量来实现一个限流器。

信号量模型还是很简单的，可以简单概况为：一个计数器、一个等待队列，三个方法（init、up、down）。在
信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它
们，这三个方法分别是：init、down和up。你可以结

这三个方法详细的语义具体如下所示
init:设置计数器的初始值。
down:计数器的值减一；如果此时计数器的值小于0，则当前线程被阻塞，否则当前线程可以继续执行。
up：计数器的值加一；如果此时计数器的值小于或者等于0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。

这里提到的init、down、up三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。
在javasdk里面，信号量是由模型javauitl.concurrent.Symaphore实现的
，Semaphore这个类能够保证这三个方法都是原子操作。

semaphore.acquire 减一
semphore. release 加一

这里再插一句，信号量模型里面，down up这两个操作历史上最早称为P操作和V操作，
所以信号量模型也被称为PV原语。另外，还有些人喜欢用semWait和semSignal来称呼他们
，虽然叫法不同，但是语义都是相同的。在javaSDK并发包里，down和up对应的则是
acquire和release()


如何使用信号量
通过上文，你应该发现信号量的模型还是很简单的，那具体该如何使用呢？其实你想想红绿灯
就可以了。十字路口的红绿灯可以控制交通，得益于他的一个关键规则：车辆在通过路口前必须
先检查是否是绿灯，只有绿灯才能通过。这个规则和我前面提到的锁规则是不是很类似。

其实，信号量使用的也是类似的。这里我们还是用累加器的例子来说明信号量的使用吧。在累加器
的利器里。count+1的操作是个临界区，值运行一个线程执行，也即是说保证互斥。那这种
情况用信号量怎么控制呢

其实很简单，就像我们用互斥锁一样，只需要在进入临界区之前执行一个down操作，推出临界
区之前执行一下up操作就可以了。下面是java代码的示例，acquire就是信号量里的down
操作，release就是信号量里的up操作o

下面我们再来分析一下，信号量是如何保证互斥的。假设两个线程T1和T2同事访问addone方法
，当它们同事调用acquire的时候，由于acquire是一个原子操作，所以只能由一个
线程把信号量里的计数器减为0，另外一个线程T2则是将计数器减为-1。对于线程
T1，信号量里面的计数器的值是0，大于等于0，所以线程T1会继续执行；对于线程T2，信号量
里面的计数器的值是-1，晓宇0，按照信号量模型里对down操作的描述，线程T2将被阻塞。
所以此时只有线程T1会进入临界区执行count+1
当线程T1执行release操作，也就是up操作的时候，信号量里计数器的值是-1，加1之后的值是0，
小于等于0，按照信号量模型里对up操作的描述，此时等待队列中的T2将会被唤醒。
于是T2在T1执行完临界区代码之后才获得了进入临界区执行的机会，从而保证了互斥性。


快速实现一个限流器
上面的例子，我们用信号量实现了一个最简单的互斥锁功能。估计你会觉得奇怪，既然有java
SDK里面提供的lcok，为啥还要提供一个Semaphore其实实现一个互斥锁，仅仅是
semaphore的部分功能，semaphore还有一个功能是lcok不容易实现的，那就是
semaphore可以允许多个线程访问一个临界区。

现实中还有这种需求？有的。比较常见的需求就是我们工作中遇到的各种池化资源，例如
连接池、对象池、线程池等等。其中，你可可能最熟悉数据库连接池，在同一时刻，一定是允许多个线程
同时使用连接池的，当然，每个连接在被释放前，是不允许其他线程使用的。

其实前不久，我在工作中也遇到了一个对象池的需求。所谓对象池呢，值得是一次性创建出N个对象
，之后所有线程重复利用这N个对象，当然对象在被释放前，也是不允许其他线程使用的。
对象池，可以用list保存示例对象，这个很简单。但管家你是限流器的设计，这里的限流，指
的是不允许多余N个线程同时进入临界区。那如何快读实现一个这样的限流器呢？这种场景，
我立刻就想到了信号量的解决方案。
  
  
  信号量的计数器，在上面的例子中，我们设置成了1，这个1表示只允许一个线程进入临界区，
但如果我们把计数器的值设置成对象池里对象的个数N，就能完美解决对象池的限流问题了。


我们用一个list来保持对象实例，用semaphore 实现限流器。关键的代码是objpool里面的
exec方法，这个方法里面实现了限流的功能。在这个方法里面，我们首先调用acquire方法
与之匹配的是在finally里面调用了release方法，假设对象池的大小是10，信号量的计数器
初始化为10，那么前10个线程调用aquire方法，都能继续支持，相当于通过了信号灯，
而其他线程则会阻塞在acquire方法上。对于通过信号灯的线程，我们为每个线程分配了一个
对象T这个分配工作时通过pool.remove实现的，分配完之后会执行一个回调函数hunc，
而函数的参数正是前面分配的对象t；执行完回调函数之后，他们就会释放对象 这个释放工作时通过pooladd实现的
同时调用release方法来更新信号量的计数器。如果此时
信号量里计数器的值小于等于0，那么说明有线程在等待，此时会自动唤醒等待的线程。

简言之，使用信号量，我们可以轻松实现一个限流器，使用起来还是非常简单的。

总结:

信号量在java语言里面名气并不算大，但是在其他语言里却是很有知名度的。java在并发编程
领域走的很快，重点支持的还是管程模型。管程模型理论上解决了信号量模型的一些不足，主要
提现在易用性和工程方面，例如用信号量解决我们曾经提到过的阻塞队列问题，就比管程模型
麻烦很多，你如果感兴趣，可以课下了解尝试一下。



17 ReadWriteLock:如何快速实现一个完备的缓存

前面我们介绍了管程和信号量这两个同步原语在Java语言中的实现，理论上用着两个同步原语
中任何一个都可以解决所有的并发问题。那Java SDK并发包里为什么还有很多其他的工作类呢？
原因很简单：分场景优化性能，提升易用性。

今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经常
会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。缓存
之所以能提升性能，一个重要的条件就是缓存的数据一定是读多写少的，例如元数据和技术数据
基本上不会发生变化，但是使用它们的地方却很多。
 
针对读多写少这种并发场景，javasdk并发包提供了读写锁  readwritelock ，非常容易使用
并且性能很好。

那什么是读写锁呢？
 读写锁，并不是java语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条
 基本原则：
 
 1.允许多个线程同时读共享变量；
 2.只允许一个线程写共享变量;
 3.如果一个写线程正在执行写操作，此时禁止读线程读共享变量。
 
 读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的
 ，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个
 线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。
 
 快速实现一个缓存
 下面我们就实践起来，用ReadWriteLock快速实现一个通用的缓存工具类。
 在下面的代码中，我们声明一个cache类，其中类型操作K代表缓存里key的类型
 V代表缓存里value类型。缓存的数据保持在cache类内部的hashmap里
 ，hashmap不是线程安全的，这里我们使用读写锁readwritelock来保证其线程安全。
 readwritelock是一个接口，它的实现类是reentrantreadwritelock，通过名字你应该就能
 判断出来，它是支持可重入的。下面我们通过rwl创建一把读锁和一把写锁。
 Cache这个工具类，我们提供了两个方法，一个是读缓存方法get，拎一个是写缓存方法
 put。读缓存需要用到读锁，读锁的使用和前面我们介绍的lcok的使用时相同的，都是
 tryfinally这个编程范式。写缓存则需要用到写锁，写锁的使用和读锁是类似的。这样看来，读写锁
 的使用还是非常简单的。
 
 如果你曾经使用过缓存的话，你应该知道使用缓存首先要解决缓存数据的初始化问题。缓存数据的
 初始化，可以此阿勇一次性加载的方式，也可以使用按需加载的方式。

  如果源头数据的数据量不大，就可以采用一次性加载的方式，这种方式最简单
  只需在应用启动的时候把源头数据查询出来，依次调用类似上面示例代码中的put方法就可以了
  
  如果源头数据量非常大，那么就需要按需加载了，按需加载也叫懒加载，指的是只有当应用查询
  缓存，并且数据不再缓存里的时候，才出发加载源头相关数据进行缓存的操作。下面你可以结合稳重
  示意图来看看如何利用readwritelock来实现缓存的按需加载。

   实现缓存的按需加载
   文中下面的这段代码实现了按需加载的功能，这里我们假设缓存的源头是数据库。需要注意的
   是，如果缓存中没有缓存目标对象，那么就需要从数据库中加载，然后写入缓存，写缓存需要用
   到写锁，所以在代码中，我们调用w.lock 来获取写锁。
   
   另外，还需要注意的是，在获取写锁之后，我们并没有直接去查询数据库，而是在代码
   重新验证了一次缓存中是否存在，再次验证如果还是不存在，我们采取查询数据库并更新本地缓存。
   为什么我们要再次验证呢?
   原因是在高并发下的场景，有可能会有多线程竞争写锁。假设缓存是空的，没有缓存任何东西，
   如果此时有三个线程T1T2T3同时调用get方法，并且参数可以也是相同的。那么它们
   会同事执行到代码，但此时只有一个线程能够获得写锁，假设是线程1，线程T1获取写锁
   之后查询数据库并更新缓存，最终释放写锁。此时线程T2和T3会再有一个线程能够获取写锁
   ，假设是T2，如果不采用再次验证的方式，此时T2会再次查询数据库。T2释放写锁之后
   ，T3也会再次查询一次数据库。而实际上线程T2已经把缓存的值设置好了，T2T3完全没有
   必要再次查询数据库。所以再次验证的方式，能够避免高并发场景下重复查询数据的问题。
   
   读写锁的升级与降级
   上面按需加载的示例代码中，在1获取读锁，在3释放读锁，
    锁升级。可以readwritelock并不支持这种升级。在上面的代码示例中，读锁还没有释放
    此时获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会被唤醒。
    锁的升级是不允许的，这个你一定要注意。
    
   不过，虽然锁的升级是不允许的，但是锁的降级确实允许的。
   ReentrantReadWriteLcol的官方示例，率做改动。
     获取读锁的时候线程还是持有写锁的，这种锁支持降级是支持的。
   总结 
   
   读写锁类似ReentrantLock,也支持公平模式和非公平模式。读锁和写锁都实现了lcok接口
   所以除了支持lock外，还支持trylock lockInterruptibyl等方法也都是支持的
   interrupty。但是有一点需要注意，那就是只有写锁支持条件变量，读锁是不支持条件变量的。
   读锁调用newCondition会抛出unsupportedOperationException
 
   今天我们用ReadWriteLock实现了一个简单的缓存，这个缓存虽然解决了缓存的初始化问题，
   但是没有解决缓存数据与源头数据的同步问题，这里的数据同步值得是保证存储数据和源头数据
   的一致性。解决数据同步问题的一个最简单的方案就是超时机制。所说义超市机制值得是加载进huanc
   的数据不是长久有效的，而是有实效的，当缓存的数据超时时候，也即是超时，这条
   在缓存中就失效了。而访问缓存中失效的数据，会触发缓存重新从源头把数据加载进缓存。
   
   当然也可以在源头数据发生变化时，快速反馈给缓存，但这个就依赖具体场景了。例如
   mysql作为数据源头，可以通过近实时解析binlog来识别数据是否发生了变化，如果发生了
   变化就将最新的数据推送给缓存。另外，还有一些方法采取的是数据库和缓存的双写方案。
   总之，具体采用哪种方法，还是要看应用的场景。
   
   课后思考


stamptedLock



18 StampedLock:有没有比读写锁更快的锁？

我们介绍了读写锁，学习完之后你应该已经知道“读写锁允许多个线程同时读共享变量
，适用于读多写少的场景”。那在读多写少的场景中，还有没有更快的技术方案呢
，还真有，java8这个版本里，提供了一种叫做StampedLock锁，它的性能就比读写锁还要好。

下面我们就来介绍一下StampedLock的使用方法、内部工作原理以及在使用过程中需要注意
的事项。

StamedLock支持三种锁模式
我们先来看看在使用上StampedLock和上一篇文章讲的ReadWriteLock有哪些区别。

ReadWriteLock支持两种模式:一种是读锁，一种是写锁。而StampedLock支持三种模式，
分别是：写锁、悲观读锁和乐观读。其中，写锁、悲观读锁的语义和ReadWriteLock的
写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁
锁，写锁和悲观锁是互斥的。不同的是：StampedLock里的写锁和悲观读锁加锁成功
之后，都会返回一个stamp；然后解锁的时候，需要传入这个stamp。相关代码

StampedLock的性能之所以比ReadWrite还要好，其关键是Stampedlock支持乐观
读的方式。ReadWriteLock支持多个线程同时读，但是当多个线程同时读的时候，所有的写
操作会被阻塞；而StampedLock提供的乐观读，是允许一个线程获取写锁的，也就是说不是
所有的写操作都是被阻塞。

注意这里，我们用的是乐观读这个词，而不是乐观读锁，是要提醒你，乐观读这个操作
是无锁的，所以相比较readWritelock的读锁，乐观读的性能更好一些。

文中下面这段代码是出自java sdk 官方示例，并略作了修改。在distanceFromOrigin()这个
方法汇总，首先通过调用tryOptimisticRead获取了一个stamp,这里的
tryOptimisticRead就是我们前面提到的乐观读。之后将共享变量X和Y读入方法的局部变量
中，不过需要注意的是，由于tryOptimisticRead是无锁的，所以共享变量X和Y读入方法
局部变量时，x和y有可能被其他线程修改了。因此最后读完之后，还需要再次验证一下是否
存在写操作，这个验证操作是通过调用validatestamp来实现的

在上面这个代码示例中，如果执行乐观读操作的期间，存在写操作，会把乐观读升级为悲观读
锁。这个做法挺合理的，否则你就需要在一个循环里反复执行乐观读，直到执行乐观读操作的
期间没有写操作 只有这样才能保证X和Y的正确性和一致性，而循环读会浪费大量的CPU
。升级为悲观读锁，代码简练且不易出错，减一你在具体时间时也采用这样的方法。

进一步理解乐观读

如果你曾经用过数据库的乐观锁，可能会发现StamepdLock的乐观读和数据库的乐观锁有异曲同工
之妙。的确是这样的，就拿我个人来说，我是先解除的数据库里的乐观锁，然后才解除的
Stamepedlock，我就觉得我前期数据库里乐观锁的学习对于后面理解stampedlock的乐观
读有很大帮助，所以这里有必要再介绍一下数据库里的乐观锁。

还记得我第一次使用数据库乐观锁的场景是这样的：在ERP的生产模块里，会有多个人通过
ERP系统提供的UI同时修改同一条生产订单，那如何保证生产订单数据是并发安全的呢？我采用
的方案就是乐观锁。


乐观锁的实现很简单，在生产订单的表productdoc里增加了一个数值型版本号字段version,
每次更新productdoc这个表的时候，都将version字段加1。生产订单的UI再
展示的时候，需要查询数据库，此时将这个version字段和其他业务字段一起返回给生产订单UI
。假设用户查询的生产订单的ID=777，那么SQL类似

用户在生产订单UI执行保持操作的时候，后台利用SQL语句更新生产订单，此处我们假设该条生产
订单的version=9。


如果这条sql语句执行成功并且返回的条数等于1，那么说明从生产订单UI执行查询超到
执行保持操作期间，没有其他人修改过这条数据。因为如果这期间其他人修改过这条数据，那么
版本号字段一定会大于9。

你会发现数据量的乐观锁，查询的时候需要把version字段查出来，更新的时候要利用
version字段做验证。这个version字段就类似于stampedlock里面的stamp。这样对比着
看，相信你会更容易理解stampedlock里乐观读的用法。

stampedlock使用注意事项

对于读多写少的场景StampedLock性能很好，简单的应用场景基本上可以替代
ReadWriteLock,但是StamepdLock的功能仅仅是ReadWritelock的子集，在使用的时候
，还是有几个地方需要注意一下。

StamedLock在命名上并没有增加REENTRANT，想必你已经猜到stampedLock应该是不可
重入的。事实上，的确是这样的，stampedlock不支持重入。这个是在使用中必须要特别
注意的。

另外，stampedlock的悲观读锁、写锁多步支持条件变量，这个也需要你注意。

还有一点需要特别注意，那就是：如果线程阻塞在stampedlock的readlock或者
writelock时，此时调用该阻塞线程的interrupt方法，会导致cpu飙升。例如下面的
代码中，线程T1获取写锁之后将自己阻塞，线程T2尝试获取悲观读锁，也会阻塞；如果此时
调用线程T2DE INTERRUPT方法来终端线程T2的话，你会发现线程T2所在的CPU会飙升到100

所以，使用stampedlock一定不要调用终端操作，如果需要支持中断功能，一定使用可中断
的悲观读锁readlockInterruptibly和写锁writeLockInterruptibly()。这个规则一定
要记清楚。

总结
stampedlock的使用看上去有点复杂，但是如果你能理解乐观锁背后的原理，使用起来还是
比较流畅的。减一你认真揣摩java的官方示例，这个实例基本上就是一个最佳实践。我们把精简后。


课后思考
StampedLock支持锁的降级通过tryConvertToReadLock方法实现和升级通过
tryConvertToWriteLock方法实现，但是建议你要慎重使用。下面的代码也源自java的
官方示例，我们仅仅做了一点修改，因此了一个BUG，你来看看BUG处在哪里把




19 | CountDownLatch 和 CyclicBarrier :如何让多线程步调一致？

前几天老板突然匆匆忙忙过来，说队长系统最近越来越慢了，能不能快速优化一下。我了解了
队长系统的业务后，发现还是挺简单的，用户通过在线商城下单，会生成电子订单，保持在订单库
之后物流会生成派送单给用户发货，派送点保持在派送单库。为了防止漏拍送或者重复
派送，对账系统每天还会校验释放存在 异常订单。

对账系统的处理逻辑很简单，你可以参考下面的对账系统流程图。目前对账系统的处理逻辑是
首先查询订单，然后查询派送单，之后对比订单和派送单，将差异谢雨差异库。
对账系统的代码抽象之后，也很简单，核心代码如下，就是在一个单线程里面循环查询订单、
派送单，然后执行对账，最后将写入差异库。

利用并行优化对账系统
老板要我优化性能，那我就首先要找到这个对账系统的瓶颈所在。
目前的对账系统，由于订单量和派送单量巨大，所以查询未对账订单getPOrders和查询派送单
getdorders相对较慢，那有没有办法快速优化一下呢？目前对账系统是但现场执行的
，图形化后是下图这个样子。对于串行化的系统，优化性能首先想到的是能否利用多线程并行处理。

所以，这里你应该能够看出来这个对账系统里的瓶颈：查询未对账订单getporders和查询
派送单getdorders释放可以并行处理呢，显然是可以的，因为这两个操作并没有先后顺序
的依赖。这两个最好是的操作并行之后，执行过程如下图所示。对比一下单线程的执行示意图
，你会发现同等时间里，并行执行的吞吐量近乎单线程的2倍，优化效果还是相对明显的。

思路有了，下面我们再来看看如何用代码实现。下面的代码中，我们创建了两个线程T1和T2，
并行查询未对账订单getpoders和查询派送单getdorders这两个操作。在住
线程中执行对账操作check和差异写入save两个操作。不过需要注意的是：主线程需要等待
线程T1和T2执行完才能执行check和save这两个操作，为此我们通过调用
T1。join和t2.join来实现等待，当T1和T2线程推出时，调用T1。join和T2。join的zhuxianc就会从
阻塞态被唤醒，从而之后之后的撤ck和save

用CountDownLatch实现线程等待
经过上面的优化之后，基本上可以跟老板汇报收工了，但是还是有点美中不足，相信你也发现了
while循环里面每次多会创建新的线程，而创建线程可是个耗时的操作。所以最后是创建出来的线程
能够循环利用，估计这时你已经想到线程池了，是的，线程池就能解决这个问题。

而下面的代码就是用线程池优化后的：我们首先创建了一个固定大小为2的线程池，之后
while循环里面重复利用。一切上看去都很顺利，但是有个问题好像无解了,那就是主线程如何知道
getPoRDERhe getDorder两个操作什么时候执行完。前面主线程通过调用线程T1和T2的join
方法来等待T1和T2推出，但是在线程池的方案里，线程根本就不会推出，所以join方法已经失效了。

那如何解决这个问题呢？你可以开动脑经想出很多办法，最直接的办法就是弄一个计数器，初始
值设置成2，当执行完pos=getPorderS,这个操作之后将计数器减一，执行完DOS=getDorder之后
也将计数器减一，在主线程里，等待计数器等于0；当计数器等于0时，说明这两个查询插座执行完了。
等待计数器等于0其实就是一个条件变量，用管程实现起来也很简单。

不过我并不减一你在实际项目中去实现上面的方案，因为java并发包里已经提供给了实现类似
功能的工具类:countDownLath,我们直接使用就可以了
我们创建了一个CountDownLatch计数器初始值等于2，之后在线程操作里调用 latch.CountDown
主线程我们通过awati来等待等于0

进一步优化性能
经过上面的优化之后，长处一口气，终于可以交付了。不过在交付之前还需要再次审视一番，还有么有
优化的余地，仔细看还是有的。
前面我们

用CyclicBarrier实现线程同步
一是线程T1和T2要做到步调一致，另一个是要能够通知到线程T3。
你依然可以利用一个计数器来解决这两个难点，计数器初始化为2，线程T1和T2生产完一条
数据都将计数器减一，如果计数器大于0则线程T1或者T2等待。如果计数器等于0，则通知
T3，并唤醒等待的线程T1或者T2，与此同时，将计数器充值未2，这样线程T1和线程T2
生产下一条数据的时候就可以继续使用这个计数器了。

同样，还是建议你不要在实际项目中这么做，因为java并发包里也已经提供了相关的工具类
CYCLICbARRIE。在下面的代码中，我们首先创建了一个计数器初始值为2的cyclicBarrir
你需要注意的是创建cyclicBarrir的时候，我们还传入了一个回调函数，当计数器见到0的时候
会调用这个回调函数。

线程T1负责查询订单，当查出一条时，调用barrier,await来讲计数器减一，同事等等
计数器变为0；线程T2负责查询派送单，当查出一条时，也调用barrier.await来讲计数器
减一，同时等等计数器编程0；当1和2都调用了await的时候，计数器
会见到0，此时1和2 就可以执行下一条语句了，同时会调用barrier的回调函数来执行对账操作o

非常值得一提的是，cychlicbarrier的计数器有自动充值的功能，当减到0的时候，会自动重置
你的设置的初始值。这个功能用起来实在是太方便了。

总结
CountDownLathc和cyclicBarrir是java并发包提供的两个非常易用的线程同步工具，
这两个工具类用法的区别在这里还是有必要强调一下:CountDownLathc主要用来解决一个线程
等待讴歌线程的场景，可以类比领队等待游客。而CyclicBarrir是一组线程之间互相等待，更像不离不弃。
除此之外，countDownLatch的计数器是不能循环利用的，也就是说一旦计数器见到0，再有线程调用await
该线程会直接通过。但CyclicBarrier的计数器是可以循环利用的，而且具备自动重置的功能，一旦计数器见到0
会自动重置到你设置的初始值。除此之外，cyclicbarrier还可以这只回调函数，可以说是功能丰富。
线程池提供了Future特性，我们也可以利用future
特性来实现线程之间的等待，这个我们也会详细介绍



20 并发容器:都有哪些坑需要我们填

Java并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。

Java1.5 之前提供的同步容器虽然也能保证线程安全，但是性能很差，而Java5之后
提供的并发容器在性能方便则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比
二者来学习这部分的内容。

同步容器以其注意事项
Java中的容器主要可以分为四个大类：分别是List Map Set Queue,但并不是所有的
Java容器都是线程安全的。例如，我们常用的arraylist hashmap就不是线程安全的。在
介绍线程安全的容器之前，我们先思考这样一个问题：如果将非线程安全的容器编程线程安全
的容器？

在前面我们讲过实现死了其实很简单，只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。


下面我们就以Arraylist为例，我们如何将它变成线程安全的。在下面的代码中
SafeArrayList内部持有一个arraylist的实例c，所有访问c的方法我们都增加了
synchronized关键字，需要注意的是我们还增加了一个addIfNotExitst方法，这个方法也是用
synchronized来保证原子性。

看到这里，你可能会举一反三，然后想到：所有非线程安全的类是不是都可以用这种包装的
方式来实现线程安全呢？其实这一点不止你想到了，javasdk的开发人员也想到了，所以他们
在collections这个类中还提供了一套完备的包装类，比如下面的示例代码中，分别把
arraylist hashset hashmap包装成了线程安全的list set map

我们曾经多次强调，组合操作需要注意竞态条件问题，例如上面提到的，addIfNotExist方法
就包含组合操作。组合操作往往隐藏着静态条件问题，即便每个操作都能保证原子性，也并不能
保证组合操作的原子性，这个一定要注意。

在容器领域一个容易被忽略的坑是用迭代器变量容器，例如在下面的代码中，通过迭代器
遍历容器list，对每个元素调用foo方法，这就存在并发问题，这些组合的操作不具备原子性。












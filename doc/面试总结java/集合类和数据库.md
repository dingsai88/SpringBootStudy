
----------------------------------------------------------集合框架开始------------------------------------------------------------------------------------------


集合框架

I.Collection

II.List(有序的 collection)
III.ArrayList (默认10，每次增加[oldCapacity + (oldCapacity >> 1)]1+1.5倍;A>>1往左移以为等于除以2
III.LinkedList 底层双向循环列表实现(排列有序) 下标查询速度慢；新增删除速度快；顺序遍历速度快；add、remove速度快
III.Vector 默认10；每次增加2N
和Collecions.synchronzedList对比 
SynchronizedList有很好的扩展和兼容功能。他可以将所有的List的子类转成线程安全的类
 
II.set(不包含重复元素的 collection)
III.HashSet 底层 HashMap
III.LinkedHashSet  底层是LinkedHashMap （HashMap+双向链表）
III.TreeSet 底层TreeMap的SortedMap 二叉树存储 key不能重复
 

I.map(hashmap、linkedHM、TreeMap)

II.HashMap(线程不安全)默认大小16；负载因子0.75每次增加2N (当前数据量>12(默认大小16*0.75负载因子) )就扩容.0.75空间利用率最高
JDK8之前Hash+链表
JDK8Hash+红黑树 链表大小超过阈值（  8）
哈希碰撞拒绝服务攻击-构建相同的哈希值，变成链表CPU100
扩容(resize)就是重新计算容量:新建2N，遍历旧集合依次放入新集合。jdk8做了个优化，扩容后要么是原位置要么是



II.ConcurrentHashMap
JDK7:分段锁 
III.JDK7:分成segment (赛格ment)  数组+链表
每个segment段有若干个桶桶里存放K-V形式的链表
Segment 的数量由所谓的 concurrentcyLevel 决定，默认是 16，
每次锁定segment
 
 
III.JDK8 Node + CAS + Synchronized设计
node数组，默认为16，可以自动扩展，扩展速度为0.75
每一个节点，挂载一个链表，当链表挂载数据大于8时，链表自动转换成红黑树

put的时候 cas+synchronized 
1.空node节点的时候cas
2.有数据node的节点就synchronized



II.LinkedHashMap(保证顺序线程不安全)带链表的hashmap

II.TreeMap(排序的存储) 二叉树实现


II.Hashtable(线程安全被HashMap代替)


 
 


I.Queue先进先出的队列BlockingQueue、ArrayDeque、ConcurrentLinkedQueue、LinkedList、PriorityQueue

II.阻塞BlockingQueue接口(put、take阻塞)
ArrayBlockingQueue固定大小
DelayQueue无界
LinkedBlockingDeque任选范围默认 Integer.MAX_VALUE
PriorityBlockingQueue优先级Comparator排序
SynchronousQueue两个线程交替执行同线程不行

II.非阻塞
ArrayDeque可变数组大小
ConcurrentLinkedQueue
LinkedList
PriorityQueue优先级Comparator排序


----------------------------------------------------------集合框架结束  数据库开始------------------------------------------------------------------------------------------



I.事务的ACID
原子性 最小单元:redolog重做日志保证A原子性和D持久性
一致性 同时转换:undolog保证事务的C一致性
隔离性 其他不可见:锁来保证事务的I隔离性
持久性 不丢失:redolog重做日志保证A原子性和D持久性


I.事务-隔离性-隔离级别
ReadUnCommitTed未提交读：即使没有提交，对其他事务也都是可见的。   其他事务可以读取未提交的数据,脏读 dirty read
ReadCommitTed提交读:一个事务开始时，只能看见已经提交的事务所做的修改  不可重复读 nonrepeatableread ,因为两次执行同样的查询，可能会得到不一样的结果
RepeaTableRead可重复读:在同一个事务中多次读取同样记录的结果是一致的 幻读phantom read的问题 
serializable可串行化:它通过强制事务串行执行，避免了前面说的幻读的问题


Phantom problem(不可重复读也是幻读):在同一事务里,连续两次相同的SQL导致不同的结果,第二次返回之前不存在的行.


事务提交purge线程
1.事务提交后并未真正删除数据
2.history list按照事务提交的顺序组织undolog
3.purge操作从history list找到第一个需要被清理的trx1:如果有可以复用的就不删除
purge线程清除：最终完成update、delete操作


I.Innodb线程：
1.Master thread  重做日志缓冲刷新到磁盘 插入合并、删除无用的undo页(总是)
2.IO Thread
3.purge thread清除线程回收undolog
4.Page cleaner thread:脏页刷新操作线程（innodb1.2.x之后的版本）


Innodb文件:
1.表结构定义文件:user.frm
2.1表空间文件(ibdata1):可设置多个在不同磁盘:共享表空间
2.2独立表空间:表名.ibd（只有ON的时候才有）数据索引等:tb_tdc_user.ibd
3.重做日志文件:ib_logfile0、ib_logfile1(保证持久性)
4.binlog文件


I.索引组成：
行:innodb面向列的row-oriented
页page(默认16k能调整)也叫块  每页最多允许存放16K/2-200行记录，即7992行.
区extent:连续的页组成的空间(固定1MB):
段segment(多个段组成表空间)
表空间tablespace:


I.lock(锁事务)行锁、表锁、意向锁(表锁)
1、乐观锁并未真正加锁，效率高。一旦锁的粒度掌握不好，更新失败的概率就会比较高，容易发生业务失败。
2、悲观锁依赖数据库锁，效率低。更新失败的概率比较低。


II.行级锁类型:
共享锁 Slock 允许事务读一行数据
排他锁 Xlock 允许事务删除或更新一行数据


II.意向锁:只会和表级锁冲突
1.允许事务在行级表级锁同时存在。
2.两种意向锁(表级别):表锁和行锁共存而使用了意向锁(只会和表级的X，S发生冲突)
3.IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突


II.锁相关内容

1.一致性非锁定读(RC和RR级别下可用) MVCC多版本并发控制，别人锁定也能读.通过undo日志实现

2.一致性锁定读
select for update;加排他锁读
select lock in share mode;加共享锁读




I.行锁的3种算法
Record lock:当个行记录上的锁:只有唯一索引的情况下才生效，辅助索引不生效。
Gap lock:间隙锁，锁定一个范围，但是不包含记录本身。(锁这个值前后已存在的值)
next-key lock(解决幻读问题):Gap lock+record lock，锁定一个范围，并且锁定记录本身。



锁问题:
脏读(读未提交级别):本事务读取到其他事务未提交的数据。
不可重复读(幻读):提交读隔离级别下，本事务两次读取不一致。(防止间隙内被插入新值、防止间隙内值被更新)  使用nextkeylock锁定住区间来解决不可重复读问题.

丢失更新:第二个事务覆盖第一个事务的更新（任何隔离级别都不会有问题）有锁保证

阻塞：不同锁之间兼容性问题，等待另外一个事务释放占用资源。（设置超时时间、）





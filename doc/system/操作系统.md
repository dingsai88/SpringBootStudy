**第1章**
一级学科:计算机科学与技术
二级学科:计算机系统结构、计算机软件、计算机应用技术


汇编语言


Cache一致性问题:
1.1 Cache Coherence 一致性 问题

core1   Cache1   shared memory
core2   Cache2   shared memory

原子性 可见性 顺序性
I.缓存一致性问题的原因

1:共享可写数据的不一致性(sharing of writable data)共享数据没同步到其它Cahce

2:进程迁移的不一致性;进程切换CPU导致

3:I/O操作（绕过Cache的I/O操作）:输入输出设备写入数据到Cache，但是Cache数据还是老数据。


1.1.3 两种设计Cache 一致性协议策略
1.写无效(write invalidate)
任一core写它的的私有Cache时，它都使所有其它的Cache中的副本失效。
对Write-through,它也更新memory中的副本（最终是一个Cache中的副本和memory中的副本是有效的）。
对Write-back,它使memory中的副本也失效（最终只有一个Cache的副本是有效的）。

2.写更新(write update)
任一处理器写它的私有Cache时，它都立即更新所有其它的Cache中的副本。
对Write-through,它也更新主存储器中的副本。
对Write-back,对存储器中副本的更新延迟到这个Cache被置换的时刻。


3.示意图

4.写无效的问题
主要开销在两个方面
1.作废各Cache副本的开销
2.由作废引起缺失造成的开销，即处理机需要访问已经作废的数据时引起Cache的缺失。

后果:
如果一个Core经常对某个块连续写，且Core间对共享块的竞争较小，这时写无效策略维护
一致性的开销是很小的。如发生严重竞争，即Core之间对某个地址的共享数据竞争，
将产生较多的作废，引起更多的作废缺失。结果是共享数据在各Cache间倒来倒去，
产生颠簸现象，当缓存块比较大时，这种颠簸现象更为严重。


5.写更新的问题
由于更新时，所有的副本均需要更新，开销很大。

1.2 监听总线协议(Snoopy protocol)

通过总线监听机制实现Cache和共享存储器之间的一致性。

适用性分析：
    适用于具有广播能力的总线结构多Core系统，允许每个Core监听其它Core的存储器访问情况。
    
   只适用于小规模的多Core系统。

1.2.1 写一次(write-once)协议
      写无效监听一致性协议，将通过和写回策略结合。      
   为了减少总线流量，高速缓冲块的第一次写用写通过方法，产生一份正确的主存储器副本，
并使其它的Cache中的副本无效，之后就采用写回方法更新Cahce与主存储器。

1.一致性协议的内容
  (1)Cache可能出现的状态集合
  (2)共享主存的状态
  (3)为维护一致性而引起的状态转换

2.每份Cache中的副本可能出现的四种状态
    (1)有效(valid state):与主存器副本一直的Cache副本，即该副本未经修改，所以这个Cache副本不是唯一的副本。
    (2)保留(reserved state):这个Cache副本是第一次修改，并用写通过方法写入主存，所以这个Cache副本和主存器副本是一致。
    (3)重写(dirty state):Cache副本不止一次被修改过，由于不再采用写通过方法，所以这个Cache副本是唯一的副本。与存储器和其它的Cache副本都不一致。主存器中的副本也是无效的。
    (4)无效(invalid state):与存储器或其它的Cache副本不一致，或在Cache中找不到。

3.局部命令(Local commands)

(1)P-Read ：本地处理机读取自己的Cache副本。
(2)P-Write: 本地处理机写自己的Cache副本。

4.一致性命令
(1)Read-blk:从另一Cache读一份有效的副本。
(2)Write-inv:在写命中时在总线上广播一个无效命令。
(3)Read-inv:在写缺失时在总线上广播一个无效命令。

5.Write-Once 一致性协议状态转移图
四种状态的含义:
Dirty:修改不止一次；多次重写(只有它有效，其它cache和memory都是无效)
Invalid:无效状态。
Reserved:保留状态;只被修改过一次。
Valid:有效的；从未被修改过的。


1.2监听总线协议
通过总线监听机制实现Cache和共享存储器之间的一致性。

适用性分析：
适用于具有广播能力的总线结构多Core系统，允许每个Core监听其它Core的存储器访问情况。
只适用于小规模的多Core系统




1.2 基于目录的Cache一致性协议
2. 基于目录的一致性协议的基本思想(只发送给存放该副本的Cache)
  当Core个数增加时，一般不用总线结构，而采用多级互联网络。多级互联网实现广播功能代价很大。
  能不能只发送给存放该副本的Cache
  
  

1.3基于目录的Cache一致性协议 适应很多core






什么是并行处理
1.同时性simultaneity
两个或多个时间在同一时刻发生

2.并发性concurrency
两个或多个时间在同一时间间隔内发生。

3.流水特性
在一个重叠的时间内所发生的的流水事件。


粒度granularity
衡量一个软件进程的计算量的度量，最简单的是指此程序段中的指令数
细粒度：用并行化或向量化编译器来开发，共享变量通信支持。

中粒度：靠程序员和编译器一起开发，共享变量通信。

粗粒度：取决于操作系统和算法的效率，消息传递通信。


并行性级别
按粒度的不同，并行性级别可以分为:
1.指令级并行
典型细粒度，一般少于20条指令。借助优化编译器自动检测并行性，将源代码变成运行时系统能识别的并行形式。

2.循环级并行
典型循环含少于500条指令，由于有些循环操作在连续迭代中并不相关，易于向量化，是并行机或向量机上运行的最优程序结构。递归循环的并行化比较困难。向量处理由优化编译器在循环级开发，仍属于细粒度计算。

3.过程级并行

4.子程序级并行

5.作业级并行



为什么要开发并行处理技术

单用户:
可以提高加速比（Speedup Oriented)

多用户:
可以提高吞吐率（Throughput Oriented)



第一章
操作系统漫游
   
   计算机系统是由硬件和系统软件组成的，它们共同工作来运行应用程序。虽然系统的
具体实现方式随着时间不断变化，但是系统内在的概念却没有改变。所有计算机系统都有
相似的硬件和软件组成，它们又执行着相似的功能。一些程序员希望深入了解这些组件是
如何工作的以及这些组件是如何影响程序的正确性和性能的，以此来提高自身的技能。本
书便是为这些读者而写的。
   现在就要开始一次有趣漫游历程了。如果你全力投身学习本书中的概念，完全理解底层
计算机系统以及它对应用程序的影响，那么你会步上成为为数不多的大牛的道路。
  你将会学习一些实践技巧，比如如何避免由计算机表示数字的方式引起的奇怪的数字
错误。你将会学怎样通过一些小窍门来优化自己的C代码，以充分利用现代处理器和存储
器系统的设计。你将了解编译器是如何实现过程调用的，以及如何利用这些知识来避免缓
冲区溢出错误带来的安全漏洞，这些弱点给网络和因特网软件带来了巨大的麻烦。你将学
会如何识别和避免连接时那些令人讨厌的错误，它们困扰着普通的程序员。你将学会如何
编写自己的Unix shell、自己的动态存储分配包，甚至于自己的web服务器。你会认识并发
带来的希望和陷阱，这个主题随着单个芯片上集成了多个处理器核变得越来越重要。
   在kernighan和ritchie的关于C编程语言的经典教材中，他们通过所示的
hello程序来向读者介绍C。尽管hello程序非常简单，但是为了让它实现运行，系统
的每个主要组成部分都需要协调工作。从某种意义上来说，本书的目的就是要帮助你了解
当你的系统上执行hello程序时候，系统发生了什么以及为什么会这样。
   我通过跟踪hello程序的生命周期来开始对系统的学习   从它被程序员创建开始，
到在系统上运行，输出简单的消息，然后终止。我们将沿着这个程序的生命周期，简要地介
绍一些逐步出现的关键概念、专业术语和组成部分。后面的章节将威少这些内容展开。

1.1  信息就是位+上下文
   hello程序的生命周期是从一个源程序开始的，即程序员通过编辑器创
建并保持的文本文件，文件名是hello.c。源程序实际上就是一个由值0和1组成的位(又称
位比特)序列，8个位被组织称一组，成为字节。每个字节表示程序中的某些文本字符。
   大部分的现代计算机系统都使用ASCII标准来表示文本字符，这种方式实际上就是用
一个唯一的单字节达标的整数值来表示每个字符。比如，图1-2中给出了hello。c程序
的ascii码表示。
    hello.c程序是以字节序列的方式存储在文件中的。每个字节都有一个整数值，对应
于某些字符。例如，第一个字节的整数值是35，它对应的就是字符#。第二个字节的
整数值位105，它对应的字符是i，依次类推。注意，每个文本行都是以一个看不见的
换行符\n来结束的，它所对应的整数值位10.想helloc这样只有ascii字符构成
的文件成为文本文件，所有其他文件都成为二进制文件。
   hello.c的表示方法说明了一个基本思想：系统中所有的信息--包括磁盘文件、内
存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由遗传比特表示的。区
分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文
中，一个统一的字节序列可能表示一个整数、浮点数、字符串或者机器指令。
   作为程序员，我们需要了解数字的机器表示方式，因为它们与实际的整数和实数是不
同的。它们是对真值的有限近似值，有时候会有意向不到的行为表现。这方便的基本原理
将在第二章中详细描述

1.2 程序被其它程序翻译成不同的格式
   hello程序的生命周期是从一个高级C语言程序开始的，因为这种形式能够被人读
懂。然后，为了在系统上运行hello.c程序，每条C语言都必须被其他程序转化为一系
列的低级机器语言指令。然后这些指令按照一种称为可执行目标程序的格式打好包，并以
二进制磁盘文件的形式存放起来。目标程序也称为可行性目标文件。
  在unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的:
  linux>gcc -o hello hello.c
   在这里，GCC编译器驱动程序读取源程序文件hello.c，并把它翻译成一个可执行
目标文件hello。这个翻译过程可分为四个阶段完成，图1-3所示。执行这四个阶段的
程序(预处理器、编译器、汇编器和连接器)一起构成了编译系统(compilation system)
* 预处理阶段。预处理器CPP根据以字符#开头的命令，修改原始的C程序。比如
hello.c中第一行的#include<stdio.h>命令告诉预处理器读取系统头文件
stdio.h的内容，并把它直接插入程序文件中。结果就得到了另一个C程序，通常
是以.i作为文件拓展名。
* 编译阶段。编译器CCL将文件文本hello。i翻译成文本文件hello.s，它包含一个
汇编语言程序。该程序包含函数main的定义，如下所示：
main:
subq &8,%rsp
movl $.LC0,%edi
call puts
movl $0,%eax
addq $8,%rsp
ret
  定义中2-7行的每条语句都以一种文本格式描述了一条低级机器语言指令。
汇编语言是非常有用的，因为它为不同高级语言的不同编译器提供了通用的输出语言
例如,c编译器和FOrtran编译产生的输出文件用的都是一样的汇编语言。
* 汇编阶段。接下来，汇编器as将hello。s翻译成机器语言指令，把这些指令打包成
一种叫做可重定位目标程序relocatable object program的格式，并将结果保存在目标文件hello.o中
hello。o文件是一个二进制文件，它包含的17个字节是函数main的指令编码。如果我们在文本
编辑器中打开hello.o文件，将看到一堆乱码。
* 链接阶段。请注意，hello程序调用了PRINTF函数，它是每个C编译器都提供的
标准C库中的一个函数。printf函数存在于一个名为printf.o的单独的预编译
好了的目标文件中，而这个文件必须以某种方式合并到我们的hello.o程序中。连接器
ld就负责处理这种合并。结果就得到hello文件，它是一个可行性目标文件，可以被加载到内存中，
由系统执行

1.3 了解编译系统如何工作时大有益处的
   对于像hello.c这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。
但是，有一些重要的原因促使程序员必须知道编译系统是如何工作的。
   *优化程序性能。现代编译器都是成熟的工作，通常可以生成很好的代码。作为程序员
，我们无需为了写出高效代码而去了解编译器的内部工作。但是，为了在c程序中
做出好的编码选择，我们确实需要了解一些机器代码以及编译器将不同的C语句转化为
机器代码的方式。比如，一个switch语句是否总比一系列的ifelse语句高效的多
一个函数调用的开销有多大？while循环比for循环更有效吗指针引用比数组
索引更有效吗？为什么将循环求和的结果放到一个本地变量中，回避将其放到一个
通过引用传递过来的参数中，运行起来块很多呢？为什么我们只是简单地重新排列一
下算法表达式中的括号就能让函数运行的更快？
    在第三章中，我们将介绍x86-64,最近系带linux、macintosh和windows计算机的
机器语言。我们会讲述编译器是怎样把不同的C语言结果翻译成这种机器语言的。在第五章中
，你将学习如何通过简单转换C语言代码，帮助编译器更好地完成工作，从而调整
C程序的性能。在第六章中，你将学习存储器系统的层次结果特性，C语言编译器ruhe将
数组存放在内存中，以及C程序又是如何能够利用这些知识从而更高效地运行。
* 理解连接时出现的错误。 根据我们的经验，一些最令人困扰的程序错误往往都与连接器
操作有关，尤其是当你师徒构建大型的软件系统时。比如连接器报告说它无法解析
一个引用，这是什么意思？静态变量和全局变量的区别是什么？如何你再不同的C文件中
定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别
是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么哟西额连接
错误知道运行时才会出现？在第七章中，你将得到这些问题的答案。
* 避免安全漏洞。多年来，缓冲区溢出错误是造成大多数网络和internet服务器上安全
漏洞的主要原因。存在这些错误是因为很少有程序员能够理解需要限制从不受信任
的源接受数据的数量和格式。学习安全编程的第一步就是理解数据和控制信息存储
在程序栈上的方式会引起的后果。作为学习汇编语言的一部分，我们将在第三种中
描述对战原理和缓冲区溢出的错误。我们还将学习程序员、编译器和操作系统可以
用来降低攻击威胁的方法。

1.4 处理器读并解释存储在内存中的指令
   此刻，hello.c源程序已经被编译系统翻译成了可执行目标文件hello,并被存放在
磁盘上。要向在unix系统上运行该可执行文件，我们讲他的文件名输入到成为shell的引用程序中：
linux>./hello
hello,world
linux>
     shell是一个命令行解释器，它输出一个提示符，等待输入一个命令行，然后执行这个
命令。如果该命令行的第一个单词不是一个内置的shell命令，那么shell就会假设这是
一个ke执行文件的名字，它将加载并运行这个文件。所以在此例中，shell将加载并运行
hello程序，然后等待程序终止。hello程序在屏幕上输出它的消息，然后终止。shell
随后输出一个提示符，等待下一个输入的命令行。
1.4.1系统的硬件组成
  为例理解运行hello程序时发生了什么，我们需要了解一个典型系统的硬件组织，如图
1-4所示。这张图是近期intel系统产品族的模型，但是所有其他系统也有相同的外观
和特性。现在不要担心这张图很复杂--我们将在本书分阶段对其进行详尽的介绍。

 1.总线
 贯穿整个系统的是一组电子管道，称作总线，它携带信息字节并负责在各个部件间传
递。通常总线被设计成传送定长的字节块，也就是字word。字中的字节数即字长是一个
基本的系统参数，各个系统中都不进相同。现在的大多数机器字长要么是4个字节32位
要么设计8个字节64位。本书中，我们部队字长做任何固定的假设。相反，我们将在
需要明确定义个上下文中具体说明一个字是多大。

 2.IO设备
 IO设备是系统与外部世界的联系通道。我们的示例系统包括四个IO设备
作为用户输入的键盘和鼠标，作为用户输出的显示器。以及用于长期存储数据和程序
的磁盘驱动器。最开始可执行程序hello就存放在磁盘上。
每个io设备都通过一个控制器或适配器与io总线相连。控制器和适配器之间的区
别主要在于他们的封装方式。控制器是IO设备本书或者系统的主印制电路板通常称作
主板上的芯片组。而适配器则是一块插在主板插槽上的卡。无论如何，它们的功能都是在
IO总线和io设备之间传递信息。
   第六章会更多地说明磁盘指令的IO设备是如何工作的。在第十章中，你将学习如何
在应用程序中利用UNIXio访问设备。我们将特别关注网络累设备，不过这些技术
对于其他设备来说也是通用的。
 3.主存
 主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从
物理上来说，主存是一组动态随机存取存储器DRAM芯片组成的。从逻辑上来说，存储
器是一个线性的字节数组，每个字节都有唯一的地址数组索引，这些地址是从零开始
的。一般来说，组成程序的每条机器指令都由不同数量的字节构成。与C程序变量相对应的
数据项的带下是根据类型变化的。比如在运行linux的x8664机器上，short类型的数据
需要2个字节，int和floast类型需要四个字节，而long和double类型需要8个字节。
  第六章将具体介绍存储器技术，比如DRAM新品是如何工作的，他们又是如何组合
起来构成主存的。
   4.处理器
   中央处理单元CPU，简称处理器，是解释或执行存储在主存中指令的引起。处理器
的核心是一个大小为一个字的存储设备或寄存器，程序程序计数器PC。在任何时
刻，PC都执行主存中的某条机器语言指令（即含有该条指令的地址）。
  从系统通电开始，知道系统断点，处理器一直在不断地执行程序计数器只想的指令。
再更新程序计数器，使其指向下一条执行令，处理器看上去是按照一个非常简单的指令执行
模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行
，而执行一条指令包含执行一系列的步骤。处理器从程序计数器只想的内存处读取指
令，解释指令中的位，执行该指令执行的简单操作，然后更新PC，使其指向下一条指令，
而这条执行令并不一定和在内存中刚刚执行的指令相邻。
  这样的简单操作并不多，他们围绕着主存、寄存器文件register file和算数 逻辑单元
ALU进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个
寄存器都有唯一的名字。ALU计算新的数据和地址值。下面是一些简单操作的例子，
CPU在指令的要求下可能会执行这些操作。
加载:从主存赋值一个字节或一个字到寄存器，以覆盖寄存器原来的内容。
存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
操作：把两个寄存器的内容赋值到ALU，ALU对着两个字做算术运行，并将结果
存放到一个寄存器中，以覆盖该寄存器中原来的内容。
跳转：从指令本书中抽取一个字，并将这个字复制到程序计数器PC中，以覆盖
PC中原来的值。
   处理器看上去是它的指令集架构的简单实现，但是实际上现代处理器使用了非常负载的
的机制来加速程序的执行。因此，我们将处理器的指令集架构和处理器的微体系结构区分开来：
指令集架构描述的是每条机器代码指令的效果；而微体系结构的是处理器实际
上市如何实现的。在第三种研究机器代码时，我们考虑的是机器的指令集架构锁提供的抽象性。
第四章将更消息地介绍处理器实际上是入额实现的。第五章用一个模型说明现代处
理器是如何工作的，从而能预测和优化机器语言程序的性能。

1.4.2 运行hello程序
   前面简单描述了系统的硬件组成和操作，现在开始介绍当我们运行示例程序时到底发
生了些什么。在这里必须省略很多细节，稍后会做补充，但是现在我们将很满意于这种整
体上的描述。
   初始时，shell程序执行它的指令，等待我们输入一个命令。当我们在键盘上输入字符串
"hello"后，shell程序将字符逐一读入寄存器，再把它存放到内存中，如图1-5所示。
   当我们在键盘上敲回车键时，shell程序就知道我们已经结束了命令的输入。然后
shell执行一系列指令来加载可执行的hello文件，这些指令将hello目标文件中的代码
和数据从磁盘赋值到主存。数据包括最终会被输出的字符串helloworld
   利用直接存储器存取DMA将在第六章中讨论技术，数据可以不通过处理器而直
接从磁盘到达主存。这个步骤如下1-6所示
    一旦目标文件hello中的代码和数据被加载到主存，处理器就开始执行hello程序
的main程序中的机器语言指令。这些指令将hello world字符串中的字节从主存
赋值到寄存器文件，再从寄存器文件中赋值到显示设备，最终显示在屏幕上。这个步骤如图
1-7所示。

1.5 高速缓存至关重要
   这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方
挪到另一个地方。hello程序的机器指令最初是存放在磁盘上，当程序加载时，它们被复
制到主存；当处理器运行程序时，指令又从主存赋值到处理器。相思地，数据串helloworld
开始时在磁盘上，然后被复制到主存，最后从主存上复制到显示设备。从
程序员的角度来看，这些复制就是开销，减慢了程序真正的工作。因此，系统设计者
的一个主要目标就是使这些复制操作尽可能快的完成。
   根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高
于同类的低速设备。比如说，一个典型系统上的磁盘驱动器可能比主存打1000倍，但是对
处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍。
   类似的，一个典型的寄存器文件值存储几百字节的信息，而主存里可存放几十亿字
节。然后，处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。更麻烦的是，
随着这些年半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器
的运行速度比加快主存的运行速度要容易和便宜得多。
   针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为高
速缓存存储器(cache memory,简称为cache或高速缓存)，作为暂时的集结区域，存放处
理器近期可能会需要的信息。图1-8展示了一个典型系统中的高速缓存存储器。位于处理
器芯片上的L1高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样
快。一个容量为数十万到数百万字节的更大的L2高速缓冲通过一条特殊的总线连接到处理器
。进程访问L2高速缓冲的时间要比访问L1高速缓存要比访问L1高速缓存的时间长5倍，但是这仍然比
访问主存的时间快5-10倍。L1和L2高速缓存是用一种叫做静态随机访问存储器SRAM
的硬件技术实现的。比较新的、处理能力更强大的系统设置有三级高速缓存：L1l2和L3
。系统可以获得一个很大的存储器，同事访问速度也很快，原因是利用了高速缓存的局
部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能
经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。
   本书得出的重要结论之一就是，意识到高速缓存存储器存在的应用程序员能够利用高速缓存
将程序的性能提高一个数量级。你将在第六章里学习这些重要的设备以及如何利用它们。

1.6 存储设备形成层次结构
   在处理器和一个较大较慢的设备之间插入一个更小更快的存储设备(例如
高速缓存)的想法已经成为一个普遍的观念。实际上，每个计算机系统中的存储设备都
被组织称了一个存储器层次结构，如图1-9所示。在这个层次结构中，从上至下，设备的访
问速度越来越慢、容量越来越大，并且每个字节的造假也越来越便宜。寄存器文件在层次结构
中位于最顶部，也就是第0级或者L0。这里我们展示的是三层高速缓存L1到L3，
占据存储层次结构的第1层到第3层。主存在第4层，以此类推。
寄存器
L1高速缓存
L2高速缓存
L3高速缓存
主存DRAM
本地二级存储 本地磁盘
远程二级存储。

  存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。因此，
寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存
的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中，本
地磁盘就是存储在其他系统中的磁盘上的数据的高速缓存。
   正如可以运用不同的高速缓存的只是来提高程序性能一样，程序员同样可以利用对整
个存储器层次结构的理解来提高程序性能。第六章将更详细地讨论这个问题。

1.7 操作系统管理硬件
    让我们回到hello程序的例子。当shell加载和运行hello程序时，以及hello程序输
出自己的消息时，shell和hello程序都没有直接访问键盘、显示器、磁盘或者主存。取而代之
的是，他们依靠操作系统提供的服务。我们可以吧操作系统看成是应用程序和硬件之间
插入的一层软件，如图1-10所示。所有应用程序对硬件的操作尝试都必须通过操作系统。

  操作系统有两个基本功能：1防止硬件被失控的应用程序滥用；2.向应用程序
提供简单一直的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个
基本的抽象概念(进程、虚拟内存和文件)来实现这两个功能，如图1-11所示，文件是对
IO设备的抽象表示，虚拟内存是对主存和磁盘io设备的抽象表示，进程则是对处理器
主存和io设备的抽象表示。我们将依次讨论每种抽象表示。

multics
unix
linux
1.7.1 进程
    像hello这样的程序在现代系统上运行时，操作系统会提供一种假象，就好像系统上只有
这个程序在运行。程序看上去是独占地使用处理器、主存和IO设备。处理器看上去就像
在不间断地一条接一条的执行程序中的指令，即该程序的代码和数据是系统内存中唯一的对
象。这些假象是通过进程的概念来实现的，进程是计算机科学中最重要和最成功的概念之一。
    进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个
进程，而每个进程都好像在独占地使用硬件。而并非运行，则是说一个进程的指令和另一个
进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的
CPU个数的。传统系统在一个时刻只能执行一个程序，而现今的多核处理器同事能够执行多个
程序。无论是在单核还是多核系统中，一个CPU看上去都像是在并发地执行多个
进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制成为上下文
切换。为了简化讨论，我们只考虑包含一个CPU的单处理器系统的情况。我们会在
1.9.2节中讨论多处理器系统。
    操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，包括许
多信息，比如PC和寄存器文件的当前值，以及主存的内容。在任何一个时刻，但处理器
系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程
时，就会进行上下文切换，即保持当前进程的上下文、恢复新进程的上下文，然后将控制
权传递到新进程。新进程就会从它上次停止的地方开始。图1-12展示了示例hello程
序运行场景的基本理念。
   示例场景中有两个并发的进程:shell进程和hello进程。最开始，只有shell进程在
运行，即等待命令行上的输入。当我们让它运行hello程序时，shell通过调用一个专门的
函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统
保持shell进程的上下文，创建一个新的hello进程及其上下文，然后将控制权传给新的
hello进程。hello进程终止后，操作系统恢复shell进程的上下文，并将控制权传回
给它，shell进程会继续等待下一个命令行输入。
   如图1-12所示，从一个进程到另一个进程的转化是由操作系统内核kernel管理的。
内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写
文件，它就执行一条特殊的系统调用systemcall指令，将控制权传递给内核。然后内核执行
被请求的操作并放回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理
全部进程所用代码和数据结构的集合。
   实现进程这个抽象概念需要低级硬件和操作系统之间的紧密合作。我们将在第八章中揭示
这些工作的原理，以及应用程序时如何创建和控制他们的进程的。

1.7.2 线程
     尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上
可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码
和全局数据。由网络服务器中对并行处理的需求，线程称为原来越重要的编程模型，
因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。
当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法，我们将
在1.9.2节中讨论这个问题。在第12章中，你将学习并发的基本概念，包括如何写线程化的程序。
1.7.3 虚拟内存
   虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用
主存。每个进程看到的内存都是一致的，称为虚拟地址空间。图1-13所示的是linux进程的
虚拟地址空间(其他unix系统的设计也与此类似)。在linux中，地址空间最上面的区域是
保留给操作系统中的代码和数据的，这对所有进程来说都是一样的。地址空间的底部区域UCUN方
用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。
  每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。在
本书的后续章节你将学到更多有关这些区的知识，但是先简单了解每一个区是非常有益的
我们从最低的地址开始，逐步向上介绍。
  程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和
  C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，
  在示例中就是可执行文件hello。在第七章我们研究连接和加载时，你会学习更多有关地址空间的内容。
   
   堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被
   制定了大小，与此不同，当调用像malloc和free这样的C标准库函数时，堆可以
   在运行时的动态扩展和收缩。在第九章学习管理虚拟内存时，我们将更详细地研究堆。
   
   共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数据库这样的共享的
   代码和数据的区域。共享库的概念非常强大，也相当难懂。在第七章介绍动态链接时
   将学习共享库是如何工作的。
   
    * 栈 。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一
    样，用户栈在程序执行期间可以动态地拓展和收缩。特别地，每次我们调用一个函数
    时，栈就会增长；从一个函数返回时，栈就会收缩。在第三章中将学习编译器是如何
    使用栈的。

   * 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区
   域的内容或者直接调用内核代码定义的函数。相反，他们必须调用内核来执行这些操作。
   
     虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互，包括对处理器生成的每
个地址的硬件翻译。基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为
磁盘的高速缓存。第九章将解释他是如何工作，以及为什么对现代系统的运行如此重要。
1.7.4 文件
    文件就是字节序列，仅此而已。每个IO设备，包括磁盘、键盘、显示器、甚至网络
，都可以看成是文件。系统中的所有输入输出都是通过使用1小组成为UNIXioDE 系统函数
调用读写文件来实现的。
    文件这个简单而精致的概念是非常强大的，因为它向应用程序提供了一个统一的视图
，来看待系统中坑你含有的所有各个各样的IO设备。例如、处理磁盘文件内容的应用
程序可以非常幸福，因为它们抚恤了解具体的磁盘技术。进一步说，同一个程序可以在
使用不同磁盘技术的不同系统上运行。你将在地址张中学习unixio


1.8 系统之间利用网络通信
   系统漫游至此，我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上，
现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个IO设备，
如图1-14所示。但该系统从主存赋值遗传字节到网络适配器时，数据流经过网络到达另一台机器。
而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，
并把数据赋值到自己的主存。
   随着internet这样的全球网络的出现，从一台主机复制信息到另外一台主机已经成为
计算机系统最重要的用途之一。比如，像电子邮件、即时通信、万维网、FTP和telnet这样
的应用都是基于网络复制信息的功能。
  回到hello示例，我们可以使用熟悉的telnet应用在一个远程主机上运行hello程
序。假设用本地主机上的telnet客户端连接远程主机上的telnet服务器。在我们等于到远
程主机并运行shell后，远端的shell就在等待接收输入命令。此后在远端运行hello程序
包括突入15所示的五个基本步骤。
     
     当我们在telnet客户端键入hello字符串并敲下回车后，客户端软件就会将这
个字符串发送到telnet的服务器。telnet服务从网络上接收到这个字符串后，会把它传
递给远程shell程序。接下来，远端shell运行hello程序，并将输出行返回给telnent服务器
。最后，特林恩图服务器通过网络吧输出穿转发给特拉能客户端，客户端就将输出穿输出到我们
的本地终端上。
   这种客户端和服务器之间交互的类型在所有的网络应用中是非常经典的。在第11章
中，你将会学会如何构造网络应用程序，并利用这些知识创建一个简单的web服务器。
1.9 重要主题
    在此，小结一下我们旋风式的系统漫流。这次讨论得出一个很重要的观点，那就是系统
不仅仅只是硬件。系统是硬件和系统软件互相交织的集合体，他们必须共同协作以达到
运行应用程序的最终目的。本书的鱼虾部分会讲述硬件和软件的详细内容，通过了解这些
详细内容，你可以写出更快速、更可靠和更安全的程序。
   作为本章的阶数，我们在此强调几个贯穿计算机系统所有方面的重要概念。我们会在本书
   中多处讨论这些概念的重要性。
1.9.1 Amdahl 定律
     Gene amdahl 计算机领域的早期先锋之一，对提升系统某一部分性能锁带来的效果做
出了简单却又见地的观察。这个观察被称为amdahl定律。该定律的主要思想是，
当我们对系统的某个部分加速时，其对系统整体性能的影响去决定于该部分的重要性
和加速程序。若系统执行某应用程序需要时间为Told.假设系统某部分所需执行时间与
该时间的比例为a，而该部分性能提升比例为K，技改部分初始所需时间为aTold，现在所需时间
为
   举个例子，考虑这样的一种情况，系统的某个部分初始耗时比例为60%,其加速比
例因子为3，。则我们可以获得的加速比1.67倍。虽然我们对系统的
一个主要部分作出了重大改进，但是获得系统加速比却明显小于这部分的加速比。这就是
amdahl定律的主要观点---要向显著加速整个系统，必须提升系统中相当大的部分的速度。
   
1.9.2 并发和并行
     数字计算机的整个历史中，有两个需求是驱动进步的持续动力：一个是我们想要计算
机做的更多，另一个是我们想要计算机运行得更快。当处理器能够同时做更多的事情时，
这两个因素都会改进。我们用的术语并发concurrentcy是一个通用的概念，指一个同时具
有多个活动的系统；而术语并行parallelism指的是用并发来使用系统运行更快。并
行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中由高到低的
顺序强调三个层次。
   
1.线程级并发
   构建在进程这个抽象只想，我们能够设计出同事有多个程序执行的系统，这就导致了
并发。使用线程，我们设置能够在一个进程中执行多个控制流。自初期出现
时间共享以来，计算机系统中就开始有了对并发执行的支持。传统意义上，这种并发执行
只是模拟出来的，通过使一台计算机在它正在执行的进程间快速切换来实现的，就好像
一个杂耍艺人保持多个球在空中飞舞一样。何种并发形式允许多个用户同事与系统交互，
例如，在要给窗口开启web浏览器，在另一个窗口运行字处理器，同事有播放音乐。
在以前，即是处理器必须在多个任务间切换，大多数实际的计算也都是由一个处理器
来完成的。这种配置成为单处理器系统。
     当构建一个由单操作系统内核控制的多处理器组成的系统时，我们就得到了一个多处理器系统。
其实从，在大规模的就死按照就有了这种系统，单知道最近，随着多核处理器和超线程hyperthreading的出现
这种系统才变得常见。
  多核处理器是将多个CPU集成到一个集成电路芯片上。图17描述的是一个
  典型多核处理器的组织结构，其中微处理器芯片有四个cpu核，每个核心都有自己的L1和L2
高速缓存，其中的L1高速缓存分为两个部分，一个保持最近渠道的指令，另一个存放数据。
这些核共享更高层次的高速缓存，以及到主存的接口。工业界的专家预言他们能够将
几十个、最终会是上百个核做到一个芯片上。
   
   超线程，有时成为同时多线程simulaneous multi-threading，是一项允许一个CPU
执行多个控制流的技术。它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件
，而其他的硬件部分只有一份，比如执行浮点算数运算的单元。常规的处理器需要大约
10000个时刻周期做冉线程间的转化，而超线程的处理器可以在单个周期的基础上决定要
执行那一个线程。这使得CPU能够更好抵用它处理资源。比如，假设一个线程必须
等到某些数据被状态到高速缓存中，那CPU就可以继续去执行另一个线程。距离来说，
intercorei7 处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行地
执行8个线程。
   多处理器的使用可以从两个方面提供系统性能。首先，它减少了再执行多个任务时候模拟
并发的需要。正如前面提到的，即是是只有一个用户使用的个人计算机也需要并发地执行
多个活动。其次，它可以是用用程序运行得更快，当然，这必须要求程序员是以多线程方式
来书写的，这些线程可以并行地高效执行。因此，虽然并发原理的形成和研究已经超过50年
的时间了，但是多核和超线程系统的出现才极大地激发了一种愿望，即找到书写应用程
序的方法利用硬件开发线程级并行性。第12章会更深入地探讨并发，以及使用并发来提供
处理器资源的共享，使程序的执行允许有更多的并行。


2.指令级并行
  在较低的抽象层次上，现代处理器可以同时执行多条指令的属性成为指令集并行。早期
  的微处理器，如1987年的interl8086，需要多个通常是3-10个时钟周期来执行一条
  指令。最近的处理器可以保持每个时钟周期2-4条指令的执行速率。其实每条指令从
开始到结束需要长得多的时间，大约20个或者跟多周期，但是处理器使用了非常多的聪明
技巧来同事处理多大100条指令。在第4章中，我们会研究流水线pipelining的使用。在
流水线中，将执行一条指令所需的活动划分成不同的步骤，将处理器的硬件组织称以锡类
的极端，每个阶段执行一个步骤。这些阶段可以并性地操作，用来处理不同指令的不同
部分。我们会看到一个相当简单的硬件设计，它能够达到接近于一个时钟周期一条指令的
执行速率。
   如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量super
scalar处理器。大多数现代处理器都支持超标量操作。第五章中，我们将描述超标量处理器
的高级模型。应用程序员可以用这个模型来理解程序的性能。然后，他们就能写出拥有
更高程序的指令集并行性的程序代码，因而也运行得更快。
   2.单指令、多数据并行
   在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行
的操作，这种方式成为单指令、多数据，即simd并行。例如，叫心计带的intel和
AMD处理器都具有并性地对8对单精度浮点数做加法的指令。
    提供这些SIMD指令多事为了提高处理影像、声音和视频数据应用的执行速度。虽然
有些编译器会试图从C程序中自动抽取SIMD并行性，但是更可靠的方式是用编译器支持
的特殊的向量数据类型来写程序，比如GCC就支持向量数据类型。作为对第五章中比较
通用的程序优化描述的补充，我们在网络旁注OPT SIMD中描述了这种编程方式。
   
1.9.3 计算机系统中抽象的重要性
   抽象的使用时计算机科学中最为重要的概念之一。例如为一组函数规定一个简单的
应用程序接口API就是一个很好的编程习惯，程序员无须了解它内部的工作便可以使用
这些代码。不同的编程语言提供不同形式和登记的抽象支持，例如java类的生命和C语言
的函数原型。
   我们已经介绍了计算机系统中使用的几个抽象，。在处理器中，指令集
架构提供了对实际处理器硬件的抽象。使用这个抽象，机器代码程序表现得就好像运行
在一个一次只执行一条指令的处理器上。底层的硬件远比描述的要复杂精细，它并行
地执行多条指令，但又总是与那个简单有序的模型保持一致。只要执行模型一样，不同的
处理器实现也能执行同样的机器代码，而有提供不同的开销和性能。
    在学习操作系统时，我们介绍了三个抽象:w文件是对IO设备的抽象，虚拟机内存是对
程序存储器的抽象，而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象：
虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。虚拟机的思想是
IBM在60年代提出来的，但是最近才显示出其管理计算机方式的优势，因为一些计算机必须能够
运行为不同的操作系统 windows os linux
或同一操作系统的不同版本设计的程序。
    在本书后续的章节中，我们会具体介绍这些抽象。
1.10 小结
    计算机系统是由硬件和系统软件组成的，他们共同协作运行应用程序。计算机内部的信息被表示
为一组组的位，他们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是
ASII文件，然后被编译器和连接器翻译成二进制可执行文件。
   处理器读取并解释存放在二进制指令。因为计算机划分了大量的时间在内存IO设备和
CPU寄存器之间的复制数据，所以将系统中的存储设备划分成层次结构--CPU寄存器在顶部，接着
是多层的硬件高速缓存存储器‘DRAM主存和磁盘存储器。在层次模型中，位于更高层的存储设备比底层
的存储设备要更快，单位比特造假也更高。层次结构中教高层次的存储设备可以作为较低层次设备的高速
缓存。通过理解和运用这种存储层次结构的只是，程序员可以优化C程序的性能。
   操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的首相1.文件是对IO设备的抽象
   2虚拟机内存是对主存和磁盘的抽象；3进程是处理器’主存和IO设备的抽象。
    最后，网络提供给了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种IO设备
   
   
   
   
   
   
   
   

**第1章**
一级学科:计算机科学与技术
二级学科:计算机系统结构、计算机软件、计算机应用技术


汇编语言


Cache一致性问题:
1.1 Cache Coherence 一致性 问题

core1   Cache1   shared memory
core2   Cache2   shared memory

原子性 可见性 顺序性
I.缓存一致性问题的原因

1:共享可写数据的不一致性(sharing of writable data)共享数据没同步到其它Cahce

2:进程迁移的不一致性;进程切换CPU导致

3:I/O操作（绕过Cache的I/O操作）:输入输出设备写入数据到Cache，但是Cache数据还是老数据。


1.1.3 两种设计Cache 一致性协议策略
1.写无效(write invalidate)
任一core写它的的私有Cache时，它都使所有其它的Cache中的副本失效。
对Write-through,它也更新memory中的副本（最终是一个Cache中的副本和memory中的副本是有效的）。
对Write-back,它使memory中的副本也失效（最终只有一个Cache的副本是有效的）。

2.写更新(write update)
任一处理器写它的私有Cache时，它都立即更新所有其它的Cache中的副本。
对Write-through,它也更新主存储器中的副本。
对Write-back,对存储器中副本的更新延迟到这个Cache被置换的时刻。


3.示意图

4.写无效的问题
主要开销在两个方面
1.作废各Cache副本的开销
2.由作废引起缺失造成的开销，即处理机需要访问已经作废的数据时引起Cache的缺失。

后果:
如果一个Core经常对某个块连续写，且Core间对共享块的竞争较小，这时写无效策略维护
一致性的开销是很小的。如发生严重竞争，即Core之间对某个地址的共享数据竞争，
将产生较多的作废，引起更多的作废缺失。结果是共享数据在各Cache间倒来倒去，
产生颠簸现象，当缓存块比较大时，这种颠簸现象更为严重。


5.写更新的问题
由于更新时，所有的副本均需要更新，开销很大。

1.2 监听总线协议(Snoopy protocol)

通过总线监听机制实现Cache和共享存储器之间的一致性。

适用性分析：
    适用于具有广播能力的总线结构多Core系统，允许每个Core监听其它Core的存储器访问情况。
    
   只适用于小规模的多Core系统。

1.2.1 写一次(write-once)协议
      写无效监听一致性协议，将通过和写回策略结合。      
   为了减少总线流量，高速缓冲块的第一次写用写通过方法，产生一份正确的主存储器副本，
并使其它的Cache中的副本无效，之后就采用写回方法更新Cahce与主存储器。

1.一致性协议的内容
  (1)Cache可能出现的状态集合
  (2)共享主存的状态
  (3)为维护一致性而引起的状态转换

2.每份Cache中的副本可能出现的四种状态
    (1)有效(valid state):与主存器副本一直的Cache副本，即该副本未经修改，所以这个Cache副本不是唯一的副本。
    (2)保留(reserved state):这个Cache副本是第一次修改，并用写通过方法写入主存，所以这个Cache副本和主存器副本是一致。
    (3)重写(dirty state):Cache副本不止一次被修改过，由于不再采用写通过方法，所以这个Cache副本是唯一的副本。与存储器和其它的Cache副本都不一致。主存器中的副本也是无效的。
    (4)无效(invalid state):与存储器或其它的Cache副本不一致，或在Cache中找不到。

3.局部命令(Local commands)

(1)P-Read ：本地处理机读取自己的Cache副本。
(2)P-Write: 本地处理机写自己的Cache副本。

4.一致性命令
(1)Read-blk:从另一Cache读一份有效的副本。
(2)Write-inv:在写命中时在总线上广播一个无效命令。
(3)Read-inv:在写缺失时在总线上广播一个无效命令。

5.Write-Once 一致性协议状态转移图
四种状态的含义:
Dirty:修改不止一次；多次重写(只有它有效，其它cache和memory都是无效)
Invalid:无效状态。
Reserved:保留状态;只被修改过一次。
Valid:有效的；从未被修改过的。


1.2监听总线协议
通过总线监听机制实现Cache和共享存储器之间的一致性。

适用性分析：
适用于具有广播能力的总线结构多Core系统，允许每个Core监听其它Core的存储器访问情况。
只适用于小规模的多Core系统




1.2 基于目录的Cache一致性协议
2. 基于目录的一致性协议的基本思想(只发送给存放该副本的Cache)
  当Core个数增加时，一般不用总线结构，而采用多级互联网络。多级互联网实现广播功能代价很大。
  能不能只发送给存放该副本的Cache
  
  

1.3基于目录的Cache一致性协议 适应很多core






什么是并行处理
1.同时性simultaneity
两个或多个时间在同一时刻发生

2.并发性concurrency
两个或多个时间在同一时间间隔内发生。

3.流水特性
在一个重叠的时间内所发生的的流水事件。


粒度granularity
衡量一个软件进程的计算量的度量，最简单的是指此程序段中的指令数
细粒度：用并行化或向量化编译器来开发，共享变量通信支持。

中粒度：靠程序员和编译器一起开发，共享变量通信。

粗粒度：取决于操作系统和算法的效率，消息传递通信。


并行性级别
按粒度的不同，并行性级别可以分为:
1.指令级并行
典型细粒度，一般少于20条指令。借助优化编译器自动检测并行性，将源代码变成运行时系统能识别的并行形式。

2.循环级并行
典型循环含少于500条指令，由于有些循环操作在连续迭代中并不相关，易于向量化，是并行机或向量机上运行的最优程序结构。递归循环的并行化比较困难。向量处理由优化编译器在循环级开发，仍属于细粒度计算。

3.过程级并行

4.子程序级并行

5.作业级并行



为什么要开发并行处理技术

单用户:
可以提高加速比（Speedup Oriented)

多用户:
可以提高吞吐率（Throughput Oriented)



第一章
操作系统漫游
   
   计算机系统是由硬件和系统软件组成的，它们共同工作来运行应用程序。虽然系统的
具体实现方式随着时间不断变化，但是系统内在的概念却没有改变。所有计算机系统都有
相似的硬件和软件组成，它们又执行着相似的功能。一些程序员希望深入了解这些组件是
如何工作的以及这些组件是如何影响程序的正确性和性能的，以此来提高自身的技能。本
书便是为这些读者而写的。
   现在就要开始一次有趣漫游历程了。如果你全力投身学习本书中的概念，完全理解底层
计算机系统以及它对应用程序的影响，那么你会步上成为为数不多的大牛的道路。
  你将会学习一些实践技巧，比如如何避免由计算机表示数字的方式引起的奇怪的数字
错误。你将会学怎样通过一些小窍门来优化自己的C代码，以充分利用现代处理器和存储
器系统的设计。你将了解编译器是如何实现过程调用的，以及如何利用这些知识来避免缓
冲区溢出错误带来的安全漏洞，这些弱点给网络和因特网软件带来了巨大的麻烦。你将学
会如何识别和避免连接时那些令人讨厌的错误，它们困扰着普通的程序员。你将学会如何
编写自己的Unix shell、自己的动态存储分配包，甚至于自己的web服务器。你会认识并发
带来的希望和陷阱，这个主题随着单个芯片上集成了多个处理器核变得越来越重要。
   在kernighan和ritchie的关于C编程语言的经典教材中，他们通过所示的
hello程序来向读者介绍C。尽管hello程序非常简单，但是为了让它实现运行，系统
的每个主要组成部分都需要协调工作。从某种意义上来说，本书的目的就是要帮助你了解
当你的系统上执行hello程序时候，系统发生了什么以及为什么会这样。
   我通过跟踪hello程序的生命周期来开始对系统的学习   从它被程序员创建开始，
到在系统上运行，输出简单的消息，然后终止。我们将沿着这个程序的生命周期，简要地介
绍一些逐步出现的关键概念、专业术语和组成部分。后面的章节将威少这些内容展开。

1.1  信息就是位+上下文
   hello程序的生命周期是从一个源程序开始的，即程序员通过编辑器创
建并保持的文本文件，文件名是hello.c。源程序实际上就是一个由值0和1组成的位(又称
位比特)序列，8个位被组织称一组，成为字节。每个字节表示程序中的某些文本字符。
   大部分的现代计算机系统都使用ASCII标准来表示文本字符，这种方式实际上就是用
一个唯一的单字节达标的整数值来表示每个字符。比如，图1-2中给出了hello。c程序
的ascii码表示。
    hello.c程序是以字节序列的方式存储在文件中的。每个字节都有一个整数值，对应
于某些字符。例如，第一个字节的整数值是35，它对应的就是字符#。第二个字节的
整数值位105，它对应的字符是i，依次类推。注意，每个文本行都是以一个看不见的
换行符\n来结束的，它所对应的整数值位10.想helloc这样只有ascii字符构成
的文件成为文本文件，所有其他文件都成为二进制文件。
   hello.c的表示方法说明了一个基本思想：系统中所有的信息--包括磁盘文件、内
存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由遗传比特表示的。区
分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文
中，一个统一的字节序列可能表示一个整数、浮点数、字符串或者机器指令。
   作为程序员，我们需要了解数字的机器表示方式，因为它们与实际的整数和实数是不
同的。它们是对真值的有限近似值，有时候会有意向不到的行为表现。这方便的基本原理
将在第二章中详细描述

1.2 程序被其它程序翻译成不同的格式
   hello程序的生命周期是从一个高级C语言程序开始的，因为这种形式能够被人读
懂。然后，为了在系统上运行hello.c程序，每条C语言都必须被其他程序转化为一系
列的低级机器语言指令。然后这些指令按照一种称为可执行目标程序的格式打好包，并以
二进制磁盘文件的形式存放起来。目标程序也称为可行性目标文件。
  在unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的:
  linux>gcc -o hello hello.c
   在这里，GCC编译器驱动程序读取源程序文件hello.c，并把它翻译成一个可执行
目标文件hello。这个翻译过程可分为四个阶段完成，图1-3所示。执行这四个阶段的
程序(预处理器、编译器、汇编器和连接器)一起构成了编译系统(compilation system)
* 预处理阶段。预处理器CPP根据以字符#开头的命令，修改原始的C程序。比如
hello.c中第一行的#include<stdio.h>命令告诉预处理器读取系统头文件
stdio.h的内容，并把它直接插入程序文件中。结果就得到了另一个C程序，通常
是以.i作为文件拓展名。
* 编译阶段。编译器CCL将文件文本hello。i翻译成文本文件hello.s，它包含一个
汇编语言程序。该程序包含函数main的定义，如下所示：
main:
subq &8,%rsp
movl $.LC0,%edi
call puts
movl $0,%eax
addq $8,%rsp
ret
  定义中2-7行的每条语句都以一种文本格式描述了一条低级机器语言指令。
汇编语言是非常有用的，因为它为不同高级语言的不同编译器提供了通用的输出语言
例如,c编译器和FOrtran编译产生的输出文件用的都是一样的汇编语言。
* 汇编阶段。接下来，汇编器as将hello。s翻译成机器语言指令，把这些指令打包成
一种叫做可重定位目标程序relocatable object program的格式，并将结果保存在目标文件hello.o中
hello。o文件是一个二进制文件，它包含的17个字节是函数main的指令编码。如果我们在文本
编辑器中打开hello.o文件，将看到一堆乱码。
* 链接阶段。请注意，hello程序调用了PRINTF函数，它是每个C编译器都提供的
标准C库中的一个函数。printf函数存在于一个名为printf.o的单独的预编译
好了的目标文件中，而这个文件必须以某种方式合并到我们的hello.o程序中。连接器
ld就负责处理这种合并。结果就得到hello文件，它是一个可行性目标文件，可以被加载到内存中，
由系统执行

1.3 了解编译系统如何工作时大有益处的
   对于像hello.c这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。
但是，有一些重要的原因促使程序员必须知道编译系统是如何工作的。
   *优化程序性能。现代编译器都是成熟的工作，通常可以生成很好的代码。作为程序员
，我们无需为了写出高效代码而去了解编译器的内部工作。但是，为了在c程序中
做出好的编码选择，我们确实需要了解一些机器代码以及编译器将不同的C语句转化为
机器代码的方式。比如，一个switch语句是否总比一系列的ifelse语句高效的多
一个函数调用的开销有多大？while循环比for循环更有效吗指针引用比数组
索引更有效吗？为什么将循环求和的结果放到一个本地变量中，回避将其放到一个
通过引用传递过来的参数中，运行起来块很多呢？为什么我们只是简单地重新排列一
下算法表达式中的括号就能让函数运行的更快？
    在第三章中，我们将介绍x86-64,最近系带linux、macintosh和windows计算机的
机器语言。我们会讲述编译器是怎样把不同的C语言结果翻译成这种机器语言的。在第五章中
，你将学习如何通过简单转换C语言代码，帮助编译器更好地完成工作，从而调整
C程序的性能。在第六章中，你将学习存储器系统的层次结果特性，C语言编译器ruhe将
数组存放在内存中，以及C程序又是如何能够利用这些知识从而更高效地运行。
* 理解连接时出现的错误。 根据我们的经验，一些最令人困扰的程序错误往往都与连接器
操作有关，尤其是当你师徒构建大型的软件系统时。比如连接器报告说它无法解析
一个引用，这是什么意思？静态变量和全局变量的区别是什么？如何你再不同的C文件中
定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别
是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么哟西额连接
错误知道运行时才会出现？在第七章中，你将得到这些问题的答案。
* 避免安全漏洞。多年来，缓冲区溢出错误是造成大多数网络和internet服务器上安全
漏洞的主要原因。存在这些错误是因为很少有程序员能够理解需要限制从不受信任
的源接受数据的数量和格式。学习安全编程的第一步就是理解数据和控制信息存储
在程序栈上的方式会引起的后果。作为学习汇编语言的一部分，我们将在第三种中
描述对战原理和缓冲区溢出的错误。我们还将学习程序员、编译器和操作系统可以
用来降低攻击威胁的方法。

1.4 处理器读并解释存储在内存中的指令
   此刻，hello.c源程序已经被编译系统翻译成了可执行目标文件hello,并被存放在
磁盘上。要向在unix系统上运行该可执行文件，我们讲他的文件名输入到成为shell的引用程序中：
linux>./hello
hello,world
linux>
     shell是一个命令行解释器，它输出一个提示符，等待输入一个命令行，然后执行这个
命令。如果该命令行的第一个单词不是一个内置的shell命令，那么shell就会假设这是
一个ke执行文件的名字，它将加载并运行这个文件。所以在此例中，shell将加载并运行
hello程序，然后等待程序终止。hello程序在屏幕上输出它的消息，然后终止。shell
随后输出一个提示符，等待下一个输入的命令行。
1.4.1系统的硬件组成
  为例理解运行hello程序时发生了什么，我们需要了解一个典型系统的硬件组织，如图
1-4所示。这张图是近期intel系统产品族的模型，但是所有其他系统也有相同的外观
和特性。现在不要担心这张图很复杂--我们将在本书分阶段对其进行详尽的介绍。

 1.总线
 贯穿整个系统的是一组电子管道，称作总线，它携带信息字节并负责在各个部件间传
递。通常总线被设计成传送定长的字节块，也就是字word。字中的字节数即字长是一个
基本的系统参数，各个系统中都不进相同。现在的大多数机器字长要么是4个字节32位
要么设计8个字节64位。本书中，我们部队字长做任何固定的假设。相反，我们将在
需要明确定义个上下文中具体说明一个字是多大。

 2.IO设备
 IO设备是系统与外部世界的联系通道。我们的示例系统包括四个IO设备
作为用户输入的键盘和鼠标，作为用户输出的显示器。以及用于长期存储数据和程序
的磁盘驱动器。最开始可执行程序hello就存放在磁盘上。
每个io设备都通过一个控制器或适配器与io总线相连。控制器和适配器之间的区
别主要在于他们的封装方式。控制器是IO设备本书或者系统的主印制电路板通常称作
主板上的芯片组。而适配器则是一块插在主板插槽上的卡。无论如何，它们的功能都是在
IO总线和io设备之间传递信息。
   第六章会更多地说明磁盘指令的IO设备是如何工作的。在第十章中，你将学习如何
在应用程序中利用UNIXio访问设备。我们将特别关注网络累设备，不过这些技术
对于其他设备来说也是通用的。
 3.主存
 主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从
物理上来说，主存是一组动态随机存取存储器DRAM芯片组成的。从逻辑上来说，存储
器是一个线性的字节数组，每个字节都有唯一的地址数组索引，这些地址是从零开始
的。一般来说，组成程序的每条机器指令都由不同数量的字节构成。与C程序变量相对应的
数据项的带下是根据类型变化的。比如在运行linux的x8664机器上，short类型的数据
需要2个字节，int和floast类型需要四个字节，而long和double类型需要8个字节。
  第六章将具体介绍存储器技术，比如DRAM新品是如何工作的，他们又是如何组合
起来构成主存的。
   4.处理器
   中央处理单元CPU，简称处理器，是解释或执行存储在主存中指令的引起。处理器
的核心是一个大小为一个字的存储设备或寄存器，程序程序计数器PC。在任何时
刻，PC都执行主存中的某条机器语言指令（即含有该条指令的地址）。
  从系统通电开始，知道系统断点，处理器一直在不断地执行程序计数器只想的指令。
再更新程序计数器，使其指向下一条执行令，处理器看上去是按照一个非常简单的指令执行
模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行
，而执行一条指令包含执行一系列的步骤。处理器从程序计数器只想的内存处读取指
令，解释指令中的位，执行该指令执行的简单操作，然后更新PC，使其指向下一条指令，
而这条执行令并不一定和在内存中刚刚执行的指令相邻。
  这样的简单操作并不多，他们围绕着主存、寄存器文件register file和算数 逻辑单元
ALU进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个
寄存器都有唯一的名字。ALU计算新的数据和地址值。下面是一些简单操作的例子，
CPU在指令的要求下可能会执行这些操作。
加载:从主存赋值一个字节或一个字到寄存器，以覆盖寄存器原来的内容。
存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置上原来的内容。
操作：把两个寄存器的内容赋值到ALU，ALU对着两个字做算术运行，并将结果
存放到一个寄存器中，以覆盖该寄存器中原来的内容。
跳转：从指令本书中抽取一个字，并将这个字复制到程序计数器PC中，以覆盖
PC中原来的值。
   处理器看上去是它的指令集架构的简单实现，但是实际上现代处理器使用了非常负载的
的机制来加速程序的执行。因此，我们将处理器的指令集架构和处理器的微体系结构区分开来：
指令集架构描述的是每条机器代码指令的效果；而微体系结构的是处理器实际
上市如何实现的。在第三种研究机器代码时，我们考虑的是机器的指令集架构锁提供的抽象性。
第四章将更消息地介绍处理器实际上是入额实现的。第五章用一个模型说明现代处
理器是如何工作的，从而能预测和优化机器语言程序的性能。

1.4.2 运行hello程序
   前面简单描述了系统的硬件组成和操作，现在开始介绍当我们运行示例程序时到底发
生了些什么。在这里必须省略很多细节，稍后会做补充，但是现在我们将很满意于这种整
体上的描述。
   初始时，shell程序执行它的指令，等待我们输入一个命令。当我们在键盘上输入字符串
"hello"后，shell程序将字符逐一读入寄存器，再把它存放到内存中，如图1-5所示。
   当我们在键盘上敲回车键时，shell程序就知道我们已经结束了命令的输入。然后
shell执行一系列指令来加载可执行的hello文件，这些指令将hello目标文件中的代码
和数据从磁盘赋值到主存。数据包括最终会被输出的字符串helloworld
   利用直接存储器存取DMA将在第六章中讨论技术，数据可以不通过处理器而直
接从磁盘到达主存。这个步骤如下1-6所示
    一旦目标文件hello中的代码和数据被加载到主存，处理器就开始执行hello程序
的main程序中的机器语言指令。这些指令将hello world字符串中的字节从主存
赋值到寄存器文件，再从寄存器文件中赋值到显示设备，最终显示在屏幕上。这个步骤如图
1-7所示。

1.5 高速缓存至关重要
   这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方
挪到另一个地方。hello程序的机器指令最初是存放在磁盘上，当程序加载时，它们被复
制到主存；当处理器运行程序时，指令又从主存赋值到处理器。相思地，数据串helloworld
开始时在磁盘上，然后被复制到主存，最后从主存上复制到显示设备。从
程序员的角度来看，这些复制就是开销，减慢了程序真正的工作。因此，系统设计者
的一个主要目标就是使这些复制操作尽可能快的完成。
   根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高
于同类的低速设备。比如说，一个典型系统上的磁盘驱动器可能比主存打1000倍，但是对
处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍。
   类似的，一个典型的寄存器文件值存储几百字节的信息，而主存里可存放几十亿字
节。然后，处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。更麻烦的是，
随着这些年半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器
的运行速度比加快主存的运行速度要容易和便宜得多。
   针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为高
速缓存存储器(cache memory,简称为cache或高速缓存)，作为暂时的集结区域，存放处
理器近期可能会需要的信息。图1-8展示了一个典型系统中的高速缓存存储器。位于处理
器芯片上的L1高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样
快。一个容量为数十万到数百万字节的更大的L2高速缓冲通过一条特殊的总线连接到处理器
。进程访问L2高速缓冲的时间要比访问L1高速缓存要比访问L1高速缓存的时间长5倍，但是这仍然比
访问主存的时间快5-10倍。L1和L2高速缓存是用一种叫做静态随机访问存储器SRAM
的硬件技术实现的。比较新的、处理能力更强大的系统设置有三级高速缓存：L1l2和L3
。系统可以获得一个很大的存储器，同事访问速度也很快，原因是利用了高速缓存的局
部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能
经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。
   本书得出的重要结论之一就是，意识到高速缓存存储器存在的应用程序员能够利用高速缓存
将程序的性能提高一个数量级。你将在第六章里学习这些重要的设备以及如何利用它们。

1.6 存储设备形成层次结构
   在处理器和一个较大较慢的设备之间插入一个更小更快的存储设备(例如
高速缓存)的想法已经成为一个普遍的观念。实际上，每个计算机系统中的存储设备都
被组织称了一个存储器层次结构，如图1-9所示。在这个层次结构中，从上至下，设备的访
问速度越来越慢、容量越来越大，并且每个字节的造假也越来越便宜。寄存器文件在层次结构
中位于最顶部，也就是第0级或者L0。这里我们展示的是三层高速缓存L1到L3，
占据存储层次结构的第1层到第3层。主存在第4层，以此类推。
寄存器
L1高速缓存
L2高速缓存
L3高速缓存
主存DRAM
本地二级存储 本地磁盘
远程二级存储。

  存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。因此，
寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存
的高速缓存，而主存又是磁盘的高速缓存。在某些具有分布式文件系统的网络系统中，本
地磁盘就是存储在其他系统中的磁盘上的数据的高速缓存。
   正如可以运用不同的高速缓存的只是来提高程序性能一样，程序员同样可以利用对整
个存储器层次结构的理解来提高程序性能。第六章将更详细地讨论这个问题。

1.7 操作系统管理硬件
    让我们回到hello程序的例子。当shell加载和运行hello程序时，以及hello程序输
出自己的消息时，shell和hello程序都没有直接访问键盘、显示器、磁盘或者主存。取而代之
的是，他们依靠操作系统提供的服务。我们可以吧操作系统看成是应用程序和硬件之间
插入的一层软件，如图1-10所示。所有应用程序对硬件的操作尝试都必须通过操作系统。

  操作系统有两个基本功能：1防止硬件被失控的应用程序滥用；2.向应用程序
提供简单一直的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个
基本的抽象概念(进程、虚拟内存和文件)来实现这两个功能，如图1-11所示，文件是对
IO设备的抽象表示，虚拟内存是对主存和磁盘io设备的抽象表示，进程则是对处理器
主存和io设备的抽象表示。我们将依次讨论每种抽象表示。

multics
unix
linux
1.7.1 进程
    像hello这样的程序在现代系统上运行时，操作系统会提供一种假象，就好像系统上只有
这个程序在运行。程序看上去是独占地使用处理器、主存和IO设备。处理器看上去就像
在不间断地一条接一条的执行程序中的指令，即该程序的代码和数据是系统内存中唯一的对
象。这些假象是通过进程的概念来实现的，进程是计算机科学中最重要和最成功的概念之一。
    进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个
进程，而每个进程都好像在独占地使用硬件。而并非运行，则是说一个进程的指令和另一个
进程的指令是交错执行的。在大多数系统中，需要运行的进程数是多于可以运行它们的
CPU个数的。传统系统在一个时刻只能执行一个程序，而现今的多核处理器同事能够执行多个
程序。无论是在单核还是多核系统中，一个CPU看上去都像是在并发地执行多个
进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制成为上下文
切换。为了简化讨论，我们只考虑包含一个CPU的单处理器系统的情况。我们会在
1.9.2节中讨论多处理器系统。
    操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，包括许
多信息，比如PC和寄存器文件的当前值，以及主存的内容。在任何一个时刻，但处理器
系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程
时，就会进行上下文切换，即保持当前进程的上下文、恢复新进程的上下文，然后将控制
权传递到新进程。新进程就会从它上次停止的地方开始。图1-12展示了示例hello程
序运行场景的基本理念。
   示例场景中有两个并发的进程:shell进程和hello进程。最开始，只有shell进程在
运行，即等待命令行上的输入。当我们让它运行hello程序时，shell通过调用一个专门的
函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统
保持shell进程的上下文，创建一个新的hello进程及其上下文，然后将控制权传给新的
hello进程。hello进程终止后，操作系统恢复shell进程的上下文，并将控制权传回
给它，shell进程会继续等待下一个命令行输入。
   如图1-12所示，从一个进程到另一个进程的转化是由操作系统内核kernel管理的。
内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写
文件，它就执行一条特殊的系统调用systemcall指令，将控制权传递给内核。然后内核执行
被请求的操作并放回应用程序。注意，内核不是一个独立的进程。相反，它是系统管理
全部进程所用代码和数据结构的集合。
   实现进程这个抽象概念需要低级硬件和操作系统之间的紧密合作。我们将在第八章中揭示
这些工作的原理，以及应用程序时如何创建和控制他们的进程的。

1.7.2 线程
     尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上
可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码
和全局数据。由网络服务器中对并行处理的需求，线程称为原来越重要的编程模型，
因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。
当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法，我们将
在1.9.2节中讨论这个问题。在第12章中，你将学习并发的基本概念，包括如何写线程化的程序。
1.7.3 虚拟内存
   虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用
主存。每个进程看到的内存都是一致的，称为虚拟地址空间。图1-13所示的是linux进程的
虚拟地址空间(其他unix系统的设计也与此类似)。在linux中，地址空间最上面的区域是
保留给操作系统中的代码和数据的，这对所有进程来说都是一样的。地址空间的底部区域UCUN方
用户进程定义的代码和数据。请注意，图中的地址是从下往上增大的。
  每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。在
本书的后续章节你将学到更多有关这些区的知识，但是先简单了解每一个区是非常有益的
我们从最低的地址开始，逐步向上介绍。
  程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和
  C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，
  在示例中就是可执行文件hello。在第七章我们研究连接和加载时，你会学习更多有关地址空间的内容。
   
   堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被
   制定了大小，与此不同，当调用像malloc和free这样的C标准库函数时，堆可以
   在运行时的动态扩展和收缩。在第九章学习管理虚拟内存时，我们将更详细地研究堆。
   
   共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数据库这样的共享的
   代码和数据的区域。共享库的概念非常强大，也相当难懂。在第七章介绍动态链接时
   将学习共享库是如何工作的。
   
    * 栈 。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一
    样，用户栈在程序执行期间可以动态地拓展和收缩。特别地，每次我们调用一个函数
    时，栈就会增长；从一个函数返回时，栈就会收缩。在第三章中将学习编译器是如何
    使用栈的。

   * 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区
   域的内容或者直接调用内核代码定义的函数。相反，他们必须调用内核来执行这些操作。
   
     虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互，包括对处理器生成的每
个地址的硬件翻译。基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为
磁盘的高速缓存。第九章将解释他是如何工作，以及为什么对现代系统的运行如此重要。
1.7.4 文件
    文件就是字节序列，仅此而已。每个IO设备，包括磁盘、键盘、显示器、甚至网络
，都可以看成是文件。系统中的所有输入输出都是通过使用1小组成为UNIXioDE 系统函数
调用读写文件来实现的。
    文件这个简单而精致的概念是非常强大的，因为它向应用程序提供了一个统一的视图
，来看待系统中坑你含有的所有各个各样的IO设备。例如、处理磁盘文件内容的应用
程序可以非常幸福，因为它们抚恤了解具体的磁盘技术。进一步说，同一个程序可以在
使用不同磁盘技术的不同系统上运行。你将在地址张中学习unixio


1.8 系统之间利用网络通信
   系统漫游至此，我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上，
现代系统经常通过网络和其他系统连接到一起。从一个单独的系统来看，网络可视为一个IO设备，
如图1-14所示。但该系统从主存赋值遗传字节到网络适配器时，数据流经过网络到达另一台机器。
而不是比如说到达本地磁盘驱动器。相似地，系统可以读取从其他机器发送来的数据，
并把数据赋值到自己的主存。
   随着internet这样的全球网络的出现，从一台主机复制信息到另外一台主机已经成为
计算机系统最重要的用途之一。比如，像电子邮件、即时通信、万维网、FTP和telnet这样
的应用都是基于网络复制信息的功能。
  回到hello示例，我们可以使用熟悉的telnet应用在一个远程主机上运行hello程
序。假设用本地主机上的telnet客户端连接远程主机上的telnet服务器。在我们等于到远
程主机并运行shell后，远端的shell就在等待接收输入命令。此后在远端运行hello程序
包括突入15所示的五个基本步骤。
     
     当我们在telnet客户端键入hello字符串并敲下回车后，客户端软件就会将这
个字符串发送到telnet的服务器。telnet服务从网络上接收到这个字符串后，会把它传
递给远程shell程序。接下来，远端shell运行hello程序，并将输出行返回给telnent服务器
。最后，特林恩图服务器通过网络吧输出穿转发给特拉能客户端，客户端就将输出穿输出到我们
的本地终端上。
   这种客户端和服务器之间交互的类型在所有的网络应用中是非常经典的。在第11章
中，你将会学会如何构造网络应用程序，并利用这些知识创建一个简单的web服务器。
1.9 重要主题
    在此，小结一下我们旋风式的系统漫流。这次讨论得出一个很重要的观点，那就是系统
不仅仅只是硬件。系统是硬件和系统软件互相交织的集合体，他们必须共同协作以达到
运行应用程序的最终目的。本书的鱼虾部分会讲述硬件和软件的详细内容，通过了解这些
详细内容，你可以写出更快速、更可靠和更安全的程序。
   作为本章的阶数，我们在此强调几个贯穿计算机系统所有方面的重要概念。我们会在本书
   中多处讨论这些概念的重要性。
1.9.1 Amdahl 定律
     Gene amdahl 计算机领域的早期先锋之一，对提升系统某一部分性能锁带来的效果做
出了简单却又见地的观察。这个观察被称为amdahl定律。该定律的主要思想是，
当我们对系统的某个部分加速时，其对系统整体性能的影响去决定于该部分的重要性
和加速程序。若系统执行某应用程序需要时间为Told.假设系统某部分所需执行时间与
该时间的比例为a，而该部分性能提升比例为K，技改部分初始所需时间为aTold，现在所需时间
为
   举个例子，考虑这样的一种情况，系统的某个部分初始耗时比例为60%,其加速比
例因子为3，。则我们可以获得的加速比1.67倍。虽然我们对系统的
一个主要部分作出了重大改进，但是获得系统加速比却明显小于这部分的加速比。这就是
amdahl定律的主要观点---要向显著加速整个系统，必须提升系统中相当大的部分的速度。
   
1.9.2 并发和并行
     数字计算机的整个历史中，有两个需求是驱动进步的持续动力：一个是我们想要计算
机做的更多，另一个是我们想要计算机运行得更快。当处理器能够同时做更多的事情时，
这两个因素都会改进。我们用的术语并发concurrentcy是一个通用的概念，指一个同时具
有多个活动的系统；而术语并行parallelism指的是用并发来使用系统运行更快。并
行可以在计算机系统的多个抽象层次上运用。在此，我们按照系统层次结构中由高到低的
顺序强调三个层次。
   
1.线程级并发
   构建在进程这个抽象只想，我们能够设计出同事有多个程序执行的系统，这就导致了
并发。使用线程，我们设置能够在一个进程中执行多个控制流。自初期出现
时间共享以来，计算机系统中就开始有了对并发执行的支持。传统意义上，这种并发执行
只是模拟出来的，通过使一台计算机在它正在执行的进程间快速切换来实现的，就好像
一个杂耍艺人保持多个球在空中飞舞一样。何种并发形式允许多个用户同事与系统交互，
例如，在要给窗口开启web浏览器，在另一个窗口运行字处理器，同事有播放音乐。
在以前，即是处理器必须在多个任务间切换，大多数实际的计算也都是由一个处理器
来完成的。这种配置成为单处理器系统。
     当构建一个由单操作系统内核控制的多处理器组成的系统时，我们就得到了一个多处理器系统。
其实从，在大规模的就死按照就有了这种系统，单知道最近，随着多核处理器和超线程hyperthreading的出现
这种系统才变得常见。
  多核处理器是将多个CPU集成到一个集成电路芯片上。图17描述的是一个
  典型多核处理器的组织结构，其中微处理器芯片有四个cpu核，每个核心都有自己的L1和L2
高速缓存，其中的L1高速缓存分为两个部分，一个保持最近渠道的指令，另一个存放数据。
这些核共享更高层次的高速缓存，以及到主存的接口。工业界的专家预言他们能够将
几十个、最终会是上百个核做到一个芯片上。
   
   超线程，有时成为同时多线程simulaneous multi-threading，是一项允许一个CPU
执行多个控制流的技术。它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件
，而其他的硬件部分只有一份，比如执行浮点算数运算的单元。常规的处理器需要大约
10000个时刻周期做冉线程间的转化，而超线程的处理器可以在单个周期的基础上决定要
执行那一个线程。这使得CPU能够更好抵用它处理资源。比如，假设一个线程必须
等到某些数据被状态到高速缓存中，那CPU就可以继续去执行另一个线程。距离来说，
intercorei7 处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行地
执行8个线程。
   多处理器的使用可以从两个方面提供系统性能。首先，它减少了再执行多个任务时候模拟
并发的需要。正如前面提到的，即是是只有一个用户使用的个人计算机也需要并发地执行
多个活动。其次，它可以是用用程序运行得更快，当然，这必须要求程序员是以多线程方式
来书写的，这些线程可以并行地高效执行。因此，虽然并发原理的形成和研究已经超过50年
的时间了，但是多核和超线程系统的出现才极大地激发了一种愿望，即找到书写应用程
序的方法利用硬件开发线程级并行性。第12章会更深入地探讨并发，以及使用并发来提供
处理器资源的共享，使程序的执行允许有更多的并行。


2.指令级并行
  在较低的抽象层次上，现代处理器可以同时执行多条指令的属性成为指令集并行。早期
  的微处理器，如1987年的interl8086，需要多个通常是3-10个时钟周期来执行一条
  指令。最近的处理器可以保持每个时钟周期2-4条指令的执行速率。其实每条指令从
开始到结束需要长得多的时间，大约20个或者跟多周期，但是处理器使用了非常多的聪明
技巧来同事处理多大100条指令。在第4章中，我们会研究流水线pipelining的使用。在
流水线中，将执行一条指令所需的活动划分成不同的步骤，将处理器的硬件组织称以锡类
的极端，每个阶段执行一个步骤。这些阶段可以并性地操作，用来处理不同指令的不同
部分。我们会看到一个相当简单的硬件设计，它能够达到接近于一个时钟周期一条指令的
执行速率。
   如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量super
scalar处理器。大多数现代处理器都支持超标量操作。第五章中，我们将描述超标量处理器
的高级模型。应用程序员可以用这个模型来理解程序的性能。然后，他们就能写出拥有
更高程序的指令集并行性的程序代码，因而也运行得更快。
   2.单指令、多数据并行
   在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行
的操作，这种方式成为单指令、多数据，即simd并行。例如，叫心计带的intel和
AMD处理器都具有并性地对8对单精度浮点数做加法的指令。
    提供这些SIMD指令多事为了提高处理影像、声音和视频数据应用的执行速度。虽然
有些编译器会试图从C程序中自动抽取SIMD并行性，但是更可靠的方式是用编译器支持
的特殊的向量数据类型来写程序，比如GCC就支持向量数据类型。作为对第五章中比较
通用的程序优化描述的补充，我们在网络旁注OPT SIMD中描述了这种编程方式。
   
1.9.3 计算机系统中抽象的重要性
   抽象的使用时计算机科学中最为重要的概念之一。例如为一组函数规定一个简单的
应用程序接口API就是一个很好的编程习惯，程序员无须了解它内部的工作便可以使用
这些代码。不同的编程语言提供不同形式和登记的抽象支持，例如java类的生命和C语言
的函数原型。
   我们已经介绍了计算机系统中使用的几个抽象，。在处理器中，指令集
架构提供了对实际处理器硬件的抽象。使用这个抽象，机器代码程序表现得就好像运行
在一个一次只执行一条指令的处理器上。底层的硬件远比描述的要复杂精细，它并行
地执行多条指令，但又总是与那个简单有序的模型保持一致。只要执行模型一样，不同的
处理器实现也能执行同样的机器代码，而有提供不同的开销和性能。
    在学习操作系统时，我们介绍了三个抽象:w文件是对IO设备的抽象，虚拟机内存是对
程序存储器的抽象，而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象：
虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。虚拟机的思想是
IBM在60年代提出来的，但是最近才显示出其管理计算机方式的优势，因为一些计算机必须能够
运行为不同的操作系统 windows os linux
或同一操作系统的不同版本设计的程序。
    在本书后续的章节中，我们会具体介绍这些抽象。
1.10 小结
    计算机系统是由硬件和系统软件组成的，他们共同协作运行应用程序。计算机内部的信息被表示
为一组组的位，他们依据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，开始时是
ASII文件，然后被编译器和连接器翻译成二进制可执行文件。
   处理器读取并解释存放在二进制指令。因为计算机划分了大量的时间在内存IO设备和
CPU寄存器之间的复制数据，所以将系统中的存储设备划分成层次结构--CPU寄存器在顶部，接着
是多层的硬件高速缓存存储器‘DRAM主存和磁盘存储器。在层次模型中，位于更高层的存储设备比底层
的存储设备要更快，单位比特造假也更高。层次结构中教高层次的存储设备可以作为较低层次设备的高速
缓存。通过理解和运用这种存储层次结构的只是，程序员可以优化C程序的性能。
   操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的首相1.文件是对IO设备的抽象
   2虚拟机内存是对主存和磁盘的抽象；3进程是处理器’主存和IO设备的抽象。
    最后，网络提供给了计算机系统之间通信的手段。从特殊系统的角度来看，网络就是一种IO设备
   
   并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的。
   
   并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。
   
   
   
   
  操作系统--浙江大学
   
   主讲
   李善平，季江民，邢卫，寿黎但，张泉方
   
   Email
   shan@zju.edu.cn
   
   主页
http://os.zju.edu.cn
http://jwbinfosys.zju.edu.cn
http://os.zju.edu.cn/linux/files/lsp/




第一遍，理解 之
字面上理解知识点的含义

第二遍，质疑之
思考为什么非得这么论述这个知识点。假如不是这样，将会

第三遍，否定之
思考这么论述这个知识点，有什么欠缺


第一部分
 
 程序结构和执行
 
  我们对计算机系统的探索是从学习计算机本书开始的，它由
处理器和存储器字系统组成。在核心部分，我们需要方法来表示
基本数据类型，比如整数和实数运算的近似值。然后，我们考虑
机器级指令如何操作这样的数据，以及编译器又如何将C程序翻
译成这样的指令。接下来，研究集中实现处理器的方法，帮助我
们更好地了解硬件资源如何被用来执行指令。一旦理解了编译器
和机器级代码，我们就能了解如何通过编写C程序以及编译它们
来最大化程序的性能。本部分以存储器子系统的设计作为结束，
这是现代计算机系统最复杂的部分之一。
   本书的这一部分将领着你深入了解如何表示和执行应用程序。
你将学会一些技巧，来帮助你写出安全、可靠且充分利用计算资
源的程序。



    第二章

信息的表示和处理

  现代计算机存储和处理的信息以二值信号表示。这些微不足道的二进制数字，或者称
为位bit,形成了数字革命的基础。大家熟悉并使用了1000多年的十进制以10为基数
起源于印度，在12世纪被阿拉伯数学改进，并在13世纪被意大利数学家
带到西方。对于有10个手指的人类来说，使用十进制表示法是很自然的事情，但是当构造存储
和处理信息的机器时，二进制工作得更好。二值信号能够很容易地被表示、存储和传输，例如，可以表
示为穿孔卡片上有洞或无洞、导线上的高压电或低电压，或者顺时针或逆时针的磁场。对
二值信号进行存储和执行计算的电子电路非常简单和可靠，制造商能够在一个单独的硅片
上集成数百万甚至数十亿个这样的电路。
   孤立地讲，单个的位不是非常有用。然后，当把位组合在一起，再加上某种解释
   ，即赋予不同的可能位模式以含蓄，我们就能够表示任何有限集合的元素。比如，
   使用一个二进制数字系统，我们能够用位组来编码非负数。通过使用标准的字符码，
我们能够对文档中的字母和字符进行编码。在本章中，我们将讨论着两种编码，以及负数
表示和实数近似值的编码。
   我研究三种最重要的数字表示。无符号unsigned编码基于传统的二进制表示法，
表示大于或者等于0的数字。补码twocomplement编码是表示有符号整数的最常见的
方式，有符号整数就是可以为正或负的数字。浮点数编码是表示实数
的科学计数法的以2为基数的版本。计算机用这些不同的表示方法实现算数运算，例如加法
和乘法，类似于对应的整数和实数运算。
   计算机的表示法是用有限的数量的位来对一个数字编码，因此，当结果太大以至于不能表示
时，某些运算会溢出overflow。溢出会导致某些令人吃惊的后果。例如，在今天的
大多数计算机上使用32位来表示数据类型int，计算标示顿200*330*400*500会得出结果
-884.这违背了整数运算的特性，计算一组正数的乘机不应产生一个负的结果。
  另一方面，正数计算机运算满足人们所熟知的真正整数运算的许多性质。例如，利用
乘法的结合律和交换律，计算下面任何一个C表达式，都会得出结果-884901888
计算机可能没有产生期望的结果，但是至少它是一致的
浮点运算有完全不同的数学属性。虽然溢出会产生特殊的值，但是一组正数的乘机
总是正的。由于表示的精度有限，浮点运算时不可结合的。例如，在大多数机器上，C
表达式求得的值回事0，3.14
正数运算和浮点数运算会有不同的数学属性是因为它们处理数字表示优先性的方式不同
正数的表示虽然只能编码一哥相对较小的数值范围，但是这种表示是精确的，而浮点
树虽然可以编码一个较大的数值范围，但是这种表示只是近似的。
   通过研究数字的实际表示，我们能够了解可以表示的值得范围和不同算数运算的属性
为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统
和编译器组合的可移植性，了解这种属性是非常重要的。后面我们会降到，大量计算
机的安全漏洞都是由于计算机算数运算的微妙细节引发的。在早期，当人们碰巧触发了程序
漏洞，只会给人们带来一些不便，但是现在，有众多的黑客企图利用它们能找到的任何
漏洞，不经过授权就进入他人的系统。这就要求程序员有更多的责任和义务，去了解它们
的程序如何工作，以及如何被迫产生不良的行为。
    计算机用几种不同的二进制表示形式来编码数值。随着第三章进入机器级编程，你需
要熟悉这些表示方式。在本章中，我们描述这些编码，并且教你如何推出数字的表示。
    通过直接操作数字的位级表示，我们得到了集中进行算数运算的方式。理解这些技术对于
理解编译器产生的机器级代码是很重要的，编译器会师徒优化算术表达式求职的性能。
   我们对这部分内存的处理是基于一组核心的数学原理的。从编码的基本定义开始，然
后得出一些属性，例如可表示的数字的范围、他们的位级表示以及算术运算的属性。我们
相信从这一一个抽象的观点来分析这些内容，对你来说是很重要的，因为程序员需要对计算机
运算与更为人熟悉的整数和实数运算之间的关系有清气的理解。

2.1 信息存储
   大多数计算机使用8位的块，或者字节byte,作为最小的可寻址的内存单位，而不是
访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟机内存
virtual memory 。内存的每个字节都由一个唯一的数字来标识，称为它的地址address
,所有可能地址的集合就称为虚拟地址空间virtualaddress space.顾名思义，这个
虚拟地址空间只是一个展现给机器级程序的概念性影像。实际的实现是将动态
随机访问存储器DRAM闪存 磁盘存储器特殊硬件和操作系统软件结合起来，为
程序提供一个看上去统一的字节数组。
  在接下来的记账中，我们将讲述编译器和运行时系统是如何将存储器空间划分为更可
管理的单元，来存放不同的程序对象program object 即程序数据、指令和控制信息。
可以用各种机制来分配和管理程序不同部分的存储。这种管理完全是在虚拟地址空间里完成
的。例如C语言中一个指针的值无论它只想一个整数、一个结构或是某个其他程序
对象都是某个存储卡的第一个字节的虚拟地址。C编译器还把每个指针和类型信息联系
起来，这样就可以根据指针值的类型，生成不同的机器级代码来访问存储在指针所指向的位置
处的值。尽管C编译器维护者这个类型的信息，但是它生成的实际机器级程序并不包含关于数
据类型的信息。每个程序对象可以简单地视为一个字节块，而程序本书就是一个字节序列

2.1.1十六进制表示法
  一个字节由8位组成。在二进制表示法中，它的值域是。如果看成
10进制整数，它的值域就是。两种符号表示法对于描述位模式来说都不是非常
方便。二进制表示法太冗长，而十进制表示法与位模式的互相转化很麻烦。替代的方法是，
以16为基数，或者叫做16进制数，来表示位模式。16进制hex
使用数字0-9以及字符A-F来表示16个可能的值。图2-2展示了16个十六进制
数字对应的十进制值和二进制值。用16进制书写，一个字节值域位
  在C语言中，以0x或Ox开头的数字厂里被认为是16进制的值。字符A-F
既可以大写，也可以小写。例如我们可以将数字协作，或者
设置大小写婚鞋。在本书中，我们将使用C表示法表示16进制值。
   编写机器级程序的一个常见任务就是在位模式的十进制、二进制和十六进制表示之间
人工转换。二进制和十六进制之间的转换比较简单直接，因为可以一次执行一个十六进制
数字AC和F相应的十进制值。而对于吧16进制值B\D\E转换成十进制则可以
通过计算他们与前三个只的相对关系来完成。
   比如，假设给你一个数字。可以通过展开每个16进制数字，将它换砖成为禁止格式。
   
    这样就得到了二进制表示
    反过来，如果给定一个二进制数字，可以通过首先把它分为
没4位一组来转换为16进制。不过要注意，如果为总数不是4的倍数，最左边的一组可以
少于4位，前面用0补足。然后将每个4位组转换为相应的16进制数字。


2.1.2 字数据大小
   每台计算机都有一个字长word size ,指明指针数据的标称大小nominal size 因为
虚拟机地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间
的最大大小。也就是说，对于一个字长位W位的机器而言，虚拟地址的范围
程序最多访问个字节。
   最近这西恩，出现了大规模的从32位字长机器到64位字长机器的迁移。这种情况首先出
现在为大型科学和数据库应用设计的高端机器上，之后是台式机和笔记本电脑，最近则出现在
只能手机的处理器上。32字长限制虚拟机地址空间为4G，也就是说，干干超过
4*109字节。拓展到64位字长是的虚拟机地址空间为16EB大约是1.84*10 19字节。
   大多数64位机器也可以运行为32位机器编译的程序，这是一种向后兼容。因此，举
例来说，当程序prog。c用如下伪指令编译后
   linux gcc -m32 prog.c
该程序就可以在32位或64位机器上正确运行。另一方面，若程序用下属伪指令编译
linux gcc -m64 prog.c
那就只能在64位机器上运行。因此，我们将程序称为32位程序或64位程序。
区别在于该程序是如何编译的，而不是其运行的机器类型。
   计算机和编译器支持多种不同方法编码数字格式，如不同长度的整数和浮点数
比如，许多机器都有处理单个字节的指令，也有处理表示为2个自己、4个字节或者8个
字节整数的指令，还有些指令支持表为4字节和8字节的浮点数。
     C语言支持整数和浮点数的多种数据格式。图2-3展示了为C语言各种数据类型
分配的字节数。
有些数据类型的确切字节数以来与程序是如何被编译的。我们给出的是32和64位程序
的典型值。整数或者为有符号的，即可以表示附属、0和正数。或者为无符号的，即只能
表示非负数。C的数据类型char表示一个单独的字节。尽管char是由于它被用来存
储文本串中的单个字符这一事实而得名，但它也能被用来存储整数值。数据类型short
int和long可以提供各种数据大小。即使是为64位系统编译，数据类型int通常也只有
4个字节。数据类型long一般在32位程序中位4字节，在64位程序中则为8字节。
    为了避免由于以来典型大小和不同编译器设置带来的奇怪行为IOSC99引入了
以类数据类型，其数据大小是固定的，不随编译器和机器设置而变化。其中就有数据类型
int和64，他们分别为4个字节和8个字节。使用确定大小的整数类型是程序员
准确控制数据表示的最佳途径。
  大部分数据类型都是编码为有符号数值，除非有前缀关键字unsigned或对确定大小的
数据类型使用了特定的无符号生命。数据类型char是一个例外。尽管大多数编译器和机器
将他们视为有符号数，但C标准不保证这一点。想法，正如方括号指示的那样，程序员
应该用有符号字符的生命来保证其位一个字节的有符号数值。不过，在很多情况下，程序
行为对数据类型char是由符号的还是无符号的并不名。



第三部分 程序间的交互和通信

我们学习计算机系统到现在，一直假设程序是独立运行的，
质保函最小限度的输入和输出。然后，在现实世界里，应用程序
利用操作系统提供的服务来与IO河北以及其他的程序通信。
   本书的这一部分将使你了解unix操作系统提供的基本IO服务
以及如何用这些服务来构造应用程序，例如web客户端和服务器
，他们是通过internet彼此通信的。你将学习编写注入web
服务器这样的可以同时为多个客户端提供服务的并发程序。编写
并发应用程序还能使程序在现代多核处理器上执行的更快。当学完
了这部分，你将逐渐变成一个很牛的程序员，对计算机系统
以及他们对程序的应先共有很成熟的理解。


第十章 系统级IO
  输入输出IO是在主存和外部设备例如磁盘驱动器、终端和网络之间复制数据的过
程。输入操作是从IO设备复制数据到主存，而输出操作是从主存复制数据到IO设备。
   所有语言的运行时系统都提供执行IO的较高级别的工具。例如，ansi提供标准
IO库，包含像printscanf这样执行带缓冲区的IO函数。C语言用他的丑再操作符
U输入和输出提供了类型的功能。在linux系统中，是通过使用由内核提供的
系统级UNIXio函数来实现这些较高级别的IO函数的。大多时候，高级别IO函数
工作良好，没有必要直接使用unix io那为什么还要麦富迪学习UNIXioNE 
*了解unixIO将帮助你理解其他的系统概念。IO是系统操作不可或缺的一部分，因
此，我们经常遇到IO和其他系统概念之间的循环依赖。例如，IO在进程的创建和
执行中扮演着关系的角色。反过来，进程创建又在不同进程间的文件共享中扮演着关键
角色。因此，要真正理解IO，你必须理解进行，反之亦然。在对存储器层次结构、
链接和加载、进程以及虚拟机内存的讨论中，我们已经解除了IO的某些方面。既然你
对这些概念有了比较好的理解，我们就能闭合这个循环，更加深入敌研究IO
*有时你出了使用IO意外别无选择。在某些重要的情况中，使用高级IO函数
不太可能，或者不太适合。例如标准IO库没有提供读取文件元数据的方式，
例如文件大小或文件创建时间。另外IO库还存在一些问题，是的用它来进行网络
编程非常冒险。
   这一章介绍unixio和标准IO的一般概念，并且想你展示在C程序中五河可靠地
使用它们。处理作为一般性的介绍之外，这一章还未我们随后学习网络编程和并发性奠定
坚实的基础。
10.1 unixIO
 一个linux文件就是一个m个字节的序列：
所有的IO设备例如网络、硬盘和终端都被模型化为文件，而所有的输入和输出都被当
作对相应文件的读和写来执行。这种将设备优雅地映射为文件的方式，允许linux内核引
出一个简单、低级的应用接口，称为unixio，这使得所有的输入和输出都能以一种统一
且一直的方式来执行：

*打开文件。一个应用程序通过要求内核打开相应的文件，来宣告它想要访问一个
IO设备。内核返回一个小的非负整数，叫做描述符，他在后续对此文件的所有操
作中表示这个文件。

*Linux shell创建的每个进程开始时都有三个打开的文件：标准输入0、标准
输出1和标准错误2。头文件unistd.h定义了常量STDIN_FILENO、
STDOUT_FILENO和STDERR_FILENO (STD标准的)他们可用来代替显示的描述符值。

*改变当前的文件位置。对于每个打开的文件，内核保持着一个文件位置K，初始位0
。这个文件位置是从文件开始起始的字节偏移量。应用程序能够通过执行seek操
作，显示地设置文件的当前位置为k。

*读写文件。一个读操作就是从文件复制N>0个字节到内存，从当前文件位置k开始
然后将k增加到k+n。给定一个大小为m字节的文件，当k》=m时执行读取操作
会触发一个称为end-of-file(EOF)的条件，应用程序能检测到这个条件。在文件结
尾处并没有明确的EOF符号。
   类似地，写操作就是从内存复制n>0个字节到一个文件，从当前文件位置k
开始，然后更新k。

*关闭文件。当应用完成了对文件的访问之后，他就通知内核关闭这个文件。作为相
应，内核是否文件打开时创建的数据结构，并将这个描述恢复到可用的描述符池
中。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放他们
的内存资源。

10.2 文件
   每个linux文件都有一个类型type来表明它在系统中的角色:
   * 普通文件regular file包含任一数据。应用程序常常要区分文本文件textfile和二
   进制文件binary file，文本文件是致函有ascii或unicode字符的普通文件；二
   进制文件是所有其他的文件。对内核而言，文本文件和二进制文件没有区别。
        linux文本文件包含了一个文本行text line序列，其中每一行都是一个字符序列，
   以一个新行符\n结束。新行符与ascii的换行符LF是一样的，其数字值位OXOA
   
   * 目录 directory是包含一组连接的文件，其中每个连接都将一个文件名
   filename映射到一个文件，这个文件可能使另一个目录。每个目录至少含有两个
   条目:是到该目录自身的链接，以及..是到目录层次结构中父目录
   parent directory的链接。你可以用mkdir命令创建一个目录，用ls查看其内容，用
   rmdir删除该目录。

   * 套接字 socket 是用来与另一个进程进程跨网络通信的文件
    其他文件类型包含命名通道named pipe 符号链接 symbolic link 以及字符和块
设备 character and block device,这些不在本书的讨论范围。
     linux 内核将所有文件都组织称一个目录层次结构 directory hierarchy，由名为/
的跟目录确定。系统中的每个文件都是跟目录的直接或间接的后代。


10.3 打开和关闭文件
    进程是通过调用open函数来打开一个已存在的文件或者创建一个新文件的
    open函数将filename转换为一个文件描述符，并且返回描述符数字。返回的描述符总是
在进程中当前没有打开的最小描述符。flags参数指明了进程打算如何访问这个文件：
O_RDONLY 只读  O_WRONLY 只写 O_RDWR可读可写

例如，下面的代码说明的是如何打开一个已存在文件，并在后面添加一些数据

mode参数指定了新文件的访问权限位。这些位的符号名字如图10-2所示。
作为上下文的一部分，每个进程都有一个umask，它是通过调用umask函数来设
定的。当进程通过带某个mode参数的open函数调用来创建一个新文件时，文件的访问
限位被设置为mode例如假设我们给定下面的mode和umask默认是
最后，进程通过调用cloase函数关闭一个打开的文件。

10.4读写文件
  应用程序是通过分别调用read和write函数来执行输入和输出的。
  read函数从描述符位fd的当前文件位置复制最多n个字节到内存位置buf。返回值-1
  表示一个错误，而返回值0表示EOF。否则，返回值表示的是实际传送的字节数量。
  
  write函数从内存位置buff复制至多n个字节到描述符fd的当前文件位置。
  在某些情况下，read和write传送的字节比应用程序要求的要少。这些不足值short count
不表示有错误。出现这样的情况的原因有:
  *读时遇到EOF.假设我们准备读一个文件，该文件从当前文件位置开始只含有20
  多个字节，而我们以50个字节的片进行读取。这样一来，下一个read返回的不足
  值为20，此后的read将通过返回不足值0来翻出EOF信号。
   
   * 从终端读文本行。如果打开文件是与终端相关联的如键盘和显示器，那么每个read
   函数将依次传送一个文本行，返回的不足值等于文本行的大小。
   
   *读和写网络套接字socket。如果打开的文件对应于网络套接字，那么内
   部缓冲约束和较长的网络延迟会引起read和write返回不足值。对linux管道
   pipe调用read 和write时，也有可能出现不足值，这种进程间通信机制不在我们讨论的范围之内。
   
   实际上，除了EOF，当你在读磁盘文件时，将不会遇到不足值，而且在写磁盘文件时，
也不会遇到不足值。然后，如果你想创建健壮的可靠的诸如web服务器这样的网络应用，
就必须通过反复调用read和write处理不足值，知道所有需要的字节都传送完毕。

10.5 用RIO包健壮地读写
     在这一小节里，我们会讲述一个IO包称为RIO robust io 它会
会自动为你处理上文中所述的不足值。在像网络程序这样容易出现不足值的应用中，RIO
包提供了方便、健壮和高效的IO。RIO提供了两类不同的函数。
* 无缓存的输入输出函数。这些函数直接在内存和文件之间传送数据，没有应用级缓
冲。它们对将二进制数据读写到网络和从网络读写二进制数据尤其有用。
* 带缓冲的输入函数。这些函数允许你高效地从文件中读取文本行和二进制数据，这些
文件的内容缓存在应用级缓冲区内，类似于为printf这样的标准IO函数提供
的缓冲区。带缓冲的RIO输入函数是线程安全的，它在同一个描述符上可以被交错地调用。例如
你可以从一个描述符中读一些文本行，然后读取一些二进制数据，接着再多读取一些文本行。

我们讲述RIO历程有两个原因。第一在接下来的两张中，我们开发的网络应用中使用了它们。
第二，通过学习这些历程的代码，你将从总体上对unixio有更深入的了解





第十一章网络编程
   网络应用随处可见。任何时候浏览web、发送email信息或是玩在线游戏，你就正在
使用网络应用程序。有趣的是，所有的网络应用都是基于相同的编程模型，有着相似
的整体逻辑结构，并且以来相同的编程接口。
   网络应用依赖于很多在系统研究中已经学习过的概念。例如，进程、信号、字节顺序
内存映射以及动态内存分配，都扮演着重要的角色。还有一些新概念要掌握。我们需要
理解基本的客户端服务器编程模型，以及如何编写使用因特网提供的服务的客户端-
服务器程序。最后，我们将把所有这些概念结合起来。开发一个虽小但功能齐全的web服务器
，能够为真是的web浏览器提供静态和动态的文本和图形内容。

11.1 客户端-服务器编程模型
    每个网络应用都是基于客户端-服务器模型的。采用这个模型，一个应用是由一个服
务器进程和一个或者多个客户端进程组成。服务器管理某种资源，并且通过操作这种资源
来为它的客户端提供某种服务。例如，一个web服务器管理者一组磁盘文件，它会代表
客户端进行检索和执行。一个FTP服务器管理者一组磁盘文件，他会为客户端进行存储
和检索。相似的，一个电子邮件服务器管理者一些文件，他为客户端进行读和更新。
  客户端-服务器模型中的基本操作是事务tansaction。一个客户端-服务器事务
由以下四步组成。
   1.当一个客户端需要服务时，他想服务器发送一个请求，发起一个事务。例如，当
web浏览器需要一个文件时，他就会发送一个请求给web服务器。
   2.服务器收到请求后，解释它，并以适当的方式操作它的资源。例如，当web服务器
收到浏览器发出的请求后，他就读一个磁盘文件。
   3.服务器给客户端发送一个响应，并等待下一个请求。例如，web服务器将文件发送
回客户端。
   4.客户端收到响应并处理它。例如，当web浏览器收到来自服务器的一页后，就在
屏幕上显示此页。
   
   认识到客户端是进程，而不是常提到的机器或者主机，这是很重要的。一台
主机可以同时运行许多不同的客户端和服务器，而且一个客户端和服务器的事务可以在同
一台或是不同的主机上。无论客户端和服务器是怎么样映射到主机上的，客户端-服务器模型
都是相同的。

11.2 网络
    客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来
通信。网络是很复杂的系统，在这里我们只想了解一点皮毛。我们的目标是从程序员的角
度给你一个切实可行的思维模型。
    对主机而言，网络知识又一种IO设备，是数据源和数据接收方，如图11-2所示。
一个查到IO总线拓展槽的适配器提供了到网络的物理接口。从网络上接收到的数据
从适配器经过IO和内存总线复制到内存，通常是通过DMA传送。相似地，数据也能从
内存复制到网络。
    物理上而言，网络是一个按照地理远近组成的层次系统。最底层是LAN local area network
network 局域网，在一个建筑或校园范围内。迄今为止，最流行的局域网技术是以太网
ethernet,它是由施乐公司帕洛阿尔托研究中心XeroxPARC在70年代中期
提出的。以太网技术被证明是适应力极强的，从3Mb到10Gb
    一个一天玩的Ethernet segment包括一些电缆和一个叫集线器的
小盒子，如图11-3所示。以太网段通常跨越一些小的区域，例如某建筑物的一个房间
或者一个楼层。没跟电缆都有相同的最大带宽，通常是100M或者1G一段连接
到主机的适配器，而另一端则连接到集线器的一个端口上。
集线器不加分别地讲从一个端口上收到的每个位复制到其它所有的端口上。因此，每台主机
都能看到每个位。
   每个以太网适配器都有一个全球唯一的48位地址，
   他存储在这个适配器的非遗实行存储器上。一台主机可以
   
   以发送一段位(称为帧frame)到这个网段内的其它任何主机。每个帧包括一些固定数量
的头部header位,用来表示此帧的源和目的地址以及此帧的长度，此后紧随的就是数据
位的有效载荷payload.每个主机适配器都能看到这个帧，但是只有目的主机实际读取
它。
    使用一些电缆和叫做网桥的小盒子bridge，多个以太网段可以连接成较大的局域网，
称为桥接以太网bridged ethernet 。桥接以太网能够跨越整个建筑物或
者校区。在一个桥接以太网里，一些电缆连接网桥与网桥，而另外一些连接网桥和集线
器。这些电缆的带宽可以是不同的。在我们示例中，网桥与网桥之间的电缆有1G的
带宽，而四根网桥和集线器之间电缆的带宽缺失100M
    网桥比集线器更充分地利用了电缆带宽。利用一种聪明的分配算法，他们随着时间自
动学习那个主机可以通过那个端口可达，然后只在有必要时，有选择地将帧从一个端口复制
到另一个端口。例如，如果主机A发送一个帧到同网段上的主机B，当该帧叨叨网桥X
的输入端口时，X就将丢弃此帧，因而节省了其他网段上的带宽。然后，入股哦主机A发送
一个帧到一个不同网段上的主机C，那么网桥X只会把此帧复制到和网桥Y相连的端口上
，网桥Y会只把此帧复制到与主机C的网段连接的端口。
   为了简化局域网的表示，我们将把集线器和网桥以及连接他们的电缆画成一根水平
线，
   在层次的更高级别中，多个不兼容的局域可以通过叫做路由器router的特殊计算机
连接起来，组成一个internet互联网。每台路由器对于它所连接到的每个网络都有
一个适配器端口。路由器也能连接高速点到点的电话连接，这是称为WAN wide -area network
广域网的网络示例，之所以这么叫是因为它们
覆盖的地里范围比局域网的大。一般而言，路由器可以用来由各种局域网和关于我构建互联网络。

  互联网络至关重要的特性是，他能由采用完全不同和不兼容技术的各种局域网和关于我
组成。每台主机和其他每台主机都是物理连接的，但是如何能够让某台源主机跨国所有
这些不兼容的网络发送数据到另外一台目的主机呢？

* 命名机制。不同的局域网技术有不同和不兼容的方式来为主机分配地址。互联网络
协议通过定义一种一直的主机地址格式消除了这些差异。每台主机会被分配至少一个
这种互联网地址internet address，这个地址唯一地标识了这台主机。

* 传送机制。在电缆上编码位和将这些位封装成帧方面，不同的联网技术有不同的和
不兼容的方式。互联网络协议通过定义一种吧数据为捆扎成不连续的片称为包的
统一方式，从而消除了这些差异。一个包是由包头和有效载荷组成的，其中包头包括
包的大小以及源主机和目的主机的地址，有效载荷包括从源主机发出的数据位。

11-7展示了主机和路由器如何使用互联网协议在不兼容的局域网间传送数据的一个
示例。这个互联网示例由两个局域网通过一台路由器连接而成。一个客户端运行在
主机A上，主机A与LAN相连local area network，它发送遗传数据字节到运行在主机B上的
服务器端，
主机B则连接在LAN2上。这个过程有8个基本步骤：

1.运行在主机A上的客户端进行一个系统调用，从客户端的虚拟地址空间复制数据
到内核缓冲区中。

2.主机A上的协议软件通过在数据前附加互联网包头和LAN帧头，创建了一个
Lan的帧。互联网络包头寻址到互联网络主机B。Lan帧头寻址到路由器。然后他传
送此帧到适配器。注意，LAN1帧的有效载荷是一个互联网络包，而胡两万包的有效载荷
是实际的用户数据。这种疯转是基本的网络互连方法之一。

3.LAN1适配器复制该帧到网络上。

4.档次真到达路由器时，路由器的LAN1适配器从电缆上读取它，并把它传送到协议
软件。

5.路由器从互联网络包头中提取出目的的互联网络地址，并用它作为路由表的索引，
确定向哪里转发这个包，在本例中是LAN2。路由器剥落就得LAN1的帧头，加上寻址到
主机B的新的Lan2帧头，并把得到的帧传动到适配器。

6.路由器的LAN2适配器复制到该帧到网络上。

7.当此帧到达主机B时，它的适配器从电缆上读到此帧，并将它传送到协议软件。

8.最后，主机B上的协议软件剥落包头和帧头。当服务器进行一个读取这些数据de 
系统调用时，协议软件最终得到的数据赋值到服务器的虚拟地址空间。

  当然，在这里我们掩盖了许多很难的问题。如果不同的网络有不同帧大小的最大值，该怎
么办呢？路由器如何知道该往哪里转发帧呢？当网络拓扑变化时，如何通知路由器？如果一个
包丢失了又会如何呢？虽然如此，我们在示例抓住了互联网络思想的精髓，封装是关键。

11.3 全球IP因特网
  全球IP因特网是最著名和最成功的互联网络实现。从69年起，它就以这样或那样
的形式存在了。虽然因特网的内部体系结构复杂而且不断变化，但是自动20世纪80年代
早期以来，客户端-服务器应用的组织就一直保持着相当的稳定。图11-8展示了一个因特
网客户端-服务器应用程序的基本硬件和软件组织。

每台因特网主机都运行实现TCPIp协议 transmission controll protocol internet
protocol ，传输控制协议、互联网协议的软件，几乎每个现代计算机系统都支持这个协
议。因特网的客户端和服务器混合使用套接字接口函数和UNIXio函数来进行通信
。通常将套接字函数实现为系统调用，这些系统调用会陷
入内核，并调用各种内核模式的TCP ip函数。
  TCPIP实际是一个协议族，其中每一个都提供不同的功能。例如，IP协议提供基本
的命名方法和递送机制，这种递送机制能够从一台因特网主机往其他主机发送包，也叫做
数据报datagram.IP机制从某种意义上而言是不可靠的，因为，如果数据报在网络中丢
失或者重复，他不会试图恢复。UDP unreliable datagram protocol，不可靠数据报协议
稍微拓展了IP协议，这样一来，包可以在进程间而不是在主机间传送。TCP是一个构
建在IP之上的复杂协议，提供了进程间可靠的全双工连接。为了简化讨论，我
们将TCPIP看做是一个单独的整体协议。我们将不讨论他的内部工作，只讨论TCP和
IP位应用程序提供的某些基本功能。我们将不讨论UPD
  从程序员的角度，我们可以把因特网看做一个世界范围的主机集合，满足一下特性：
  1.主机集合被映射为一组32位的IP地址。
  2.这组IP地址被映射为一组称为英特网域名internet domain name的标识符。
  3.因特网主机上的进程能够通过连接connection和任何其他因特网主机上的进程通信。
  接下来三节将更详细地讨论这些基本的因特网概念。

11.3.1 IP地址
   一个IP地址就是一个32位无符号整数。网络程序将IP地址存放在如图11-9所示的
   IP地址结构中。
   
   把一个标量地址存放在结构中，是套接字接口早期实现的不幸产物。为IP地址定义一个
标量类型应该更有意义，但是现在更改已经太迟了，因为已经有大量应用是基于此的。
   因为因特网主机可以由不同的主机字节顺序，TCPIP为任意整数数据项定义了统一的
网络字节顺序nework byte order 大端字节顺序，例如IP地址，它放在包头中跨国网络被
携带。在IP地址结构中存放的地址总是以大端法网络字节顺序存放的，即是主机字节顺序
host byte order 是小端法。unix提供了下面这样的函数在网络和主机字节顺序间实现转换。
   hotnl函数将32位整数由主机字节顺序转换为网络字节顺序。ntohl函数将32位整
数从网络字节顺序转换为主机字节。htons和ntohs函数为16位无符号整数执行相应的
转换。注意，没有对应的处理64位值得函数。
   IP地址通常是以一种称为点分十进制表示法来表示的，这里，每个字节由它的十
进制值表示，并且用句点和其他字节间分开。例如，128.2.194.242就是地址
的点分10进制表示。在linux系统上，你能够使用hostname命令来确定你自己主机的
点分十进制地址:
   应用程序使用inet_pton和inet_ntop函数来实现IP地址和点分十进制串之间的转换。
在这些函数名中，N代表网络p代表表示。他们可以处理32位IP4地址
或者128位IP6
  inetpton函数将一个点分十进制串转换为一个二进制的网络字节顺序的IP地址
如果src没有只想一个合法的点分十进制字符串，那么该函数就返回0.任何
其他错误会返回-1，并谁知errno。相似地，inet——ntop函数将一个二进制的网络字节
顺序的IP地址转换为它所对应的点分十进制表示，并把得到的以null结尾的字符串
的最多size个字节复制到dst



11.3.2 因特网域名
  因特网客户端和服务器互相通信时使用的是IP地址。然后对于人们而言，打证书
是很难记忆的，所以因特网也定义了一组更加人性化的域名domain name，以及一种将
域名映射到IP地址的机制。域名是遗传用句点分割的单词，例如
  域名集合形成了一个层次结构，每个域名编码了它在这个层次中的位置。通过一个示例
你将很容易理解这点。图11-10展示了域名层次结构的一部分。层次结构可以表示位一
棵树。树的结点表示域名，反向到根的路径形成了域名。子树称为紫玉subdomian。层
次结构中的第一层是一个未命名的根节点。下一定是一组以及域名firestlevel domain
name 由非盈利组织ICANN定义。 常见的第一层域名

  下一层是二级域名，例如cum.edu,这些应是ICANN的各个授权
代理按照先到先服务的基础分配的。一旦一个组织得到了一个二级域名，那么它就可以在
这个子域中创建任何新的域名了，例如cs.cmu.edu.
  因特网定义了域名集合和IP地址集合之间的映射。直到88年都是hosts。xtx维护的。
从哪以后，这个映射是通过分布世界范围
的数据DNSdomain name sytem域名系统来维护的。从概念上而言，
DNA数据由上百万的主机条目结构组成，其中每条定义了一组域名
和一组IP地址之间的映射。从数学意义上讲，可以认为每条主机条目就是一个域名和
IP地址的等价类。我们可以用linux的NSLOOKUP程序来探究DNS映射的一些属性
这个程序能展示与某个IP地址对应的域名
   每台因特网主机都有本地定义的域名localhost，这个域名总是映射为回送地址
loopback address 127.0
nslookup localhost
   localhost名字为引用运行在同一台机器上的客户端和服务器提供了一种便利和可移植
的方式，这对调试相当有用。我们可以使用host那么来确定本地主机的实际域名
  在最简单的情况中，一个域名和一个IP地址之间是一一映射
  然后，在某些情况下，多个域名可以映射为同一个IP地址
   最通常的情况下，多个域名可以映射到同一组的多个IP地址  

11.3.3 因特网连接
   因特网客户端和服务器通过在连接上发送和接收字节流来通信。从连接一对进程的意义上而言，连
连接是点对点的。从数据可以同时双向流动的角度来说，它是全双工的。并且
从由源精粹发送的字节
流最终被目的进程以他发出的顺序收到他的角度来说，它是可靠的。
   一个套接字是连接的一个端点。每个套接字都有相应的套接字地址，是由一个因特网
   地址和一个16位的整数端口组成的，用地址端口来表示。
   
   当客户端发起一个连接请求时，客户端套接字地址中的端口时由内核自动分配的，称
为临时端口ephemeral port然后，服务器套接字地址中的端口通常是某个指明端口，
是和这个服务相对应的。例如，web服务器通常使用端口80，而电子邮件服务器使用端口
25.每个具有指明端口的服务都有一个对应的知名的服务名。例如，web服务器的知名
是HTTP，emial的知名名字是smtp.文件/ext/services包含一张这台机器提供的
知名名字和知名端口之间的映射。
   一个连接时由它两端的套接字地址唯一确定的。这对套接字地址叫做套接字对socket
   pair ，由下列元素来表示
   cli addr:cli port  serv addr:serv port
   其中cliadder是客户端IP地址cliport是客户端的端口，servaddr是服务器的IP地址
   servport是服务器的端口。
   在这个示例中，web客户端的套接字地址是

11.4套接字接口
   套接字接口socket interface 是一组函数，他们和unixIO函数结合起来，用以创建
网络应用。大多数现代系统上都实现套接字接口，包括所有的unix变种win和
macintosh系统。图11-12给出一个典型的客户端-服务器事务的上下文中的套接字接口
概述。当讨论各个函数时，你可以使用这张图来作为向导图。

11.4.1 套接字地址结构
  从linux内核的角度来看，一个套接字就是通信的一个端点。从linux程序的家都来
看，套接字就是一个由相应描述符的打开文件。
   因特网的套接字地址存放在类型的sockaddr_in的16字节结构中。
对于因特网应用，sin_family成员是AF_INET,sinport成员是一个16位的端口号。
而sinaddr成员就是一个32位的IP地址。IP地址和端口号总是以网络字节顺序存放的。
sin_family   AF_INET
  connect bind和accept函数要求一个指向与协议相关的套接字地址结构的指针。
套接字接口的设计者面临的问题是，如何定义这些函数，使之能接收各种类型的套接字地
址结构。今天我们可以使用通用的void指针，但是那是在C中并不存在这种类型的指针
。解决办法是定义套接字函数要求一个指向通用的sockaddr指针，然后
要求应用程序将于协议特定的结构的指针强制转换成这个通用的结构。为了简化代码
然后无论何时需要将sockaddr结构强制转成通用sockaddr结构失，我们都使用
这个类型。
11.4.2socket 函数
 客户端和服务器使用socket函数来创建一个套接字描述符socket descriptor
   如果想要使套接字称为连接的一个端点，就用如下硬编码的参数来调用socket函数
其中,AFINET表示我们正在使用32位IP地址，而sockstream表示这个套接字
是连接的一个端点。不过最好的方式是用getaddrinfo函数来自动生成这些
参数，这样代码就与协议无关了。我们会在11.4.8节中向你展示如何配合socket函数来
使用addrinfo
   socket返回的clientfd描述符近视部分打开的，还不能用于读写。如何完成打开
套接字的工作，取决于我们是客户端还是服务器。下一届描述当我们是客户端时候如何完成
打开套接字的工作。

11.4.3 connect函数
   客户端通过调用connect 函数来建立和服务的连接。
    connect函数试图与套接字地址为addr的服务器建立一个因特网连接，其中addrlen
是sizeof。connect函数会阻塞，一直到连接成功建立或是发生错误。如果
成功，clientfd描述符现在就准备好可以读写 了，并且得到的连接时由套接字对
  刻画的，其中X表示客户端的IP地址，而Y表示临时端口，它唯一地确定了客户端主机
  上的客户端进程。对于socket，最好的方法是用getaddrinfo来为connect提供参数

11.4.4bingd 函数
 剩下的套接字函数bind listen accept服务器用他们来和客户端建立连接。
 bind函数告诉内核将addr中的服务器套接字地址和套接字描述符sockfd联系起
来。参数addrlen就是sizeof。对于socket和connect，最好的方法是用
getaddrinfo来为bind提供参数。

11.4.5 listen函数
   客户端是发起连接请求的主动实体。服务器是等待来自客户端的连接其你去的被动实
体。默认情况下，内核会认为socket函数创建的描述符对应于主动套接字active socket
，它存在于一个连接的客户端。服务器调用listen函数高速内核，描述符是被服务器
而不是客户端使用的。
  listen函数将sockfd从一个主动套接字转化为一个监听套接字listening socket
该套接字可以接受来自客户端的连接请求。backlog参数按时了内核在开始拒绝连接请求
之前，队列中要怕对的未完成的连接请求的数量。backlog参数的确切含义要求对tcpip
协议的理解，这超出了我们讨论的范围。通常我们会把它设置为一个较大的值，比如
1024

11.4.6 accept 函数
      服务器通过调用accept函数来等待来自客户端的连接请求。
      accept函数等待来琦客户端的连接请求到达侦听描述符listenfd,然后再addr中
填写客户端的套接字地址，并返回一个连接描述符connected descriptor，这个描述符
可被用来利用unixio函数与客户端通信。
  监听描述符和已连接描述符之间的区别是很多人感到迷糊。监听描述符是作为客户端
连接请求的一个端点。它通常被创建一次，并存在于服务器的整个生命周期。已连接描述
符是客户端和服务器之间已经建立起来了的连接的一个端点。服务器每次请求连接请求时
都会创建一次，它只存在于服务器为一个客户端服务的过程中。
   图11-14秒回了监听描述符和已连接描述符的酵素。在第一步中，服务器调用
   accept，等待连接请求到达监听描述符，具体地我们设定为描述符3，回忆一下，描述符
0-2是预留给标准文件的。
   在第二部中，客户端调用connect函数，发送一个连接请求到listenfd。第三部，
accept函数打开了一个新的已连接描述符connfd，在clientfd
和connfd之间建立连接，并且随后返回connfd给应用程序。客户端也从connect返回，
在这一点以后，客户端和服务器就可以分别通过读和写clientfd和connfd来回传送数据了
 为何要有监听描述符和已连接描述符之间的区别。
  你可能很香知道为什么套接字接口要区别监听描述符和已连接描述符。乍一看，这
像是不必要的复杂化。然鹅，区分这两者被证明很有用的，因为它是的我们可以建立
并发服务器，它能够同时处理许多客户端连接。例如，每一次连接请求到达监听描述
符时，我们可以派生fork一个新的进程，它通过已连接描述与客户端通信。


11.4.7 主机和服务的转换
    linux 提供了一些强大的函数getaddrinfo 和getnameinfo 实现二进制套接字地
地址结构和主机名、主机地址、服务名和端口号的字符串表示之间的互相转化。当和套接字接
口一起使用时，这些函数能使我们编写独立于任何特定版本的IP协议的网络程序。
  1.getaddrinfo函数
  getaddrinfo函数将主机名、主机地址、服务名和端口号的字符串表示转化成套接字
地址结构。它是已启用的gethostbyname和getservbyname函数的新的替代品。和以
前的那些函数不同，这个函数是可重的，适用于任何协议。
   给定host和service，getaddrinfo返回result,
result一个指向addrinfo结构的链表，其中每个结构指向一个对应于host和service
的套接字地址结构

在客户端调用了getaddrinfo之后，会遍历这个列表，依次尝试每个套接字地址，直到调
用socket和connect成功，建立起连接。类似的，服务器会尝试遍历列表中的每个套接字地
址，直到调用scoket和bind成功，描述符会被绑定到一个何方的套接字地址。为了避免内存
泄露，应用程序必须在最后调用freeaddrinfo释放该链表。如果getaddrinfo返回非零的
错误代码，应用程序可以调用gai streeror，将该代码转成消息字符串。
  getaddrinfo的host参数可以是域名，也可以是数字地址。
service参数可以是服务名,也可以说十进制端口号。入股哦不想把主机名转成地址
，可以把host设置为null，对sercie来说也是一样。但是必须制定两只中至少一个。
   可选的参数hists是一个addrinfo结构，它提供对getaddrinfo返回
的套接字地址列表的更好控制。如果要传递hists参数，只能设置下列参数aifamily
aisocketype ai protocol和ai flags字段。其他字段必须设置为0，。

实际中，我们用memset将整个解构清零，然后又选择地设置一些字段

2.getnameinfo函数
  getnameinfo函数和getaddrinfo是相反的，将一个套接字地址结构转成相应的
主机和服务名字符串。他是已启用的gethostbyaddr和getservbyport函数的新的替代
品，和以前的寒邪函数不同，它是可重入和与协议无关的。
  参数sa指向大小为salen字节的套接字地址结构，host指向大小为hostlen字节的缓冲区
，sercie指向带下为servlen字节的缓冲区。getnameinfo函数将套接字地址结构 sa
转换成对应的追击和服务名字符串，并将它们复制到host和service缓冲区。如果getname
info返回非零的错误代码，应用程序可以调用gaistreoor把它转化成字符串。
   如果不想要主机名，可以把host设置为null，hostlen设置为0.对服务字段来
说也是一样。不过，两者必须设置其中之一。
  参数flags是一个位眼毛，能够修改默认的行为。

11.4.8 套接字接口的辅助函数
    初学时，getnameinfo函数和套接字接口看上去有些可怕。用高级的辅助函数包装
一下会方便很多，称为open_clientfd和open_listenfd，客户端和服务器互相通信时
可以使用这些函数。
1.open_clientfd函数
客户端调用open_clientfd建立与服务器的连接

2.open_listenfd函数
调用open_listenfd函数，服务器创建一个监听描述符，准备好接受连接请求。
open_listenfd函数打开和返回一个监听描述符，这个描述符准备好在端口port上
接收连接其你去。

11.4.9 echo客户端和服务器的示例


11.5 web服务器
   迄今为止，我们已经在一个简答的echo服务器的上下文中讨论了网络编程。在这一节
里，我们将向你展示如何利用网络编程的基本概念，来创建你自己的虽小但功能齐全的
web服务器。

11.5.1 web基础
   web客户端和服务器之间的交互用的是一个机遇文本的应用级协议，叫做http

11.5.2 web内容
   对于web客户端和服务器而言，内容是与一个MIME
   类型相关的字节序列。

11.5.3 HTTP事务
    因为HTTP是基于因特网连接上传送的文本行的。我们可以使用linux的telnet
程序来和因特网上的任何web服务器执行事务。对于调试在了解上通过文本行来与
客户端对话的服务器来说，telnet程序是非常便利的。
   1.http请求
   一个http请求的组成是这样的:一个请求行后面跟随另个
   或者更多个请求抱头，再跟随一个空的文本行来终止抱头里诶勃啊
   一个请求行的形式 是。
    2.http响应
    http响应和hettp请求时相似的。一个http影响的组成是这样的:一个响应行
    后面跟随者另个或更多的响应报头，再跟随一个终止报头的空喊，在跟随着一个响应主题
    
11.5.4 服务动态内容
   如果我们停下来考虑一下，一个服务器是如何向客户端提供动态内容的，就会发现一些
问题。例如，客户端如何将程序参数传递给服务器。服务器如何将这些参数传递给他们所
创建的子进程。服务器如何将子进程生成内容所需要的其它信息传递给子进程，紫禁城将
它的输出发送到哪里？一个称为CGIcommon gateway interface通用网管接口的实际
标准的出现解决了这些问题。
  1.客户端如何将程序参数传递给服务器
  
  2.服务器如何将参数传递给子进程
  它调用fork来创建一个子进程，并调用execve在子进程的上下文中执行adder程序。
  向adder这样的程序，常常被称为CGI程序，因为它们遵循CGI标准的规则。
  而且，因为许多CGI程序是用perl脚本编写的，所以CGI程序也被称为CGI脚本。在
  调用execve之前，子程序将CGI环境变量query_string设置为15000$123adder
  程序在运行时可以用linux getenv函数来引用它。

3.服务器如何将其他信息传递给子进程
CGI定义了大量的其他环境变量,一个CGI程序在它运行时可以设置这些环境变量。

4.子进程将它的输出发送到哪里
一个CGI程序将它的动态内容发送到标准输出。在子进程加载并运行CGI程序之前
它使用linux dup2函数将标准输出重定向到和客户端相关联的已连接描述符。因此任
何CGI程序写到标准输出的东西都会直接到达客户端。
  注意，因为父进程不知道子进程生成的内容的类型或大小，所以子进程就要负责生成
COntenttype和contentlength影响报头，以及种植报头的空行。

每个网络应用都是基于客户端-服务器模型的。根据这个模型，一个应用是由一个服务器和一个
或多个客户端组成的。服务器管理资源，以某种方式操作资源，为他的客户端提供服务。客户顿模型
中的基本操作是客户端-服务器事务，它是由客户端请求和跟随其后的服务器影响组成的。


最流行的LAN局域网技术是以太网Ethernet

以太网是标准是技术


第十二章并发编程
正如我们在第八章学到的，如果逻辑控制流在时间上重叠，那么他们就是并发的
concurrent。这种常见的现象称为并发concurrency，出现在计算机系统的许多不同层
面上。硬件异常处理程序、进程和linux信号处理程序都是大家很熟悉的例子。
   到目前为止，我们主要讲并发看做是一种操作系统内核用来运行多个应用程序的机
制。但是，并发不仅仅局限于内核。他也可以在应用程序中扮演重要的角色。例如，我们已经
看到linux信号处理程序如何允许应用影响一步时间，例如用户键入ctrlc或者程序
访问虚拟内存的一个未定义的区域。应用级并发在其他情况下也是很有用的：
* 访问慢速IO设备。当一个应用正在等待来自慢IO设备的数据到达时候
内核会运行其他进程，使CPU保持繁忙。每个应用都可以按照类似的方式，
通过交替执行IO请求和其他有用的工作来利用并发。

* 与人交互。和计算机交互的人要求计算机有同时执行多个任务的能力。例如，他们
在打印一个文档时，可能想要调整一个窗口的大小。现代视窗系统利用并发来提供
这种能力。每次用户请求某种操作时，一个独立的并发逻辑流
被创建来执行这个操作。

* 通过推迟工作以降低延迟。有时，应用程序能够通过推迟其他操作和并发地执行他们
利用并发来降低某些操作的延迟。比如，一个动态内存分配器可以通过推迟合并
，把它放到一个运行在较低优先级上的并发合并流中，在有空闲的CPU周期
时充分刘勇这些空闲周期，从而降低单个free操作的延迟。

* 服务多个网络客户端。我们学习迭代网络服务器是不显示的，因为
他们一次只能为一个客户端提供服务。因此一个慢速的客户端可能会导致服务器拒绝
为所有其他客户端服务。对于一个真正的服务器来说，可能期望它美妙为成百上千的
客户端提供服务，由于一个慢速客户端导致拒绝为其他客户端服务，这是不能接受的
。一个更好的方法是创建一个并发服务器，它为每个客户端创建一个单独的逻辑流
。这就允许服务器同事为多个客户端服务，并且也避免了慢速客户端独占服务器。

* 在多核机器上进行并行计算。许多现代系统都配置多核处理器，多核处理器中包含
有多个CPU。被划分成并发刘的应用程序通常在多核机器上比在单核处理器机器上yunx得快
，因为这些流并行执行，而不是交错执行。

使用应用级并发的应用程序称为并发程序concurrent program。现代操作系统提供
了三种基本的构造并发程序的方法：

1.进程。用这种方法，每个逻辑控制流都是一个进程，由内核来调度和维护。因为进
程有独立的虚拟地址空间，想要和其他流通信，控制流必须使用某种显示的进程间
通信interprocess communicationIPC机制。

2.IO多路复用。在这种形式的并发编程中，应用程序在一个进程的上下文中显示地
调度他们自己的逻辑流。逻辑流被模型化位状态机，数据到达文件描述符后，主程序
显示地从一个状态转换到另一个状态。因为程序是一个单独的进程，所以所有的
流都桐乡同一个地址空间。

3.线程。线程是运行在一个单一进程上下文中的逻辑流，由内核进行调度。你可以把
线程看成是其他两种方式的混合体。像进程流一样由内核进行调度，而像IO多路
复用流一样共享同一个虚拟地址空间。
本章研究这三种不同的并发编程技术。为了使我们讨论比较具体，我们始终以统一
个应用为例。11.4.9节中的迭代echo服务器的并发版本。

内核（kernel）利用文件描述符（file descriptor）来访问文件。
文件描述符是非负整数。打开现存文件或新建文件时，内核会返回一个文件描述符。
读写文件也需要使用文件描述符来指定待读写的文件。

12.1 基于进程的并发编程。
  构造并发程序最简单的方法就是用进程，使用那些大家很熟悉的函数，像fork
exec和waitpid。例如，一个构造并发服务器的自然方法就是，在父进程中接收客户端
连接请求，然后创建一个新的子进程来为每个新客户端提供服务。
   为了了解这个是如何工作的，假设我们有两个客户端和一个服务器，服务器正在监听一
个监听描述符上的连接请求。现在假设服务器接受了客户端1的连接请求，
并返回一个已连接描述符，在接受连接请求之后，服务器
派生一个子进程，这个子进程获得服务器描述符表的完整副本。子进程关闭它的副本中的
监听描述符3，而父进程关闭它的已连接描述符4的副本，因为不再需要这些描述符了。
这就得到了12-2中的状态，其中子进程正忙于为客户端提供服务。
    因为父子进程中的已连接描述符都指向同一个文件表表项，所以父进程关闭它的已
经连接描述符的副本是至关重要的。否则，将永不会释放以连接描述符4的文件表条目，而
且由此引起的内存泄露将最终消耗光可用的内存，使系统崩溃。
   现在，假设在父进程为客户端1创建了子进程之后，它接收一个新的客户端2的连接骑牛
，并返回一个新的已连接描述符，然后父进程又派生另一个子进程，
这个子进程用已连接描述符5为他的客户端提供服务，此时
父进程正在等待下一个连接请求，而两个子进程正在并发地为他们各自的客户端提供服务。
12.1.1 基于进程的并发服务器
   基于进程的并发echo服务器的代码。
*首先，通常服务器会运行很长的时间，所以我们必须要包括一个SIGCHLD处理程
序，来回收僵尸子进程的资源。因为当SIGCHLD处理程序
执行时候，SIGCHLD信号是阻塞的，而linux信号是不排队的，所以SIGCHLD处理
程序必须准备好回收多个僵尸进程的资源。
*其次，父子进程必须关闭他们各自的connfd副本。就像
我们已经提到过的，这对父进程而言尤为重要，它必须关闭它的已连接描述符，
以避免内存泄露
*最后，因为套接字的文件表表项中的引用计数，直到父子进程的connfd都关闭了，
到客户端的连接才会终止。

12.1.2 进程的优劣
对于在父子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共
享用户地址空间。进程有独立的地址空间既是优点也是缺点。这样一来，一个进程不可能不小
心覆盖另一个进程的虚拟内存，这样就消除了许多令人迷糊的错误，这是一个明显的有点。
  另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，他们
必须使用显示的IPC进程间通信机制。基于进程的设计的另一个缺点是
他们往往比较慢，因为进程控制和IPC的开销很高。

12.2 基于IO多路复用的并发编程
  假设要求你编写一个echo服务器，它也能对用户从标准输入键入的交互命令做出相应。
。在这种情况下，服务器必须相应两个互相独立的IO事件：1.网络客户端发起连接请求
2.用户在键盘上键入命令行.我们先等待那个事件呢？没有那个选择是理想的。如果
在accept中等待一个连接请求,我们就不能响应输入的命令。类似的，如果在read中
等待一个输入命令，我们就不能响应任何连接请求。
   针对这种困境的一个解决办法就是IO多路复用IOmultiplexing技术。基本的思
想就是使用select函数，要求内核挂起进程,只有在一个或多个IO事件发生后，才将
控制返回给应用程序，就像在下面的示例中一样：
当集合0、4中任意描述符准备好读时返回。
当集合1、2、7中任意描述符准备好写时返回。
如果在等待一个IO事件发生时过了152.13秒就超时。
   select是一个复杂的函数，有许多不同的使用场景。我们将只讨论第一种场景：等待
一组描述符准备好读。全面的讨论请参考62 110

  int select (int n,fd_set *fdset,null,null,null)
  FD_ZERO
  fd_clr
  fd_Set
  fd_isset
  select函数处理类型为fd_set的集合，也叫做描述符集合。逻辑上，我们将描述符
集合看成一个大小为N的维向量
每个位bk对应于描述符K。当且仅当bk=1，描述符K才表明是描述符集合的一个元素。只
允许你对描述符集合做三件事：1.分配它们，2.将一个此种类型的变量赋值给另一个变量
3.用FD_zero、fd_Set、fd_clr和fd_isset宏来修改和检查他们。
  针对我们的目的，select函数有两个熟人：一个称为读集合的描述符集合fdset
和该读集合的技术n实际上是任何描述符集合的最大基数。select函数会一直阻塞，
直到读集合中至少有一个描述符准备好可以读。当且仅当一个从该描述符读取一个字节的
请求不会阻塞时，描述符k就表示准备好可以读了。select有一个附作用，它修改参数
fdset指向的fdset，指明读集合的有一个子集，称为准备好集合readyset,这个集合
是由读集合中准备好可以读了的描述符组成的。该函数返回的值指明了准备好集合的基数
。注意，由于这个副作用，我们必须在每次调用select时都更新读集合。
   理解select的最好办法是研究一个具体例子。图12-6展示了可以如何利用selct
来实现一个迭代echo服务器，它也可以接受标准输入上的用户命令。一开始，我们用
图11-9中的openlistenfd函数打开一个监听描述符，然后使fdzero
创建一个空的读集合

接下来，在第19和20行中，我们定义由描述符0标准输入和描述符3
组成的读集合
 在这里，我们开始典型的服务器循环。但是我们不调用accept函数来等待一个连接
 请求，而是调用select函数，这个函数会一直阻塞，直到监听描述符或者标准输入准备
 好可以读。例如，下面是当用户按下回车键，因此使得标准输入描述符变为可读
 时，select会返回的ready_Set值
 
  一旦select返回，我们就用fd_isset宏指令来确定那个描述符准备好可以读了。
如果是标准注入准备好了，我们就调用command函数，该函数在返回到住程序
前，会读、解析和响应命令。如果是监听描述符准备好了，我们就调用accept
来得到一个已连接描述符，然后调用echo函数，他会将来自客户端的每一行
又回送回去，直到客户端关闭这个连接中它的那一段。
  虽然这个程序是使用select的一个很好示例，但是它仍然留下了一些文件待解决。问题
是一旦它连接到某个客户端，就会连续回送输入行，直到客户端关闭这个连接中它的那一段
。因此，如何键入一个命令道标准输入，你将不会得到相应，直到服务器和客户端之间结
束。一个更好的方法是更细粒度的多路复用，服务器每次循环回送一个文本行

12.2.1 基于IO多路复用的并发事件驱动服务器
  IO多路复用可以用作并发事件驱动程序的基础，在事件驱动程序中
某些事件会导致流向前推进。一般的思路是将逻辑流模型化位状态机。不严格地说，一个
状态机state machine 就是一组状态、输入事件input event和转移transition
其中转移是将状态和输入事件映射到状态。每个转移是将一个输入状态，输入事件对应
射到一个输出状态。自循环selfloop是同一输入和输出状态之间的转移。通常把状态机
花城有向图，其中结点表示状态，有向弧表示转移，而弧上的标号表示输入事件。一个状
态机从某种初始状态开始执行。每个输入事件都会引发一个从当前状态到下以状态的
转移。
   对于每个新的客户端k，基于IO多路复用的并发服务器会创建一个新的状态机
   SK，并将它和已连接描述符dk联系起来。
   每个状态机sk都有一个状态、一个输入事件和一个转移
   
   服务器使用IO多路复用，借助select函数检测输入事件的发生。当每个已连接描述符
准备好可读时，服务器就为相应的状态机执行转移，在这里就是从描述符读和写回一个
文本行。
  展示了一个机遇IO多路复用的并发事件驱动服务器的完整示例代码。一个
  pool结构里维护者活动客户端的集合。在调用initpool初始池
  之后，服务器进入一个无线循环。在循环的每次迭代中，服务器调用select函数来
  检测两种不同类型的输入事件：a来自一个新客户端的连接请求到达，b一个已存在的客户端
  的已连接描述符准备好可以读了。当一个连接请求到达时，服务器打开连接
  并调用addclient函数，将该客户端添加到池里。最后，服务器调用checkclients函数，
  把来自每个准备好的已连接描述符的一个文本行回送回去。

initpool函数初始化客户端池。clientfd数组表示已连接描述符的集合
，其中整数-1表示一个可用的槽位。初始时，已连接描述符集合是空的，
而且监听描述符是select读集合中唯一的描述符。
   add client函数添加一个新的客户端到活动客户端池中。在clientfd
数组中找到一个空槽位后，服务器将这个已连接描述符添加到数组中，并初始相应的
RIO读缓冲区，这样一来我们就能够对这个描述符调用rioreadlineb。然后
我们将这个已连接描述符添加到select读集合，并更新该池的一些全局属性
。macfd变量记录了select的最大文件描述符。maxi变量
记录的是到clientfd数组的最大索引，这样checkclients函数就无须搜索整个数组
了。
  check_lients函数回送来自每个准备好的已连接描述符的一个文本行。
  如果成功的从描述符读取了一个文本行，那么就将该文本行回送到客户端
  注意，在第15行我们维护着一个从所有客户端接收到的全部字节的累计值。如果因为客户端
  关闭这个连接中它的那一端，检测到EOF，那么将关闭这边的连接端，并从
  池中清除掉这个描述符。
  根据图12-7中的有限状态模型，slect函数检测到输入事件，而addclient函数
  创建一个新的逻辑流状态机。check clients函数会输入行，从而执行装填转移，
  而且当客户端完成文本行发送时，它还要删除这个状态机

12.2.2 IO多路复用技术的优劣
    服务器提供了一个很好的基于IO多路复用的事件驱动编程的优缺点示
例。事件驱动设计的一个优点是，它比基于进程的设计给了程序员更多的对程序行为的控
制。例如我们可以设想编写一个事件驱动的并发服务器，为某些客户端提供他们需要的
服务，而这对于基于进程的并发服务器来说是很困难的。
  另一个优点是，一个基于IO多路复用的时间驱动服务器是运行在单一进程上下文中的
因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容易
。一个与作为单个进程运行相关的有点是，你可以利用熟悉的调试工具，例如GDB
来调试你的并发服务器，就像对顺序程序那样。最后，时间驱动设计常常比基于进程的设计
要高效得多，因为它们不需要进程上下文切换来调度新的流。
  事件驱动设计一个明显的缺点就是编码复杂。我们的事件驱动的并发echo服务器需要的
代码比基于进程的服务器多三倍，并且很不幸，随着并发粒度的减小，复杂性还会上升。这里
的粒度是指每个逻辑流每个时间片所需要的指令数量。例如，在示例并发服务器中，并发粒度
就是读一个完整的文本行所需要的指令数量。只要某个逻辑流正忙于读一个文本行，其他
逻辑流就不可能有进展。对我们的例子来说这没有问题。但是它是的在故意值发送部分文件
本行然后就停止的恶意客户端的攻击面前，我们的时间驱动服务器显得很脆弱。修改事件
驱动服务器来处理部分文本行不是一个简单的任务，但是基于进程的设计却能处理的很好，
而且是自动处理的。基于事件的设计另一个重要的缺点是他们不能充分利用多核处理器。

12.3 基于线程的并发编程
  到目前为止，我们已经看到了两种创建并发逻辑流的方法。在第一种方法中，我们为
  每个流使用了单独的进程。内核会自动调度每个进程，而每个进程有它自己的私有地址空间
，使得共享数据很困难。在第二种方法中，我们创建自己的逻辑流，并利用IO多路
复用来显示调度流。因为只有一个进程，所有的流共享整个地址空间。本节介绍第三种
方法-基于线程，它是这两种方法的混合。
 线程thread就是运行在进程上下文中的逻辑流。在本书里迄今为止，程序都是由每个
 进程中的一个线程组成的。但是现代系统也允许我们编写一个进程里同事运行多个线程的
 程序。线程由内核自动调度。每个线程都有它自己的线程上下文thread context包括一个
 唯一的整数线程ID hreadiD tid、栈、栈指针、程序计数器、通用目的寄存器和
 条件码。所有的运行在一个进程里的进程和基于IO多路复用的流的特性。同进程一样，线
程由内核自动调度，并且内核通过一个整数ID来识别线程。同基于IO多路复用的流一样
，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的所有内容，
包括它的代码、数据、堆、共享库和打开的文件。

12.3.1 线程执行模型
   多线程的执行模型在某些方便和多进程的执行模型是相似的。每个进程开始生命周期
时都是一个单一线程，这个线程称为主线程main thread在某一时刻，主线程创建一个对等线程
peerthread ，从这个时间点开始，两个线程就并发地运行。最后，因为主线程执行
一个慢速系统调用，例如read或者sleep，或者因为被系统的间隔计时器终端
，控制就会通过上下文切换传递到对等线程。对等线程会执行一段时间，然后控制传递回
住线程，以此类推。
  有一些重要的方面，线程执行是不同于进程的。因为一个线程的上下文要比一个进程
的上下文要小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程
不像进程那样，不是按照阉割的父子层次来组织的。和一个进程相关的线程组成一个对等
池，独立于其他线程创建的线程。主线程和其他线程的区别在于它总是进程中第一个
运行的线程。对等线程池概念的主要影响是，一个线程可以杀死他的任何对等线程，
或者等待它的任意对等线程终止。另外，每个对等线程都能读写相同的共享数据。

12.3.2 posix 线程
 posix线程pthreads是C程序中处理线程的有一个标准接口。它最早出现在1995
 年，而且在所有的LInux系统上都可用。pthreads定义了大约60个函数，允许程序创建
 杀死和回收线程，与对等线程安全的共享数据，还可以通知对等线程系统状态变化。
   
   主线程创建一个对等线程，然后等待它的
   终止。对等线程输入HW并且终止。当住线程检测到对等线程终止后，
   它就通过调用EXIT终止该进程。这是我们看到的第一个现成话的程序，所以让我们仔细
地解析它。线程的代码和本地数据被封装在一个线程历程thread routine中，正如第二行
里的原型所示，每个线程例程都以一个通用指针作为主人，并返回一个通用指针。如果想
传递多个阐述给线程例程，那么你应该将参数放到一个结构中，并传递一个指向该结构的
指针。相似的，如果想要线程例程返回多个参数，你可以返回一个指向一个结构的指针。

   第四行标出了主线程代码的开始。主线程声明了一个本地变量tid，可以用来存放对等
线程的ID。主线程通过调用pthreadcreate函数创建一个新的对等线程
当对pthreadcreate的调用返回时，主线程和新创建的对等线程同时运行，并且
TID包含新线程的ID。通过在调用pthreadjoin主线程等待对等线程终止。
最后，主线程调用exit，终止当时运行在这个进程中的所有线程。
 对等线程的例程。它只打印一个字符串，然后就通过执行return语句来终止对等线程。

12.3.3 创建线程
  线程通过调用pthread create函数来创建其他线程。
  pthread_create函数创建一个新的线程，并带着一个输入变量arg，在新线程的上
  下问运行线程例程f。能用attr参数来改变新创建线程的默认属性。改变这些属性已
超出我们学习的范围，总是用一个位null的attr参数来调用
pthreadcreate函数。
   当pthreadcreate返回时，参数tid包含新创建线程的ID。新线程可以通过调用
   pthreadself函数来获得它自己的线程ID

12.3.4 终止线程
一个线程是以下方式之一来中的
当顶层的线程例程返回时，先吹隐式地终结。
通过调用pthreadexit函数，线程会显示地终止。如果住线程调用pthreadexit
他会等待所有其他对等线程终止，然后再终止主线程和整个进程，返回值为
thread——returen。
某个对等线程调用linux的exit函数，该函数终止进程以及所有该进程相关的
线程。
另一个对等线程通过以当前线程ID作为参数调用pthreadcancel函数来终止当前
线程。

12.3.5 回收已终止线程的资源
  线程通过调用pthreadjoin函数等待其他线程终止
  pthreadjoin函数会阻塞，知道线程tid终止，将线程例程返回的通过指向
  复制为threadreturn指向的位置，然后回收已终止线程占用的所有内存资源。
  注意，和linux的wait函数不同，pthreadjoin函数只能等待一个指定的线程终止
  。没有办法让pthreadwait等待任一一个线程终止。这使得代码更加复杂，因为它迫
  使我们去使用其他一些不那么直观的机制来检测进程的终止。实际上，stevens中
  就很有说服力地论证了这是规范中的一个错误
  
  12.3.6 分离线程
   在任何一个时间点上，线程是可结合的joinable或者分离的detached .一个可结
合的线程能够被其他线程回收和杀死。在被其他线程回收之前，它的内存资源例如栈是
不释放的。想法，一个分离的线程是不能被其他线程回收或杀死的。它的内存资源在它
终止时系统自动释放。
   默认情况下，线程被创建成可结合的。为了避免内存泄露，每个可结合线程都应该要么
被其他线程显示的回收，要么通过调用pthreaddetach函数被分离。
  pthreaddetach函数分离可结合线程TID。线程能够通过pthreadself为参数
  的pthreaddetach调用来分离它们自己。
  尽管我们的一些例子会使用可结合线程，但是在现实程序中，有很好的理由要使用
  分离线程。例如，一个高性能web服务器可能在每次收到web浏览器的连接请求时都创建
  一个新的对等线程。因为每个连接都是由一个单独的线程独立处理的，所以对于服务器而言
  ，就很没有必要显示的瞪大每个对等线程终止。在这种情况下，每个
  对等线程都应该在他们开始处理请求之前分离它自身，这样就能在它终止后回收它的内存
  资源了。

12.3.7 初始化线程
 pthread_one函数允许你初始化与线程例程相关的状态。
 
  once_control变量是一个全局或者静态变量，总是被初始化为pthread_onceinit
当你第一次用参数once_control调用pthreadone时，它调用initcoutine这是一个没有输入
参数、也不返回什么函数。接下来的以oneccontrol为参数
的pthreadonce调用不做任何事情。无论何时，当你需要动态初始化多个线程共享的全局
变量时，pthreadonce函数是很有用的。

12.3.8 基于线程的并发服务器
   展示了基于线程的并发echo服务器的代码。整体结构类似于基于进程的设计
。主线程不断地等待连接请求，然后创建要给对等线程处理该请求。虽然代码看似简单
但是有几个普通而且有些微妙的问题需要我们更仔细地看一看。第一个问题是当我们
调用pthreadcreate时，如何将已连接描述符传递给对等线程。最明显的方法就是传递
一个指向这个描述符的指针，就像下面这样。
然后，我们让对等线程间接引用这个指针，并将它复制给一个局部变量

然而，这样可能会出错，因为它在对等线程的复制语句和主线程的accept语句间引入了
竞争race。如果复制语句在下一个accept之前完成，那么对等线程中的局部变量
connfd就得到正确的描述符值。然而，如果复制语句是在accept之后才完成的，那么对等
线程中的局部变量connfd就得到下一次连接的描述符值。那么不幸的结果就是，现在两个线程
在同一个描述符上执行输入和输出。为了避免这种潜在的致命竞争，我们必须将
accept返回的每个已连接描述符分配到它自己的动态分配的内存块。

12.4 多线程程序中的共享变量
 从程序员的角度来看,线程很有吸引力的一个方面是多个线程很容易共享相同的程序
变量。然而，这种共享也是很棘手的。为了编写正确的多线程程序，我们必须对所谓的共享
以及它是如何工作的有很清楚的了解。
  为了理解C程序中的一个变量是否是共享的，有一些基本的问题要解答1.线程的基础
内存模型是什么。2.根据这个模型，变量示例是如何映射到内存的3.最后有多少钱
成引用这些事例。一个变量是共享的，当且仅当多个线程引用这个变量的某个实例。
  为了让我们对共享的讨论具体化，我们将使用程序作为运行示例。尽管
有些人为的痕迹，但是它仍然值得研究，因为它说明了关于共享的许多细微之处。示例程序
由一个创建了两个对等线程的主线程组成。主线程传递一个唯一的ID给每个对等线程，
每个对等线程利用这个ID输出一条个性化的信息，以及调用该线程例程的总次数。

12.4.1 线程内存模型
   从程序员的角度来看，线程很有吸引力的一个方面是多个线程很容易共享相同的程序
变量。然而，这种共享也是很棘手的。为了编写正确的多线程程序，我们必须对所谓的共
享以及它是如何工作的有很清楚的了解。
  为了理解C程序中的一个变量是否是共享的，有一些基本的问题要解答1.线程的基
础内存模型是什么2.根据这个模型，变量示例是如何映射到内存的3.最后，有多少线程
引用这些事例，一个变量时共享的，当且仅当多个线程引用这个变量的某个实例
  为了让我们对共享的讨论具体化，我们将使用中的程序作为运行示例。尽管
有些认为的痕迹，但是它仍然值得研究，因为它说明了关于共享的许多细微之处。示例程序
由一个创建了两个对等线程的主线程组成。主线程传递一个唯一的ID给每个对等线程。
每个对等线程利用这个ID输出一条个性化的信息，以及调用该线程例程的总次数。

12.4.1 线程内存模型
   一组并发线程运行在一个进程的上下文中。每个线程都有它自己独立的线程上下文,
包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值。每个线程和其他
线程一起共享进程上下文的剩余部分。这包括整个用户虚拟地址空间，它是由只读文本
、读写数据、堆以及所有的共享代码库和数据区域组成的。线程也共享相同的打开
文件集合。
  从实际操作的角度来说，让一个线程去读或写另一个线程的寄存器值是不可能的。另
以方面，任何线程都可以访问共享虚拟内存的任一位置。如果某个线程修改了一个内存位置
，那么其他每个线程最终都能在它读这个位置时发现这个变化。因此，寄存器是从不共享
的，而虚拟内存总是共享的。
   各自独立的线程栈的内存模型不是那么整齐清楚的。这些栈被保持在虚拟地址空间的
栈区域中，并且通常是被相应的线程独立的访问的。我们说通常而不是总是，是因为不同
的线程栈是不对其他线程设防的。所以，如果一个线程以某种方式得到一个指向其他线程
栈的指针,那么它就可以读写这个栈的任何部分。示例程序展示了这一点，其
中对等线程直接通过全局变量ptr间接引用主线程的栈的内容。

12.4.2 将变量映射到内存
 多线程的C程序中变量根据它们的存储类型被映射到虚拟内存：
 *全局变量。全局变量时定义在函数之外的变量。在运行时，虚拟内存的读写区域
 值包括每个全局变量的一个实例，任何线程都可以引用。例如，第五行声明的全局
 变量ptr在虚拟内存的读写区域中有一个运行时实例。当一个变量只有一个实例
 时，我们只用变量来表示这个实例。
 *本地自动变量。本地自动变量就是定义在函数内部但是没有static属性的变量。
 在运行时，每个线程的栈都包含它自己的所有本地自动变量的实例。即是多个线程
 执行同一个线程例程时也是如此。例如，有一个本地变量tid的实例，它保存在主
 线程的栈中。我们用tid。m来表示这个实例。再来看一个例子，本地变量myid有
 两个实例，一个在对等线程O的栈内，另一个在对等线程1的栈内。我们将这两个
 实例分别表示为myid.po和myid.p1
 *本地静态变量。本地静态变量时定义在函数内部并有static属性的变量。和全局
 变量一样，虚拟内存的读写区域值包含在程序中生命的每个本地静态变量的一个
 实例。例如，即是示例程序中的每个对等线程都在25行生命了CNT，在运行时，
 虚拟内的读写区域中也只有一个cnt实例。每个对等线程都渡河写这个实例。
12.4.3 共享变量
   我们说一个变量V时共享的，当且仅当它的一个实例被一个以上的线程引用。例如
实例程序中的变量CNT就是共享的，因为它只有一个运行时实例，并且这个实例被两个对等
线程引用。在另一方面，myid不是共享的，因为他的两个实例中每一个都只被一个线程
引用。然而，认识到像msgs这样的本地自动变量也能被共享是很重要的。


12.5 用信号量同步线程
  共享变量是十分方便，但是他们也引入了同步错误synchronization errro的可能性。
它创建了两个线程，每个线程都对共享计数变量CNT加1

因为每个线程都对计数器增加了niters次，我们预计它的最终值是2*niters这看上去
简单而直接。然而，当在linux系统上运行badcnt。c时，我们不仅得到错误的答案
，而且每次得到的答案都还不相同。
  那么哪里出错了呢，为了清晰地理解这个问题，我们需要研究计数器循环
的汇编代码，我们发现，将线程I的循环代码分解成五个部分是很有帮助的
Hi在循环头部的指令块。
Li加载共享变量cnt到累加寄存器rdx的指令，这里rdx表示线程I中的寄存器的值。
Ui更新rdx的指令
Si将rdx的更新值存回到共享变量cnt的指令
Ti循环尾部的指令块。
注意头和尾值操作本地栈变量，而LiUi和Si操作共享计数器变量的内容。
当badcnt。c中的两个对等线程在一个单处理上并发运行时，机器指令以某种顺序
一个接一个地完成。因此，每个并发执行定义了两个线程中的指令的某种全徐。
不行的是，这些顺序中的一些将会产生正确结果，但是其他的则不会。
这里有个关键点:一般而言，你没有办法预测操作系统是否将你为的线程选择一个正确
的顺序。例如展示了一个正确的指令顺序的分布操作。在每个线程更新了
共享变量cnt之后，它在内存中的值就是2，这正是期望的值。
  另一方面，图的顺序产生一个不正确的cnt值。会发生这样的问题是因为，
线程2在第五步加载cnt，是在第二部线程1加载cnt之后，而在第六步线程1存储它的
更新值之前。因此，每个线程最终都会存储一个值为1的更新后的计数器值。我们能够借助
与一种叫做进度图progress graph的方法来阐明这些正确的和不正确的指令顺序的概念

12.5.1 进度图
  进度图progress graph 将n个并发线程的执行模型化为一条n维笛卡尔空间中的轨迹
线。每条轴k对应于线程k的进度。每个点i1i2代表线程k
已经完成了指令Ik这一状态。图的原点对应于没有任何线程完成一条指令的初始状态。
 展示了badcnt。c程序第一次循环迭代的二维进度图。水平轴对应于线程1
 垂直轴对应于线程2.点L1S2对应于线程1完成了L1而线程2完成了S2的状态。
    进度图将指令执行模型化为从一种状态到另一种状态的转换transition。转换被表示
为一条从一点到相邻点的有向变。合法的转换是向右或者向上
的。两条指令不能在同一时刻完成对象先转换是不允许的。
程序不会反向运行，所以乡下或者向左移动的转换也是不合法的。
   一个程序的执行理事被模型化为状态空间中的一条轨迹线。展示了下面指令
顺序对应的轨迹线。
   对于线程I，操作共享变量cnt内存的指令构成了一个
临界区，这个临界区不应该和其他进程的临界区交替执行。换句话
说，我们想要确保每个线程在指令它的临界区中的指令时，拥有对共享变量的互斥的访
问。通常这种线程称为互斥。
   在进度图中，两个临界区的交集形成的状态空间区域称为不安全区
展示了变量cnt的不安全区。注意，不安全区和与它交接的状态相毗邻，但并
不包括这些状态。例如，状态h1 h2和s1 u2毗邻不安全区，但是他们并不是不安全
的一部分。绕开不安全区的轨迹线叫安全轨迹线。相反，解除到任何
不安全区的轨迹线就叫做不安全轨迹线。给出示例程序
badcnt的状态空间中的安全和不安全轨迹线。上面的轨迹线绕开了不安全区域的左边
和上边，所以是安全的。下面的轨迹线穿越不安全区，因此是不安全的。
  任何安全轨迹线都是将争取地更新共享计数器。为了保证线程程序实例的正确执行
  我们必须以某种方式同步线程，使他们总是有一条安全轨迹线。一个景点的方法是
  基于信号量的思想，接下来我们就介绍它。

12.5.2 信号量
    edsger dijkstra 并发编程领域的先锋人物。提出了一种景点的解决同步不同执行线程
问题的方法,这种方法是基于一种叫做信号量 semaphore的特殊类型变量的。信号量s
是具有非负整数值得全局变量，只能两种特殊的操作来处理，这两种操作称为P和V：
P:如果s是非零的，那么P将S减一，并立即返回。如果s为0，那么久挂起
这个线程，直到s变为非0，而一个V的操作会重启这个线程。在重启之后，P操作
将s减一，并将控制返回给调用者。

V：V操作将s加1.如果有任何线程阻塞在P操作等待s编程非0 ，那么V操作
会重启这些线程中的一个，然后改线程将s减一，完成他的P操作。

P中的测试和减1操作是不可分割的，也就是说，一旦预测信号量s变为非零，就会
将s减一，不能有中断。V中的加1操作也是不可分割的，也即是加载、加1和存储信号
量的过程中没有中断。注意，V的定义中没有定义等待线程被重启动的顺序。唯一的要求
是V必须只能重启一个正在等待的线程。因此，当有多个线程在等待同一个信号量时，你
不能预测V操作要重启哪一个线程。

  P和V的定义确保了一个正在运行的程序绝不可能进入这样一种状态，也就是一个正
确初始化了的信号量有一个负值。这个属性成为信号量不变性semaphore invariant 为
控制并发程序的轨迹线提供了强有力的工具，在下一节中我们将看到
posix标准定义了许多操作信号量的函数

  sem_init 函数将信号量sem初始化为value。每个信号量在使用前必须初始化。针对
我们的目的，中间的参数总是0.程序分别通过调用sem_wait和sem_post函数来执行
P和V操作。为了简明，我们更喜欢使用下面这些等价的P和V的包装函数：

12.5.3 使用信号量来实现互斥
   信号量提供了一种很方便的方法来确保对共享变量的互斥访问。基本思想是将每个共享
变量与一个信号量S联系起来，然后用P和V
操作将相应的临界区包围起来。
   以这种方式来保护共享变量的信号量叫做二元信号量binary semaphore,因为他的
值总是0或1.以提供互斥为目的的二元信号量常常也称为互斥锁mutex.在一个互斥
锁上执行P操作称为对互斥锁加锁。类似的，执行V操作称为对互斥锁解锁。对一个
互斥锁加了锁但是还没有解锁的线程称为占用这个互斥锁。一个被用作一组可用资源的计数器
的信号量被称为计数信号量。
   进度图展示了我们如何利用二元信号量来正确地同步计数器程序示例。
每个状态都标出了该状态中的信号量s的值。关键思想是这种P和V操作的结合创建了一组
状态，叫做禁止区forbidden region,其中S《0 因为信号量的不变性，没有实际可行的
轨迹线能够包含禁止区中的状态。而且，因为进制区完全包括了不安全区，所有没有实际
可行的轨迹线能够接触不安全区的任何部分。因此，每条实际可行的轨迹线都是安全的，
而且不管运行时指令顺序是怎样的，程序都会正确地增加计数器值。
   从可操作的意义上来说，由P和V操作创建的禁止区使得在任何时间点上，在被包
围的临界区中，不可能有多个线程在执行指令。换句话说，信号量操作确保了对临界区的
互斥访问。
   总的来说，为了用信号量正确同步中的计数器程序示例，我们首先声明一个
信号量mutex
   然后在住例程中将mutex初始化为1
   最后，我们通过把在线例程中对共享变量cnt的更新包围P和V操作，从而保护
他们
    进度图给了我们一种较好的方法，将在单处理器上的并发程序执行可视化，也帮助
我们理解为什么需要同步。然后，他们确实也有局限性，特别是对于在多处理器上的并发
执行，在多处理器上一组CPU高速缓存对共享同一个主存。多处理器的工作方式是
进度前不能解释的。特别是，一个多处理器内存系统可以处于一种状态，不对应于进度
图中任何轨迹线。不管如何，结论总是一样的：无论是在单个处理器还是多处理器上运行
程序，都要同步你对共享变量的访问。
12.5.4 利用信号量来调度共享资源
   除了提供互斥之外，信号量的另一个重要作用是调度对共享资源的访问。在这种场景
中，一个线程用信号量操作来通知另一个线程，程序装填中的某个条件已经为真了。两个
经典而有用的例子是生产者-消费者和读者-写者问题。

   1.生产者-消费者问题
   给出了生产者-消费者问题。生产者和消费者线程共享一个由N个槽的有限缓冲
区。生产者线程返回地生成新的项目item，并把他们插入到缓冲区中。消费者线程不断地
从缓冲区中取出这些项目，然后消费他们。也可能有多个生产者和消费者的变种。
   因为插入和取出项目都设计更新共享变量，所以我们必须保证对缓冲区的访问是互斥
的。但是只保证互斥访问是不够的，我们还需要调度对缓冲区的访问。如果缓冲区是满的
，那么生产者必须等待直到有一个槽位变为可用。与之相似，如果缓冲区
是空的，那么消费者必须等待直到有一个项目变为可用。
   生产者-消费者的相互作用在现实系统中是很普遍的。例如，在一个多媒体系统中，
生产者编码视频帧，而消费者解码并在屏幕上呈现出来。缓冲区的目的是为了减少视频流
的抖动，而这种抖动是由各种帧的编码和解码时与数据相关的差异引起的。缓冲区为生产者
提供了一个槽位池，而为消费者提供一个已编码的帧池。另一个常见的示例是图形用户
接口设计。生产者检测到鼠标和键盘事件，并将他们插入到缓冲区中。消费者已某种基于
优先级的方式从缓冲区取出这些事件，并显示在屏幕上。
   在本节中，我们将开发一个简单的包，叫做SBUF，用来构造生产者-消费者程序。
在下一节里，我们会看到如何用它来构造一个基于预线程化prethreading的有趣的并发
服务器。SBUF操作类型为sbuf的有限缓冲区。项目存放在一个动态分配的
N项整数数组BUF中。front和rear索引值记录该数组中的第一项和最后一项。三个信号量
同步对缓冲区的访问。mutex信号量提供互斥的缓冲区的fangwen.slots和items信号量
分别记录空槽位和可用项目的数量。

   SBUF函数实现。sbufinit函数为缓冲区分配堆内存，设置
front和rear表示一个空的缓冲区，并为三个信号量赋初始值。这个函数在调用其他三
个函数中的任何一个之前调用一次。sbufdeinit函数是当应用程序使用完缓冲时区，释放
缓冲区存储的。sbufinsert函数等待一个可用的槽位，对互斥锁加锁，添加项目，对
互斥锁解锁，然后宣布有一个新项目可用。sbufremove函数是与sbufinsert函数对称
的。在等待一个可用的缓冲区项目之后，对互斥锁加锁，从缓冲区的前面取出该项目，
对互斥锁解锁，然后发信号通知一个新的槽位可供使用。
   一个主存中的数据结构，或者一个磁盘上的数据库。有些线程只读对象，而其他的线程只
修改对象。修改对象的线程叫做写者。只读对象的线程叫做读者。写着必须拥有对象的
独占的访问，而读者可以和无线多个其他的读者共享对象。一般来说，有无线多个并发的
读者和写着。
   读者写着交互在现实系统中很常见。例如，一个在线航空预定系统中，允许有
无线多个客户同事查看座位分配，但是正在预定座位的客户必须拥有对数据库的独占
的访问。再来看另一个例子，在一个多线程缓存web代理中，无线多个线程可以从
共享页面缓存中取出已有的页面，但是任何向缓存中写入一个新页面的线程必须拥有
独占的访问。
   读者写着问题有几个变种，分别基于读者和写着的优先级。第一类读者写着问题，读者
优先，要求不要让读者等待，除非已经把使用对象的权限赋予了一个写着。换句话说，读者不会
因为有一个写着在等待而等待。第二类读者写着问题，写着优先，要求一旦一个写着准备好
可以写，它就会尽可能快地完成他的写操作。同第一类问题不同，在第一个写着后到达的读者必须等待
即是这个写着也是在等待。
  给出了一个队第一类读者-写着问题的解答。同许多同步问题的解答一样，
这个解答很微妙，极具欺骗性地简单。信号量w控制对访问共享对象
的临界区的访问。信号量mutex保护对共享变量readcnt的访问，readcnt统计
当前在临界区中的读者数量。每当一个写着进入临界区时，它对互斥锁w加锁
，每当它离开临界区时，对w解锁。这就保证了任一时刻临界区中最多只有一个写者。
另一方面，只有第一个进入临界区的读者对w加锁，而只有最后一个离开临界区的读者对w解锁。当一个读者
进入和离开临界区时，如果还有其他读者在临界区中，那么这个读者会忽略
互斥锁w。这就意味着只要还有一个读者占用互斥锁w，无线多数量额读者可以没有障碍
地进入临界区。
   对这两种读者写着问题的正确解答可能导致饥饿starvation,集合就是一个
线程无限期地阻塞，无法进展。例如，图12-26所示的解答中，如果有读者不断地
到达，写着就可能无限期地等待。
   其他同步机制
   我们已经向你展示了如何利用信号量来同步线程，主要是因为它们简单、经典，并且
有一个清晰的语义模型。但是你应该知道还是存在着其他同步技术的。例如，java线程是
用一种叫做java监控器javamoitor的机制来同步的，它提供了对信号量互斥和调度
能力的更高级别的抽象；实际上，监控器可以用信号量来实现。再来看一个例子，
pthreads接口定义了一组对互斥锁和条件变量的同步操作。pthreads互斥锁被用来实现互斥
。条件变量用来调度对共享资源的访问，例如在一个生产者消费者程序中的有限缓冲区。

12.5.5 综合：基于预线程化的并发服务器
   我们已经知道了如何使用信号量来访问共享变量和调度对共享资源的访问。为了帮助
你更清晰地理解这个思想，让我们把它们应用到一个基于称为预线程化prethreading技术
的并发服务器上。
  并发服务器中，我为每一个新客户端创建一个新的线程。这种方法
的缺点是我们为每一个新的客户端创建一个新线程，导致不小的代价。一个基于预线程化
的服务器试图通过使用所示的生产者-消费者模型来降低这种开销。服务器是
由一个主线程和一组工作者线程构成的。主线程不断地接受来自客户端的连接请求，并将
得到的连接描述符放在一个有限缓冲区中。每一个工作线程反复地从共享缓冲区中取出
描述符，为客户端服务，然后等待下一个描述符。
     显示了我们怎样用SBUF包来实现一个预线程化的并发echo服务器。在初始化
了缓冲区sbuf后，主线程创建了一组工作者线程。然后它进入
了无线的服务器循环，接受连接请求，并将得到的已连接描述符插入到缓冲区SBUF中。
每个工作者线程的行为都非常简单。它等待直到它能从缓冲区中取出一个已连接描述符
，然后调用echocnt函数回送客户端的输入。
   所示的函数echocnt中的echo函数的一个版本，他在全局变量
byte_cnt中记录了从所有客户端连接到的累计字节数。这是一段值得研究的有趣代码，
因为它向你展示了一个从现场例程调用的初始化程序包的一般技术。在这种情况中，我们
要初始化bytecnt计数器和mutex信号量。一个方法是我们为sbuf和RIO程序包
使用过的，它要求主线程显示地调用一个初始化函数。另外一个方法，在此显示的，是当
第一次有某个线程调用echocht函数时，使用pthreadonce函数去调用初始化
函数。这个方法的有点是它使程序包的使用更加容易。这种方法的缺点是没一次调用echo
cnt都会导致调用pthreadonce函数，而在大多数时候它没有做什么有用的事。
  一旦程序包被初始化，echocnt函数会初始化RIO带缓冲区的IO包
然后回送从客户端接收到的每一个文本行。注意，在第23-25行中对共享变量byte
的访问是被P和V操作保护的。
  基于线程的事件驱动程序
   IO多路复用不是编写事件驱动的唯一方法。例如，你可能已经注意到我们刚
才开发的并发的预线程化的服务器实际上是一个事件驱动服务器，带有主线程和工作者
线程的简单状态机。主线程有两种状态等待连接请求和等待可用的缓冲区槽位
两个IO事件和两个转换。类似地，每个工作者线程有一个状态、一个IO
事件和一个转换。
12.6 使用线程提供并行性
 到目前为止，在对并发的研究中，我们都假设并发线程是在单处理器系统上的执行的。
然而，大多数现代机器具有多核处理器。并发程序通常在这样的机器上运行的更快。因为
操作系统内核在多个核上并性地调度这些并发线程，而不是在单个核上顺序地调度。在像
繁忙的web服务器、数据库服务器和大型科学计算代码这样的应用中利用这样的并行性
是至关重要的，而且在像web浏览器、电子边核处理程序和文档处理程序这样的主流应用
中，并行性也变得越来越有用.
   给出了顺序、并发和并行程序之间的集合关系。所有程序的集合能够被划分成不想交
的顺序程序集合和并发程序集合。写顺序程序只有一条逻辑流。写并发程序有多条并发流。
并行程序是一个运行在多个处理器上的并发程序。
因此，这行程序的集合是并发程序集合的真子集。
   并行程序的详细处理超出了本书的范围。
但是研究一个非常简单的示例程序能够帮助你理解并行编程的一些重要的方面。例如，考虑
我们如何并行地对一列整数求和。当然，对于这个特殊的问题，有闭合形式
表达式的解答，但是尽管如此，它是一个简洁和已于理解的示例，能让我们对并行程序做
一些有趣的说明。
  将任务分配到不同线程的最直接方法是将序列划分成T个不想交的区域，然后给T个
不同的线程每个分配一个区域。为了简单，假设n是t的倍数，这样每一个区域有n、t个元素
。让我们来看看多个线程并行处理分配给他们的区域的不同方法。
   最简单也最直接的选择是将线程的和放入一个共享全局变量中，用互斥锁保护这个变量。
给出了我们会如何实现这种方法。主线程创建对等线程，然后
等待他们结束。注意，主线程传递给每个对等线程一个小整数，作为唯一的线程ID。每个对等
线程户用它的线程ID来决定它应该计算序列的那一部分。这个向对等线程传递一个小的
唯一的线程ID的思想是一项通用技术，许多并行应用中都用到了它。在对等线程终止后，
全局变量gsum包含着最终的和。然后主线程用闭合形式解答来验证结果
   每个对等线程执行的函数。线程从线程参数总提取出线程ID，
然后用这个ID来决定它要计算的序列区域。线程在它的那部分序列上迭代操作。
每个迭代都更新共享全局变量gsum。注意，我们很小心地用
P和V互斥操作来保护每次更新。
  我们在一个四核系统上，对一个大小为N=2 31的序列运行psum-mutex,测量它的运行
时间，作为线程数的函数，得到的结果难懂又令人奇怪。
   程序单线程顺序运行时非常慢，几乎比多线程并行运行时满了一个数量级。不仅如此
使用的合数越多，性能越差。超时性能差的原因是相对于内存更新操作的开销，同步
操作P和V代价太大。这凸显了并行编程的一项重要教训：同步开销巨大，要尽可能避免
。如果无可避免，必须要用尽可能多的用计算弥补这个开销。
  在我们的例子中，一种避免同步的方法是让每个对等线程在一个私有变量中计算它自己
  的部分和，这个私有变量不予其他任何线程共享。主线程
定义了一个全局数据psum，每个对等线程I把它的部分和累计在psum中。因为小心
地给了每个对等线程一个不同的内存位置来更新，所以不需要用互斥锁来保护这些更新。
唯一需要同步的地方是主线程必须等待所有的子线程完成。在对等线程结束后，主线程把
PSUM向量的元素加起来，得到最终的结果。
    在四核系统上运行psum-array时，我们看到它比psum-mutex运行得快好几个数
    量级
  我们学习到了如何使用局部变量来消除不必要的内存引用。
如何应用折现该原则，让么给对等线程把它的部分和累计在一个局部变量而不是全局变量
中。当四核机器上运行psumlocal时，得到一组新的递减的运行时间：
    
刻画并行程序的性能

运行时间，它是线程数的函数。在每个情况下，程序运行在一个由四个处理器核的系统上，
对一个n=2 31个元素的序列求和。我们看到，随着线程数的增加，运行时间下降，知道
增加到四个线程，此时，运行时间区域平稳，甚至开始有点增加。
   在理想的情况中，我们会期望运行时间随着核心数的增加线性下降。也就是说
我们会期望线程数没增加一倍，运行时间就下降一半。确实是这样，知道达到T>4的时候
此时四个核中的每一个都忙于运行至少一个线程。随着线程数量的增加，运行时间实际上增加
了一点儿，这是由于在一个核上多个线程上下文切换的开销。由于这个原因，并行程序
常常被写为每个核上只允许一个线程。
   虽然绝对运行时间是衡量程序性能的最终标准，但是还有一些有用的相对衡量标准neng
够说明并行程序有多好滴利用了潜在的并行性。并行程序的加速比speedup通常定义为
S=T1/ Tp  
这里P是处理器核的数量，Tk是在k核上的运行时间。这个公式有时被称为强拓展
strong scaling.当T1是程序顺序执行版本的执行时间时，Sp称为绝对加速比
。当T1是程序并行版本在一个核上的执行时间适，Sp称为相对加速比relative
speedup.绝对加速比比相对加速比能更真实地衡量并行的好处。即使是当并行程序在
一个处理器上运行时，也常常会收到同步开销的影响，而这些开销会认为地增加相对加速比
的数值，因为它们增加了分子的大小。另一方面，绝对加速比比相对加速比更难以测量，
因为测量绝对加速比需要程序的两种不同的版本。对于复杂的并行代码，创建一个独立的
顺序版本可能不太实际，或者因为代码太复杂，或者因为源代码不可得。
   一种相关的测量量称为效率efficiency,定义为
    E
   通常表示为范围在0-100之间的百分比。效率是对由于并行化造成的开销的衡量。具有
高效率的程序比效率低的程序在有用的工作上划分更多的时间，在同步和通信上划分更少的
s时间。
   给出我们并行求和示例程序的各个加速比和效率测量值。
像这样超过90%的效率是非常好的，但是不要被欺骗了。能取得这么高的效率是因为
我们的问题非常容易并行化。在实际中，很少会这样。
数十年来，并行编程一直是一个很活跃的研究领域。随着商用多核机器的出现，这些机器的盒数
没几年就翻一番，并行编程会继续是一个深入、困难而活跃的研究领域。
    加速比还有另外一面，称为若拓展weak scaling，在增加处理器数量的同事，增加
问题的规模，这样随着处理器数量的增减，每个处理器执行的工作量保持不变。在这种描述
中，加速比和效率被表达为单位时间完成的工作总量。例如，如果将处理器数量翻倍，
同时每个小时也做了两倍的工作量，那么我们就有线性的加速比和100的效率。
  弱拓展常常是比强拓展更真实的衡量值，因为它更准确地反应了我们更大的机器做
更多的工作的愿望。对于科学计算程序来说尤其如此,科学计算问题的规模很容易增加，
更大的问题规模直接就意味着更好地预测。不过，还有一些应用的规模不那么容易增加
，对于这样的应用，强拓展是更合适的。例如，实时信号处理应用锁执行的工作量常常
是由产生信号的物理传感器的属性决定的。改变工作总量需要用不同的物理传感器，这不
太实际或者不太必要。对于这类应用，我们通常想要用并行来尽可能快地完成定律的工作。

12.7 其他并发问题
  你可能已经注意到了，一旦我们要求同步对共享数据的访问，那么事情就变得复杂得多了
。迄今为止，我们已经看到了用于互斥和生产者-消费者同步的技术，但这仅仅是冰山
一角。同步从根本上说是很难的问题，它引出了再普通的顺序程序中不会出现的问题。
这一小节是关于你在写并发程序时需要注意的一些问题非常不完整的总数。为了让事情
具体化，我们将以现场为例描述讨论。不过要记住，这些景点问题是任何类型的并发流
操作共享资源时都会出现的。

12.7.1 线程安全
   当用线程编写程序时，必须小心地编写那些具有称为线程安全性属性的函数
。一个函数被称为线程安全的thread save ，当且仅当被多个并发线程反复地调用
时，它会一直产生正确的结果。如果一个函数不是线程安全的，我们就说它是线程不安全
的thread unsafe
   我们能够定义出的四个不想交的线程不安全函数类
   第一类:不保护共享变量的函数。thread函数总就已经遇到了这样的问题，
该函数对一个未受保护的全局计数器变量加1.将这类线程不安全函数编程线程安全的
相对而言比较容易：利用像P和V操作这样的同步操作来保护共享的变量。这个方法
的有点是在调用程序中不需要做任何修改。缺点是同步操作将减慢程序的执行时间。

   第二类:保持跨越多个调用的状态的函数。一个伪随机数生成器是这类线程不安全函数
的简单例子。为随机数生成器程序包。rand函数是线程不安全的，
因为当前调用的结果依赖于前次调用的中间结果。当调用srand为rand设置了一个种子后
，我们从一个单线程中反复地调用rand，能够与其得到一个可重复的随机数字序列。
然而，如果多线程调用rand函数，这种假设就不再成立了。
  
  使得像rand这样的函数线程安全的唯一方式是重写它，使得它不再使用任何static
数据，而是依靠调用者在参数中传递状态信息。这样做的缺点是，程序员线程还要被迫修
改调用程序中的代码。在一个大的程序中，可能有成败上线个不同的调用位置，做这样的
修改将是非常麻烦的，而且容易出错。
   第三类：返回指向静态便利店额指针的函数。某些函数，例如ctime和gethost-byname,
将计算结果放在一个static变量中，然后返回一个指向这个变量的指针。如果我们
从并发线程中调用这些函数，那么将可能发生灾难，因为正在被一个线程使用的结果会
被另一个线程悄悄地覆盖了。
    有两种方法来处理这类线程不安全函数。一种选择是重写函数，使得调用者传递存放结果
的变量的地址。这就消除了所有的共享数据，但是它要求程序员能够修改函数的源代码
   如果线程不安全函数是难以修改或不可能修改的，那么另外一种选择就是使用加锁-复制
   locakand copy 技术。基本丝线格式将线程不全
   函数与互斥锁联系起来。在每一个调用位置，对互斥锁加锁，调用线程不安全函数
将函数返回的结果复制到一个私有的内存位置，然后对互斥锁解锁。为了尽可能低减少对
调用者的修改，你应该定义要给线程安全的包装函数，它执行加锁复制，然后通过
调用这个包装函数来取代所有对线程不安全函数的调用。给出了CTIME的一个线程安全的版本，
利用的就是加锁-复制技术。

  第四类：雕工线程不安全函数的函数。如果函数f调用线程不安全函数G，那么f就是
线程不安全的吗？不一定。如果g是第二类函数，即依赖于跨越多次调用的状态，那么
f也是线程不安全的额，而且除了重写G意外，没有什么办法。然而，如果g是第一类或者
第三类函数，那么只要你用一个互斥锁保护调用位置和任何得到的共享数据，f仍然可能
是线程安全的。我们看到了一个这种情况很好的示例，其中我们使用加锁
复制编写了一个线程安全函数，它调用了一个线程不安全的函数。

12.7.2 可重入性
  有一类重要的线程安全函数，叫做可重入函数renntrant function,其特点在于它们具有这样
一种属性：当它们被多个线程调用时，不会引用任何共享数据。尽管线程安全和可重入有时会
被用作同义词，但是他们之间还是有清晰地技术差别，值得留意。
  重入函数、线程安全函数和线程不安全函数之间的集合关系。所有函数的集合被划分成不
相交的线程安全和线程不安全函数集合。可重入函数集合是线程安全函数的一个真子集。
   可重入函数通常要比不可重入的线程安全的函数高效一些，因为它们不需要同步操作
。更进一步来说，将第二类线程不安全函数转化为线程安全函数的唯一方法就是重写它
，使之变为可重入的。例如rand函数的一个可重入的版本
。关键思想是我们用一个调用者传递进来的指针取代了静态的next变量。
  检查某个函数的代码并先验断定它是可重入的，这可能吗？不幸的是，不一定能这样
。如果所有的函数参数都是船只传递的，并且所有的数据引用都是本地的
自动栈变量，那么函数就是显示可重入的，也就是锁，
无论它是被如何调用的，都可以断言它是可重入的。
   然后，如果把假设方宽送一点，允许显示可重入函数中一些参数是引用传递的
那么我们就得到了一个隐士可重入的implicityly reentrant函数，也即是
说，如果调用线程小心地传递指向非共享数据的指针，那么它是可重入的。例如，
randr函数即是饮食可重入的。
   我们总是使用术语可重入的reentrant既包括显示可重入函数也包括隐士可重入函数 
。然而，认识到可重入性有时即是调用者也是被调用者的属性，并不只是被调用者单独
的属性是非常重要的。

12.7.3 在线程化的程序中使用已存在的库函数
    大多数linux函数，包括定义在标准C库中的函数malloc free realoc
printf sacnf都是线程安全的，只有一小部分是例外。列出了常见的例外。
strtok函数是一个已启用的函数
asctime ctime和localtiome 函数是在不同时间和数据格式间互相来回转换时经常使
的函数。gethostbyname gethostbyaddr inetntoa函数是已启用的网络编程函数，已经
分别被可重入的getaddrinfo getnameinfo和inetop 函数取代
出了rand和strtok意外，所有这些线程不安全函数都是第三类的，他们返回一个
指向静态变量的指针。如果我们需要在一个线程化的程序中调用这些函数中的某一个，对
调用者来说最不惹麻烦的方法是加锁复制。然而，加锁复制方法有许多缺点。首先，额外
的同步降低了程序的速度。第二，像gethostbyname这样的函数返回指向复杂结构的
结构的指针，要复制整个结构层次，需要深层复制deep copy结构。第三，加锁复制方法
对像rand这样一来跨越调用的静态状态的第二类函数并不有效。

   因此，linux系统提供大多数线程不安全函数的可重入版本。可重入版本的名字总是
以r后缀结尾。例如，asctime的可重入版本就叫做asctimer 我们建议尽可能地
使用这些函数。

12.7.4 竞争
    当一个程序的正确性依赖于一个线程要在另一个线程到达Y点之前到达它的控制流中的想点
时，就会发生竞争race.通常发生竞争是因为程序员假定线程将按照某种特殊的轨迹线穿过执行
状态空间，而忘记了另一条准则规定：多线程的程序必须对任何可行的轨迹线都正确工作。
  例子是理解竞争本质的最简单的方法。然跟我们看看简单程序。主线程创
建了四个对等线程，并传递一个指向一个唯一的整数ID的指针到每个线程。每个对等线程
复制它的参数中传递的ID到一个局部变量中，然后输出一个包含这个ID的信息。
它看上去足够简单，但是当我们在系统上运行这个程序时，我们得到以下不正确的结果。
   问题是由每个对等线程和住线程之间的竞争引起的。你能发现这个竞争吗？下面是发生
的情况。当主线程在第13行创建了一个对等线程，它传递了一个指向本地栈变量i的指针。
在此时，竞争出现在下一次
   为了消除竞争，我们可以动态地为每个整数ID分配一个独立的块，并且传递给线程
例程一个指向这个块的指针。请注意线程例程必须释放这些块以避免内存泄露

12.7.5 死锁
    信号量引入了一种潜在的令人厌恶的运行时错误，叫做死锁deadlock,它指的是一
组线程被阻塞了，等待一个永远也不会为真的条件。进度图对于理解死锁是一个物价的工具
。展示了一堆用两个信号量来实现互斥的线程的进度图。
  程序员使用P和V操作顺序不当，以至于两个信号量的进制区域重叠。如果某个执行
  轨迹线碰巧到达了死锁状态d，那么久不可能有进一步的进展了。因为重叠的进制区域
  阻塞了每个合法方向上的进展。换句话说，程序死锁是因为每个线程都在等待
  其他线程执行一个跟不可能发生的V操作。
  
  重叠的禁止区域引起了一组称为死锁区域deadlock region 的状态。如果一个轨迹
  先碰巧到到了一个斯诺区域中的状态，那么死锁就是不可避免的了。轨迹线可以进入
  死锁区域，但是他们不可能离开。
  
  死锁是一个相当困难的问题，因为它不总是可预测的。一些幸运的执行轨迹线将绕开死锁
  区域，而其他的将会陷入这个区域。展示了每种情况的一个示例。对于程序员
  来说，这其中隐含的着实令人惊慌。你可以运行一个程序1000次不出任何问题，但是下一次
  它就死锁了。或者程序在一台机器上坑你运行得很好，但是在另外机器上就会
  死锁。最糟糕的是，错误常常是不可重复的，因为不同的执行有不同的轨迹线。
  
  程序死锁有很多原因，要避免死锁一般而言是很困难的。然而，当使用二元信号量来
  实现互斥时，你可以应用下面的简单而有效的规则来避免死锁。
  互斥锁加锁顺序规则：给定所有互斥操作的一个全续，如果每个线程都是以一种顺序
获得互斥锁并以相反的顺序释放的，那么这个程序就是无思索的。
  我们可以通过这样的方法来解决死锁问题：在每个线程中先对s
  加锁，然后在对t加锁。

  12.8 小结
  一个并发程序是由在时间上重叠的一组逻辑流组成的。在这一张中，我们学习了三种不同的构建并
发程序的机制：进程、IO多路复用和线程。我们以一个并发网络服务器作为贯穿权杖的应用程序。

进程是由内核自动调度的，而且因为它们又各自独立的虚拟地址空间，所有要实现共享数据，必须
要有显示的IPC机制。时间驱动程序创建它们自己的并发逻辑流，这些逻辑流被模型为状态机，
用IO多路复用来显示地调度这些流。因为程序运行在一个单一进程中，所有在流之间共享数据速度很快
且很容易。线程是这些方法的混合。同基于进程的流一样，线程也是由内核自动调度的。同基于IO
多路复用的流一样，线程是运行在一个单一进程的上下文中的，因此可以快读而方便地共享数据。
  无论哪种并发机制，同步对共享数据的并发访问都是一个困哪的问题。提出对信号量的P和V操作
  是就是为了帮助解决这个问题。信号量操作可以用来提供对共享数据的互斥访问，也对主语生产者消费者
  程序中有限缓冲区和读者写着系统中的共享对象这样的资源访问进行调度。一个并发预线程化的echo服务器提供了
  信号量使用场景的很好的例子
  
  并发也引入了其他一些困难的问题。被线程调用的函数必须具有一种称为线程安全的属性。我们定义
了四类线程不安全的函数，以及一些将他们变为线程安全的减一。可重入函数是线程安全函数的一个帧子集
。它不访问任何共享数据。可重入函数通常比不可重入函数更为有效。因为它们不需要任何同步愿与
。竞争和死锁是并发程序中出现的另一些困难的问题。当程序员错误滴假设逻辑流该如何调度时，
就会发生竞争。当一个流等当一个永远不会发生的时间，就会产生死锁。
  
  
  
  
  




共享锁shared lock 也叫 读锁 read lock

排他锁exclusive lock 也叫 写锁 write lock


读锁是共享的，或者说是互相不阻塞的。多个客户在同一时刻可以同时读取同一个资源，互不干扰。


写锁是排他的，也就是说一个写锁会阻塞其他的写锁和读锁。


1.2.2 锁粒度
一种提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分
数据，而不是所有的资源。更理想的方式是，只对会修改的数据片进行精确的锁定。
任何时候，在给定的资源上，锁定的数据量越少，则系统的并发程序越高，只要互相之间
不发生冲突即可。

问题是加锁也需要消耗资源。锁的各种操作，包括获得

row level lock 

mysql存储引擎都可以实现自己的锁策略和锁粒度。

表锁 table lock
表锁是mysql中最基本的锁策略，并且是开销最小的策略。表锁非常类似于前文描述
的邮箱加锁机制：它会锁定整张表。一个用户在对表进行写操作 插入 删除 更新等
前，需要先获得写锁，这回阻塞其他用户对该表的所有读写操作。只有没有写锁时，其他
读取的用户才能获得读锁，读锁之间是不相互阻塞的。

在特定的场景中，表锁也可能有良好的性能。例如 read local表锁支持某些类型的
并发写操作。另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到
读锁队列的前面（写锁可以插入到锁队列中读锁的前面，反之读锁则不能出插入到写锁的前面）

尽管存储引擎可以管理自己的锁，mysql本身还是会使用各种有效的锁来实现不同
的目的。例如，服务器会为诸如 alter table之类的语句使用表锁，而忽略存储引擎的
锁机制。

行级锁row lock
行级锁row lock可以最大程度地支持并发处理同事也带来了最大的锁开销。众所周知，在
innodb和xtardb,以及其他一些存储引擎中实现了行级锁。行级锁只在存储引擎层实现
，而mysql服务层没有实现。服务器层
完全不了解存储引擎中的锁实现。在本章的后续内容以及全书中，所以的存储引擎都以自己
的方式显现了锁机制。


1.3 事务
在理解事务的概念之前,接触数据库系统的其他高级特性还言之过早。事务就是一组原子性
的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用
改组查询的全部语句，那么就执行改组查询。如果其中有任何一条语句因为崩溃或其
他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要全部执行成功
，要么全部执行失败。

事务的ACID
原子性 atomicity
一致性 consistency
隔离性 isolation
持久性 durability

一个运行良好的事务处理系统，必须具备这些标准特性。


原子性atomicity
一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部
提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中一部分的
操作，这就是事务的原子性。

一致性 consistency
数据库总是从一个一致性的状态转换到另外一个一致性的状态。在前面的例子中，
一致性确保了，即使在执行第三四条语句之间时系统崩溃，支票账户中也不会损失
，因此事务最终没有提交，所以事务中锁座的修改也不会报错到数据库中。


隔离性 isolation
通常来说，一个事务锁座的修改在最终提交以前，对其他事务是不可见的。在签名
的例子中，当执行完第三条语句，第四条语句还未开始时，此时有另外一个账户汇总
程序开始运行，则其看到的支票账户的余额并没有被减去200元。后面我们讨论
隔离级别 isolation level的时候，会发现为什么我们要说通常来说是不可见的。


持久性 durability
一旦事务提交，则其所作的修改就会永久保存到数据库中。此时即使系统崩溃，修改
的数据也不会丢失。持久性是个有点模糊的概念，因为实际上持久性也分很多
不同的级别。有些持久性策略能够提供非常强的概念，因为实际上持久性也分很多不同
的级别。有些持久性策略能够提供非常强的安全保障，而有些则未必。而且
不可能有能做到100的持久性保证的策略 如果数据库本身就能做到真正的持久性
那么备份有能增加吃就能呢。

事务的 acid特性可以确保银行不会弄丢你的钱。而在应用逻辑中，要实现这一点非常难，
甚至可以说是不可能完成的任务。一个兼容 acid的数据库系统，需要做很多复杂但可能
yoghurt并没有察觉到的工作，才能确保ACID的实现。

就想锁粒度的升级会增加系统开销一样，这种事务处理过程中额外的安全性，也会需要
数据库系统做更多的额外工作。一个实现了acid的数据库，相比没有实现acitd的数据库
通常会需要更强的CPU处理能力更大的内存和更多的磁盘。正如本章不断
重复的，这也正是mysql的存储引擎架构可以发挥优势的地方。用户可以根据业务是否
需要事务处理，来选择合适的存储引擎。对于一些不需要事务的查询类应用，选择
一个非事务性的存储引擎，可以获得更高的性能。及时存储引擎不支持事务，也可以
通过locktables语句为应用提供一定程度的保护，这些选择用户都可以自助决定。

1.3.1 隔离级别
隔离性其实比想象的要复杂。在SQL标准中定义了四种隔离级别，每一种级别都规定了
一个事务中所做的修改，那些在事务内和事务间是课件的，那些是不可见的。较低级别
的隔离通常可以执行更高的并发，系统的开销也更低。

每种存储引擎实现的隔离级别不尽相同。如果熟悉其他的数据库产品，可能会发现
某些特性和你期望的会有些不一样。读者可以根据所选择的存储引擎，查阅相关手册。

下面简单地介绍一下四种隔离级别。

READ UNCOMMITTED 未提交读
在 ReadUnCommitTed 级别，事务中的修改，即使没有提交，对其他事务也都是可见的。
事务可以读取未提交的数据，这也被称为脏读 dirty read.这个级别会导致
很多问题，从性能上来说，read uncommitted不会比其他的级别好太多，但却缺乏
其他级别的好处，除非真的有非常必要的理由，在实际应用中一般很少使用。

READ COMMITTED 提交读
大多数数据库系统的默认隔离级别都是 ReadCommitTed 但mysql不是。read 
committed满足签名提到的隔离性的简单定义：一个事务开始时，只能看见已经
提交的事务所做的修改。换句话说，一个事务从开始直到提交之前，锁座的任何修改
对其他事务都是不可见的。这个界别有时候也叫做不可重复读 nonrepeatable
read ,因为两次执行同样的查询，可能会得到不一样的结果。

REPEATABLE READ 可重复读
RepeaTableRead 解决了脏读的问题。 该级别保证了在同一个事务中多次读取同样
记录的结果是一致的。但是理论上，可重复读隔离级别还是无法解决另外一个幻读
phantom read的问题。所谓幻读，指的是当某个事务在读取某个范围内的记录时，
另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取改范围的记录时
会产生幻行 phantom row  innodb xtra db 存储引擎通过多版本并发控制MVCC 解决幻读的问题。本章稍后会做进一步的跳楼

可重复读是mysql的默认事务隔离级别



SERIALIZABLE 可串行化
serializable 是最高的隔离级别。它通过强制事务串行执行，避免了前面说的幻读
的问题。简单来说，serializable会在读取的每一行数据上都加锁，所以可能导致
大量的超时和锁争用的问题。实际应用中也很少用到这个隔离级别，只有在非常需要
确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。

1.3.2 死锁
死锁是指两个或者多个事务在同一资源上互相占用，并请求锁定对方占用的资源，从而
导致恶性循环的现象。当多个事务试图以不同的顺序锁定资源时，就可能会产生死锁。

多个事务同时锁定同一个资源时，也会产生死锁。例如


为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，
比如innodb存储引擎，越能检测到死锁的循环依赖，并立即返回一个错误。这种解决
方式很有效，否则死锁会导致出现非常慢的查询。还有一种解决方式，就是当查询的
时间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太好。innodb目前处理
死锁的方法是，将持有最小行级排他锁的事务进行回滚（这是相对比较简单的死锁回滚算法）


锁的行为和顺序是和存储引擎相关的。以同样的顺序执行语句，有些存储引擎会产生死锁，
有些则不会。死锁的产生有双重原因：有些是因为真正的数据冲突，这些情况通常很难
避免，但有些则完全是由于存储引擎的实现方式导致的。

死锁发生以后，只有部分或者完全回滚其中一个事务，才能打破死锁。对于事务型的系统
这是无法避免的，所以应用程序在设计时必须考虑如何处理死锁。大多数情况下只
需要重新执行因死锁回滚的事务即可。


1.3.3事务日志
事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要
修改其内存拷贝，再把改修改行为记录到持久在硬盘上的事务日志中，而不用每次都将
修改的数据本身持久到磁盘。事务日志采用的是追加的方式，因此写日志的操作是磁盘
上一小块区域内的顺序IO ，而不像随机IO需要在磁盘的多个地方移动磁头，所以采用
事务日志的方式相对来说要快的多。事务日志持久以后，内存中被修改的数据在后台可以
慢慢地刷回到磁盘。目前大部分存储引擎都是这样实现的，我们通常称之为与些事日志
write ahead logging，修改数据需要些两次磁盘。

如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统
崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具体的恢复方式则视存储引擎
而定。


 show variables like 'AUTOCOMMIT'
13.4 mysql 中的事务
Mysql 提供了两种事务型的存储引擎 innodb ndb cluster 另外还有一些第三方
存储引擎也支持事务，比较知名的包括xtradb pbxt 后面将详细讨论他们各自的一些特点。


自动提交 autocommit
mysql默认采用自动提交 autocommit 模式。也就是说，如果不是显示地开始一个
事务，则每个查询都被当做一个事务执行提交操作。在当前连接中，可以通过设置
autocommit变量来启用或者禁用自动提交模式：

1或者on表示启用，o或者OFF表示禁用。当autocommit=0时，所有的查询都是在一个
事务中，直到显示地执行commit提交或者 rollback回滚，该事物结束，同时又开始了
另一个新事务。修改autocommit对非事务性的表，比如muyisam或者内存表，不会有
任何影响。对这类表来说，没有commit或者rollback的概念，也可以说是相当于一只
处于autocomiit启用的模式。

另外还有一些命令，在执行之前会强制执行commit提交当前的活动事务。典型的例子
在数据定义语言ddl中，如果是会导致大量数据改变的操作，比如alter table
就是如此。另外还有lock tables等其他语句也会导致同样的结果。如果有需要，请检查
对应版本的官方文档来确认所有可能导致自动提交的语句列表。如果有需要，请检查
对应版本的官方文档来确认所有可能导致自动提交的语句列表。

mysql可以通过执行set transactionisolationlevel命令来设置隔离级别。新的
隔离级别会在下一个事务开始 的时候生效。可以在配置文件中设置整个数据库的隔离级别，
也可以只改变当前会话的隔离级别；

set transaction isolation  lever 隔离级别。

Mysql能够识别所有的四个ansi隔离级别，innodb引擎也支持所有的隔离级别。



在事务中混合使用存储引擎

Mysql服务层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中，
使用多种存储引擎是不可靠的。

如果在事务中混合使用了事务型和非事务性的表 innodb 和myisam 在正常
提交的情况下不会有什么问题。

但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致
的状态，这种情况很难修复，事务的最终结果将无法确定。所以为每张表选择合适的
存储引擎非常重要。

在非事务性的表上执行事务相关操作的时候，mysql通常不会发出提醒，也不会报错。
有时候只有回滚的时候才会发出一个警告：某些非事务型的表上的变更不能被回滚。
但大多数情况下，对非事务性的表的操作都不会有提示。

隐式的显示锁定
innodb 采用的是两阶段锁定协议 two phase locking protocol。在事务执行过程中，随时
都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放，并且所有的
锁是在同一时刻被释放。前面描述的锁定都是隐式锁定，innodb会根据隔离级别在需要的时候自动加锁。

另外，innodb也支持通过特定的语句进行显示锁定，这些语句不属于sql规范

select lock in share mode
select for update

mysql也支持 lock table 和unlock tables 这是在服务器层实现的饿，和
存储引擎无关。他们有自己的用户，但并不能替代事务处理。如果应用需要用到事务，还是
应该选择事务型存储引擎。

经常可以发现，应用已经将表从myisam转换到innodb，但还是显示地使用locak table语句。
这不但没有必要，还会严重影响性能，实际上innodb的行级锁工作得更好。

lock tables 和事务之间互相影响的话，情况会变得非常负责，在某些mysql版本
中甚至会产生无法预料的结果。因此本书建议，除了事务中禁用了 autocomit
可以使用locktables之外，其他任何时候都不要显示地执行locktables，不管使用什么存储情况。



1.4 多版本并发控制 MVCC 
 Multi-Version Concurrency Control 多版本并发控制

Mysql的大多数事务型存储引擎实现的都不是简单的行级锁。基于提升并发性能的考虑
，他们一般都同时实现了多版本并发控制mvcc。不仅是mysql 包括oracle
postgresql等其他数据库系统也都实现了mvcc，但各自的实现机制不尽相同，因为mvcc没有
一个统一的实现标准.

可以认为MVCC是行级锁的一个变种，但是他在很多情况下避免了加锁操作,incident开销
更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。

MVCC的实现，是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行
多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对
同一张表，同一时刻看到的数据可能是不一样的。如果之前没有这方面的概念，这句话
听起来就有点迷糊。熟悉了以后会发现，这句话其实还是很容易理解的。


前面说到不同存储引擎的MVCC实现是不同的，典型的有乐观 optimistic 并发控制
和悲观pessimistic 并发控制。下面我们通过innodb的简化版行为来说明MVCC是如何工作的

innodb的mvcc，是通过在每行记录后面报错两个隐藏的列来实现的。这两个列，一个
保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是实际
的时间值，而是系统版本号system version number 没开始一个新的事务，系统版本
号会自动递增。事务开始时刻的系统版本好会作为事务的版本好，用来和查询到的
每行记录的版本好进行比较。下面看一下在Repeatable read隔离级别下，mvcc具体
是如何操作的。

select 
innodb会根据以下两个条件检查每行记录：
a.innodb只查询版本遭遇当前事务版本的数据行也就是，行的系统版本好晓宇或者等于事务的系统版本号，
这样可以确保事务读取的行，要么是在事务开始前已经存在，要么是事务自身插入或者修改过的。

b.行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的
行，在事务开始之前未被删除。

只有符合上述两个条件的记录，才能返回作为查询结果。

insert
innodb 为新插入的每一行保存当前系统版本号作为行版本号。

delete 
innodb为删除的每一行报错当前系统版本号作为行删除标识

update
innodb为插入一行新记录，保存当前系统版本号作为行版本号,同时保存当前系统
版本号到原来的行作为行删除标识

保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作
很简单，性能很好，并且也能够保证只会读取到符合标准的行。不足之处是每行记录都
需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。

MVCC只在repeatable read 和read committed 两个隔离级别下工作。其他两个隔离
级别都和MVCC不兼容，因为 read uncommitted总是读取最新的数据行，而不是符合当前
事务版本的数据行。而serialiable 则会对所有读取的行都加锁。



Innodb为每行记录都实现了三个隐藏字段
6字节的事务ID DB_TRX_ID
7字节的回滚指针 DB_ROLL_PTR
隐藏的id















1.5 Mysql的存储引擎

本节知识概要地描述mysql的存储引擎，而不会设计太多细节。因为关于观察引擎的
讨论以及其相关特定将会贯穿权术，而且本书也不是存储引擎的完全指南，所以有必要阅
读相关存储引擎的官方文档。

在文件系统中，mysql将每个数据库也可以成为 schema 保存为数据目录下的一个
子目录。创建表时，mysql会在数据库子目录下创建一个和表同名的.frm文件保存表的定义。
例如创建一个名为mytable的表，mysql会在mytable。frm文件中报错该表的定义
。因为mysql使用文件系统的目录和文件来保存数据库和表的定义，大小写明和
具体平台密切相关。在windows大小写不敏感，而在类unix中则是
敏感的。不同的存储引擎保存数据和索引的方式是不同的，但表的定义则是mysql服务层
统一处理的。
show table status like 'phone';


可以使用 show table status 在mysql5以后的版本中，也可以查询
information schema显示表的相关信息。例如，对于mysql数据库中的user表

name 表名

engine 表的存储引擎类型。在旧版本中，该列的名字叫type ，而不是engine
 
row_format
行的格式。对于myisam 表，可选的值为dynamic fixed  compressed

dynamic的行长度是可变的，一般包含可变长度的字段，如varchar或blob.fixed
的行长度则是固定的，只包含固定长度的列，如char 和inieger .compressed的行
则只在压缩表中存在，

rows 表中的行数 innodb改制是估计值
表中的行数。对于myisam和其他的一些存储引擎，改制是精确的，但对于innodb改制是估计值。

avg_row_length
平均每行包含的字节数

data length
表数据的大小以字节为单位

max data length
表数据的最大容量，改制和存储引擎有关。


index_length
索引的大小 以字节为单位

data_free
对于myisam表，表示已分配但目前没有使用的空间。这部分空间包括了之前删除的行，
以及后续可以被insertliyongdao的空间。

auto_increment下一个自增的值
下一个auto increment 的值

create_time
创建时间

updatetime
修改

checktime
使用check table命令或者myisamchk工具最后一次检测表的时间


 check table  phone 
 不加引号，检测表是否有错误
 
 ANALYZE TABLE  phone 分析表
 加一个只读锁只能读取表中的记录，不能更新和插入记录
 
 
 OPTIMIZE TABLE   phone  优化表
  只读锁, 可以消除删除和更新造成的磁盘碎片，从而减少空间的浪费
   TEXT或者BLOB这样的数据类型，那么更新、删除等操作就会造成磁盘空间的浪费
   
   
collation表的默认字符集和字符列排序规则
   
 checksum
 如果启用，保存的是整个表的实时校验和。
 
 create_options
 创建表时指定的其他选项。
 
 commet
 该列包含了一些其他的额外信息。对于myisam表，报错的是表在创建时带的注释。
 对于innodb表，则保存的是innodb表空间的剩余空间信息。如果是一个视图，则
 该列包含view的文本字样。
 
 1.5.1 innodb存储引擎
 innodb是mysql的默认事务型引擎，也是最重要、使用最广泛的存储引擎。他被设计
 用来处理大量的短期short lived事务，短期事务大部分情况是正常提交的，很少会
 被回滚。innodb的性能和自动崩溃恢复特性，使得它在非事务性存储的需求中也很流行。
 触发有非常特别的原因需要使用其他的存储引擎，否则应该优先考虑innodb引擎。
 如果要学习存储引擎，innodb也是一个非常好的指的花最多的时间去深入学习的对象，
 收益肯定比将时间平均花在每个存储引擎的学习上要高得多。
 
 Multi-Version Concurrency Control 多版本并发控制
 
 innodb的历史
 innodb有这复杂的发布历史，了解一下这段历史对于理解innodb很有帮助。2008年，
 发布了所谓的innodb plugin，适用于mysql5.1版本，但这是oracle创建的下一代
 innodb引擎，其拥有者是innodb而不是msql。这基于很多原因，这些原因如果要
 一一道来，恐怕得喝掉好几桶啤酒。msql默认还是选择了集成就得innodb引擎。当然
 用户可以自行选择使用心得性能更好拓展性更加的innodbpulgin来覆盖就得版本。
 直到最后，在oracle收购了sun公司后发布的mysql5.5才彻底使用innodb plugin
 替代了旧版本的innodb  是的，这也意味着innodb plugin已经是原生编译了，而不是
 编译成一个插件，但是名字已经约定俗成很难更改。
 
 这个现代的innodb版本，也就是mysql5.1中所谓的innodb plugin，支持一些新特性，
诸如利用排序创建索引 building index by sorting 删除或者增加索引时不需要复制全表
数据、新的支持压缩的存储格式、新的大型列值如blob的存储方式，以及文件格式管理
等。很多用户在mysql5.1中没有使用innodbplugin或许是因为他们没有注意到
有这个区别。所以如果你使用的是mysql5.1 一定要使用innodbplugin真的比旧
版本的innodb要好很好。
 
innodb是一个很重要的存储引擎，很多个人和公司都对其贡献代码，而不仅仅是
oracle公司的开发团队。一些重要的贡献者包括 谷歌，facebook等
他们的一些改进被直接一直到官方版本，也有一些由innodb团队重新实现。
在过去的几年间，innodb的改进速度大大加快，主要的改进集中在可测量性可拓展性。
可配置化、性能、各种新特性和对windows的支持等方面。mysql5.6实验室预览版里
和里程碑版包含一系列重要的innodb新特性。


为改善innodb的性能，oracle投入了大量的资源，并做了很多桌游成效的工作
。我们注意到在超过四核CPU的系统中
innodb表现不佳，而现在已经可以很好拓展至24核的系统，甚至在某些常军，
32核或者更多的系统也表现良好。很多改进将在即将发布的mysql5.6引入。
当然也还有机会做进一步的改善
 
 
innodb概览
innodb的数据存储在表空间tablespace中，表空间由innodb管理的一个黑盒子，
有一系列的数据文件组成。在4.1以后的版本，innodb可以将每个表的数据
和索引存放在单独的文件中。innodb也可以使用裸设备作为表空间的存储介质，但现代的
文件系统是的裸设备不再是必要的选择。

innodb采用MVCC来支持高并发，并且实现了四个标准的隔离级别。起默认级别是
RepeaTable read可重复读，并且通过间隙锁next key locking防止幻读的出现。
间隙锁是的innodb不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止
幻影行的插入。

innodb表是基于聚簇索引建立的，我们会在后面的张洁详细讨论聚簇索引。innodb的
索引结果和mysql的其他存储引擎有很大的不同，聚簇索引对主键查询有很高的性能。
不过他的二级索引 secondary index非主键索引 中必须包含主键列，所以如果主键
列很大的话，其他的所有索引都会很大。因此，若表上的索引较多的话，主键应当尽可能的小。
innodb的存储格式是平台独立的，也就是说可以将数据和索引文件从intel平台
复制到powerpc或者 sunsparc平台

Innodb内部做了很多优化，包括从磁盘读取数据时采用的可预测性的预读，能够自动在
内存中创建hash索引以加速读操作的自适应哈希索引 adaptive hash index 以及能够
加速插入操作的插入缓冲区 insert buffer 等。本书后面将更详细地址讨论这些内容。

innodb的行为是非常复杂的，不容易理解。如果使用了innodb引擎，笔者强烈建议阅读官方
手册中的 innodb事务模型和锁 一节。如果应用程序基于innodb构建，则事先
了解一下innodb的mvcc架构带来的一些为秒和细节之处是非常有必要的。存储引擎
要为所有用户甚至包括修改数据的用户维持一致性的视图，是非常复杂的工作。

作为事务型的存储引擎，innodb通过一些机制和工具支持真正的热备份，oracle提供
的mysql enterprise backup percona  提供的开源的xtrabackup都可以做到这一点
mysql的其他存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入，
而在读写混合场景中，停止写入可能也意味着停止读取。
 
 
 1.5.2 Mysiam存储引擎
在mysql5.1及之前的版本，myisam是默认的存储引擎。myisam提供了大量的特性
，包括全文索引，压缩、空间函数GIS 等，但myisag不支持事务和行级锁，而
且有一个毫无疑问的缺陷就是崩溃后无法安全恢复。正是由于myisam引擎的缘故，即使
mysql支持事务已经很长时间了，在很多人的概念中mysql还是非事务型的数据库。
尽管myisam引擎不支持事务、不支持崩溃后的安全恢复，但它绝不是一无是处
的。对于只读的数据，或者表比较小，可以忍受修复操作，则依然可以继续使用
myisam

存储
myisam会将表存储在两个文件中：数据文件和索引文件，分别以.myd myi为拓展名
。myiasm表可以包含动态或者静态行。mysql会根据表的定义来
觉得采用何种行格式。myisam表可以存储的行记录数，一般受限于可用的磁盘空间，
或者操作系统中单个文件的最大尺寸。

在5.0中，myisam表如果是变长行，则默认配置只能处理256TB的数据，因为
指向数据记录的指针长度是6个字节。而在更早的版本中，指针长度默认是4字节，
所以只能处理4Gb的数据。而所有的mysql版本都支持8字节的指针。要改变
myisam表指针的长度，可以通过修改表的maxorws和avgrowlength
选项的值来实现，两者相乘就是表可能达到的最大大小。修改这两个参数会导致
重建整个表和表的所有索引，这可能需要更长的时间才能完成。


MyISAM特性
作为mysql最早的存储引擎之一，myisam有一些已经开发出来很多年的特性，可以满足用户的实际需求。

加锁与并发
myisam对整张表加锁，而不是针对行。读取时会需要独到的所有表加共享锁，
写入时则对表加排他锁。但是在表有读取查询的同事，也可以往表中插入新的记录
这被称为并发插入，concurrent insert

修复
  对于myisam表，mysql可以手工或者自动执行检测和修复操作，但这里说的修复和
  事务修复以及崩溃恢复是不同的概念。执行表的修复可能导致一些数据丢失，
  而且修复操作是非常慢的。可以通过 check table mytable 检查表的错误，如果有
  错误可以通过执行repair table mytable进行修复。另外，如果mysql服务器已经
  关闭，也可以通过 myisamchk命令行工具进行检查和修复操作。
  
修复
  对于myisam表，mysql可以手工或者自动执行检查和修复操作，但这里说的修复
  和事务恢复以及崩溃修复是不同的概念。执行表的修复可能导致一些数据丢失，
  而且修复操作是非常慢的。可以通过 check table mytable检查表的错误，如果有
  错误可以通过执行 repair table mytable 进行修复。另外，如果mysql服务器已经
  关闭，也可以通过 命令行工具进行检查和修复操作。
  
索引特性
   对于myisam表，即使是blob 和text等长字段，也可以基于其前500个字符创建
索引。myisam也支持全文索引，这是一种基于分词创建的索引，可以支持复杂的
查询。关于索引的更多信息请参考第五章。

延迟更新索引建 delayed key write
创建myisam表的时候，如果指定了 delay可以write选项，在每次修改执行完成时
，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的减缓冲区 n memory key buffer
只有在清理建缓冲区或者关闭表的时候才会将对应的索引块写入到磁盘。
这种方式可以及大地提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，m需要
执行修复操作。延迟更新索引建的特性，可以在全局设置，也可以为单个表设置。

myisam 压缩表
如果表在创建并导入数据以后，不会在进行修改操作，那么这样的表或许适合采用
myaism压缩表

可以使用myisampack 对myisam表进行压缩也叫做大博鳌 pack.压缩表是不能进行修改的
。压缩表可以及大地煎炒磁盘占用空间。
因此也可以减少磁盘IO 从而提升查询性能。压缩表也支持索引，但索引也是只读的。


以现在的硬件能力，对大多数应用常军，读取压缩包数据时假牙带来的开销影响并不大，
而减少IO带来的好处则是要大的多。压缩表时记录是独立压缩的，所以读取单行的时候
不需要去解压整个表

Myisam性能
myaism引擎设计简单，数据以紧密格式存储，所以在某些常军下的性能很好，
myisam有一些服务器级别的性能拓展显示，比如对索引建缓冲区 keycache的
mutex锁，mariadb基于段segment 的索引建缓冲区机制来避免该问题。但myisam
最典型的性能高问题还是表锁的问题，如果你发现所有的查询都长期处于locked状态
那么毫无疑问表锁就是罪魁祸首。




2.2 
测试指标

吞吐量:单位时间内的事务处理数

响应时间或延迟:任务所需整体时间
 
并发性

 
 
 
 
 
3.3 剖析mysq查询
 
慢查询可以设置 long_query_time为0来捕获所有的查询，
影响性能很小。

慢查询剖析报告工具 pt_query-digest 追踪工作负载到数据库

 
3.3.2 剖析单条查询
1.show profiles;
set profiling=1;
show profile;
show profiles;
show profile for query 1;
 

2.show status;show global status;


3.慢SQL:设置 long_query_time为0来捕获所有的查询

4.performance schema


5.explain|desc 



 



第四章 schema 与数据类型有优化




4.1 优化数据类型原则

1.更小的通常更好
2.简单就好
3.避免null

datetime和timesamp   timesamp存储更小，会根据时区变化。timesamp范围小。

mysql支持别名 integer bool numeric都只是别名。

show create table 


4.1.1整数类型
两种类型的数字:
整数 whole number和 实数 real number

unsigned 无符号;使正数上限提高一倍。
tinyint、smallint、mediumint、int、bigint
-2(n-1)到2(n-1)-1

存储和计算来说int(1)和int(20)相同


4.1.2 实数类型
带小数

float double
decimal(小数的) 存储精确的小数。

CPU不支持decimal直接计算，支持原生浮点计算，所以浮点计算更快。



4.1.3 字符串类型

varchar 和char

varchar用于存储可变长字符串
innodb 把过长的varchar存储为blob

varchar(5)varchar(20)存储hello空间开销一样。更长的列会消耗更多的内存。mysql
会分配固定大小的内存来保存内部值。

char
定长的  存md5最合适

Blob(二进制存储)和text(字符存储)存储很大的数据。 

blob(二进制,无字符集和排序):tinyblob、smallblob、blob、mediumblob、longBlob
text(字符存储，有字符集和排序):tinytext、smalltext、text、mediumtext、longtext

mysql会把blob和text当作一个独立对象处理。


使用枚举类型enum代替字符串类型。



4.1.4 日期和时间类型
datetime和timestamp


datetime 1001年到9999年精度秒
封装格式YYYYMMDDHHMMSS的整数，与时区无关8字节


timestamp 1970年1月1日开始的秒数。和unix时间戳相同，四个字节和时区有关
只能从1970-2038年。时区依赖服务器操作系统和客户端连接时区。


4.1.5
bit位存01不建议用
set



4.2 Mysql schema设计陷阱

1.太多的列


2.太多的关联

3.全能的枚举

4.变相的枚举:枚举enm运行在列中存储一组定义值的单个值。集合set允许在列中存储一组定义






4.3 范式和反范式




第五章 创建高性能的索引



5.1索引基础


5.1.1 索引的类型


B-Tree索引
当人们谈论索引的时候，如果没有特别指明类型，那多半说的是B-tree索引，它使用
B-Tree数据结果来存储数据。大多数mysql引擎都支持这些索引。

实际上很多存储索引使用的是B+tree，即每一个叶子节点都包含指向下一个叶子节点的指针，从而
方便叶子节点的范围遍历。

不过，底层的存储引擎也可能使用不同的存储结构，例如，NDB集群存储引擎内部实际
上使用了T-tree结果存储这种索引，及时其名字是btrr;innodb则使用的b+tree
各种数据结构和算法的变种不在本书的讨论范围之内。

存储引擎以不同的方式使用B-tree索引，性能也个有不同，个有优劣。

可以使用b-tree索引的查询类型
1.全键值
2.键值范围
3.前缀查找



哈希索引 hash index
只有精确匹配索引所有的列的查询才有效。


5.2 如何评价一个索引是否适合某个查询  三星系统

三星系统(three-star system)：
索引将相关的记录放到一起则获得一星。
索引中的数据顺序和查找中的排列顺序一致则获得二星。
索引中的列包含了查询中需要的全部列则获得三星。






5.3 高性能的索引策略

5.3.1 独立的列

独立的列指的是索引列不能是表达式的一部分，也不能是函数的参数

where aa+1=5;
where   TO_DAYS(create_time)-TO_DAYS(update_time)<=10;

5.3.2 前缀索引和索引选择性

反转字符串进行后缀索引



5.3.3 多列索引

常见的错误就是，为每个列创建独立索引，或者按照错误的顺序创建多列索引。

在多个列上建立独立的单列索引大部分情况下并不能提高mysql的查询性能，mysql
5.0和更新版本上引入一种叫做索引合并 index merge 的策略，一定程度上可以使用
表上的多个单列索引来定位指定的行。更早版本的mysql只能使用其中某一个单列索引，
然而这种情况下没有那一个独立的单列索引是非常有效的。例如，表filmactor在
字段

索引合并策略有时候是一种优化的结果，但实际上更多时候说明了表上的索引建的很糟糕：

5.3.4 选择合适的索引列顺序

我们遇到的最容易引起困惑的问题就是索引列的顺序。正确的顺序依赖于使用该索引的
查询，并且同时需要考虑如何更好地满足排序和分组的需要。

在一个多列B tree索引中,索引列的顺序意味着索引首先按照最左列进行排序，其次是
第二列，等等。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的
order by group by  distinct等子句的查询需求。


所以多列索引的列顺序至关重要。在lahdenmaki和leach的三星索引系统中，列
顺序也决定了一个索引是否能够成为一个真正的三星索引，

将选择性最高的列放到索引最前列。



5.3.5 聚簇索引
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体的细节依赖于其
实现方式，但innodb的聚簇索引实际上在同一个结构中报错了Btree和数据行.

当表有聚簇索引时，他的数据行实际上存放在索引的叶子也 leaf page 中。属于 聚簇
表示数据和和相邻的键值紧凑地存储在一起。因为无法同时把数据行存放在两个不同
的地方，所以一个表只能有一个聚簇索引。（不过，覆盖索引可以模拟多个聚簇索引的情况）

因为是存储引擎负责实现索引，一次不是所有的存储引擎都支持聚簇索引。本节我们主要
关注innodb，但是这里讨论的原理对任何支持聚簇索引的存储引擎都是使用的。


图5-3展示了聚簇索引中的记录是如何存放的。注意到，叶子页包含了行的全部数据，
但是节点页只包含了索引列。

一些数据库服务器运行选择那个索引作为聚簇索引，但直到本书写作之际，还没有任何
一个mysql内建的存储引擎支持这一点。innodb将通过主键聚集数据，也就是说图
5-3中的被索引的列就是主键列。


如果没有定义主键,innodb会选择一个唯一的非空索引替代。如果没有这样的索引，
innodb会隐式定义一个主键来座位聚簇索引。innodb只具体在同一个页面中的记录。
包含相邻键值的页面可能会相聚深远。

聚簇主键可能对性能有帮助，但也可能导致严重的性能问题。所有需要仔细地考虑聚簇
索引，尤其是将表的存储引擎从innodb改成其他引擎的时候，反过来也一样。
具体的数据有一些重要的有有点：


1.可以吧相关的数据保存在以前。例如实现电子邮箱时，可以根据用户id来具体数据，
这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用
聚簇素银，则每逢邮件都可能导致一次磁盘IO



2.数据访问更快。聚簇索引将索引和数据保存在同一个B-tree中，因此从聚簇索引中
获取数据通常比在非聚簇索引中查询要快。

3.使用覆盖索引扫描的查询可以直接使用页节点中的主键值。


如果在设计表和查询时能充分利用上面的有点，那就能极大地提升性能。同时聚簇索引
也有一些缺点


1.聚簇数据最大限度地提高了IO密集型应用的性能，但如果数据全部都放在内存中，
则访问的顺序就没那么重要了，聚簇索引也就没有什么优势了。

2.插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到innodb表中速度
最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用
optimize table 命令重新组织一下表。

3.更新聚簇索引列的代价很高，因为会强制innodb将每个被更新的行移动到新的位置

4.基于聚簇索引的表在插入新航，或者主键被更新导致需要移动行的时候，可能面临
页分裂 page split的问题。当行的主键值要求必须将这一行插入到某个已满的
页中时，存储引擎会将该页分裂成两个页面来容乃改行，这就是一次页分裂操作。
也分裂会导致表占用更多的磁盘空间。

5.聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。

6.二级索引(非聚簇索引)可能比想象的更大，因为在二级索引的叶子节点包含了引用行的主键列。

7.二级索引访问需要两次索引查找，而不是一次。

8.二级索引访问需要两次索引查找，而不是一次。



聚簇索引(主键>第一个唯一>自己建立一列隐藏) 

二级索引（辅助索引）:唯一索引、普通索引、前缀索引、全文索引



索引实现:
B-tree
hash


最后一点可能让人有些疑惑，为什么二级索引需要两次索引查找？答案在于二级索引中
保存的行指针的实质。要记住，二级索引叶子结点保存的不是指向行的物理位置的指针，
而是行的主键值。

这意味这通过二级索引查找行，存储引擎需要找到二级索引的叶子节点获得对应的主键值，
然后根据这个值去聚簇索引中查找到对应的行。这里做了重复的工作：两次B-tree
查找而不是一次。对于innodb，资质是哈一索引能够减少这样的重复工作。


MyISAM数据文件，按照数据插入顺序存储在磁盘上

MyISAM索引文件是B-tree每个tree叶子节点保存数据的位置


InnoDB支持聚簇索引
数据和主键列一起存在B-tree上。
每个叶子节点包含(主键列、事务ID、回滚指针、非主键列S)

InnoDB二级索引(辅助索引):叶子节点中存储的不是行指针而是主键值。




在innodb表中按主键顺序插入行
如果正在使用innodb表并没有什么数据需要聚集，那么可以定义一个代理键surrogate key 作为主键。
这种主键的数据应该和应用无关，最简单的方法是使用autoincrement自增列。这样可以保证
数据行是按顺序写入，对于根据主键做关联操作的性能也会更好。

最好避免随机的聚簇索引，特别是对于IO密集型的应用
性能角度用UUID作为聚簇索引会很糟糕：它使得聚簇索引的插入变得完全随机，这是最坏的情况，
使得数据没有任何聚集特性。

UUID作为主键时插入
无法简单地总是把新航插入到索引的最后，而是需要为新的行寻找合适的位置。通常是已有数据的中间位置
并且分配空间。会增加很多额外的工作，并导致数据分布不够优化。

缺点：
1.写入的目标也可能已经刷到磁盘上并从缓存中移除，或者是还没有被加载到缓存中，
innodb在插入之前不得不先找到并从磁盘读取目标也到内存中。这将导致大量的随机IO

2.因为写入是乱序的，innodb不得不频繁地做页分裂操作，以便为细腻的行分配空间。
也分裂会导致移动大量数据，一次插入最少需要修改三个页而不是一个页。

3.由于频繁的页分裂，页会变得稀疏并被不规则地填充，所以最终数据会碎片。








顺序的主键什么时候会造成最坏的结果

对于高并发工作负载，在innodb中按主键顺序插入可能会造成明显的争用。主键
的上界会成为热点。因为所以的插入都发生在这里，所以并发插入可能导致间隙锁
竞争。另一个热点可能是auto_increment锁机制；如果遇到这个问题，则可能
需要考虑重新设计表或者应用，或者更改innodb_autoinc_lock_mode配置。如果
你的服务器版本还不支持 innodb_autoinc_lock_mode 参数，可以升级到最新版本
的innodb，可能对这种场景会工作得更好。



auto_increment  自增列不要改主键的值 
有1、2、3，把1改成4；再插入时就出问题

默认是1:

insert 语句分三种类型：
1.simple insert : insert into t1(id, name) values(1,"shenjian");
2.bulk insert 批量  : insert ... select
3.mixed insert 混合(有的指定ID有的自动生成) :insert into t1(id, name) values (111,"111"),(NULL, "abc"); 



 show variables like 'innodb_autoinc_lock_mode'
 
 innodb_autoinc_lock_mode有三个值：
 
     0, traditional  insert语句在开始时都会获得一个表锁autoinc_lock.该锁会一直持有到insert语句执行结束才会被释放。保证了同一条语句插入的行记录的自增ID是连续的。
     1, consecutive 默认 insert语句在开始时会获得一个表锁autoinc_lock, simple insert在获取到需要增加的ID的量后，autoinc_lock就会被释放,不必等到语句执行结束。
     2, interleaved 主从复制的同一张表下的同一行id有可能不一样。


5.3.6 覆盖索引
通常大家都会根据查询的where条件来创建合适的索引，不过这只是索引优化的一个方面。
设计优秀的索引应该考虑到整个查询，二部丹丹是where条件部分。索引确实是一种
查找数据的高效方法，但是mysql也可以使用索引来直接获取列的数据，这样就不需要
读取数据行。如果索引的叶子节点中已经包含要查询的数据，那么还有什么必要
再回表查询呢？如果一个索引包含所有需要查询的字段的值，我们就称之为覆盖索引。

覆盖索引是非常有用的工具，能够极大地提高性能。考虑一下如果查询只需要扫描索引
而无需回表，会带来很多好处：


1.索引条目通常远小于数据行大小，所以如果只需要读取索引，那mysql就会极大地
减少数据访问量。这对缓存的负载非常重要，因为这种情况下响应时间大部分花费
在数据拷贝上。覆盖索引对于iO密集型的应用也有帮助，因为索引比数据更小，
更容易全部放入内存中

2.因为索引是按照列值顺序存储的，所以对于IO密集型的
范围查询会比随机从磁盘读取每一行数据的IO要少的多。对于某些存储引擎，例如
myisam和percona xtradb，甚至可以通过optimize命令是的索引完全顺序排列
，这让简单的范围查询能使用完全顺序的索引访问。

3.一些存储引擎如myisam在内存中只缓存索引，数据则依赖于操作系统来缓存，因此
要访问数据需要一次系统调用。这可能会导致严重的性能呢问题，尤其是那些系统
调用占用了数据访问中的最大开销的场景。

4.由于innodb的聚簇索引，覆盖索引对innodb表特别有用。innodb的耳机索引在
叶子节点中报错了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键
索引的二次查询。

 

5.3.7 使用索引扫描来做排序
mysql有两种方式可以生成有序的结果：通过排序操作；或者按索引顺序扫描；如果
explain出来的type列的值为index，则说明没有失去了使用了索引扫描来做排序
不要和extra列的usingindex搞混淆了

扫描索引本身是很快的，因为只需要从一条索引记录移动到紧接着的下一条记录。
但如果索引不能覆盖查询所需的全部列，那就不得不每扫描一条索引记录就都回表查询一次
对应的行。这基本上都是随机IO，因此按索引顺序读取数据的速度通常要比顺序地全表
扫描慢，尤其在IO密集型的工作负载时。

Mysql可以使用同一个索引既满足排序，又用于查询行。因此，如果可能，设计索引
时应该尽可能地同时满足这两种任务，这样是最好的。

只有当索引的列顺序和order by 子句的顺序完全一致，并且所有的列排序方向倒叙正序
都一样时，mysql才能够使用索引来对结果做排序。如果查询需要关联多张表，
则只有当orderby子句引用的字段全部为第一个表时，才能使用索引做排序。
orderby 子句和查询的限制是一样的：需要满足索引的最左前缀的要求；否则，
mysql都需要执行排序操作，而无法利用索引排序。

有一种情况orderby 子句可以不满足索引的最左前缀的要求，就是前导列为常量的时候
。如果where子句或者join子句中对这些列指定了常量，就可以弥补索引的不足。


Mysql有两种方式可以生成有序的结果：通过排序操作；或者按索引顺序扫描；如果
explain出来的type列的值为index，则说明mysql使用了索引扫描来做排序（不要
和extra列的using index 搞混淆了）。

扫描索引本身是很快的，因为只需要从一条索引记录一定到紧接着的下一条记录。但如果
索引不能覆盖查询所需的全部列，那就不得不没扫描一条索引记录就都回表查询一次
对应的行。这基本上都是随机IO，因此按索引顺序读取数据的速度通常要比顺序地全表
扫描慢，尤其是在IO密集型的工作负载时。

Mysql可以使用同一个索引既满足排序，又用于查找行。因此，如果可能，设计索引时
应该尽可能地同时满足这两个任务，这样就是最好的。

只有当索引的列顺序和order by 子句的顺序完全一致，并且所有列的排序方向（倒叙或者正序）
都一样时，mysql才能够使用索引来对接过做排序。如果查询需要关联多张
表，则只有当orderby子句引用的字段全部为第一个表时，才能使用索引做排序。
orderby子句和查询型查询的限制是一样的：需要满足索引的最左前缀的要求；否则
mysql都需要执行排序操作，而无法利用索引排序。

有一种情况下orderby 子句可以不满足索引的最左前的要求，就是前导列为常量的时候。
如果where子句或者join子句中对这些列指定了常量，就可以弥补索引的不足。

即使orderby子句不满足索引的最左前缀的要求，也可以用于查询排序，这是因为所以你的
第一列被指定为一个常数。

https://www.cnblogs.com/aeolian/p/10212892.html

filesort的过程：

         1、根据表的索引或者全表扫描，读取所有满足条件的记录。

         2、对与每一行，存储一对值到缓冲区（排序列，行记录指针），一个是排序的索引列的值，即order by用到的列值，和指向该行数据的行指针，缓冲区的大小为sort_buffer_size大小。

         3、当缓冲区满后，运行一个快速排序（qsort）来将缓冲区中数据排序，并将排序完的数据存储到一个临时文件，并保存一个存储块的指针，当然如果缓冲区不满，则不会重建临时文件了。

         4、重复以上步骤，直到将所有行读完，并建立相应的有序的临时文件。

         5、对块级进行排序，这个类似与归并排序算法，只通过两个临时文件的指针来不断交换数据，最终达到两个文件，都是有序的。

         6、重复5直到所有的数据都排序完毕。

         7、采取顺序读的方式，将每行数据读入内存，并取出数据传到客户端，这里读取数据时并不是一行一行读，读如缓存大小由read_rnd_buffer_size来指定。

这就是filesort的过程，采取的方法为：快速排序 + 归并排序，但有一个问题，就是，一行数据会被读两次，第一次是where条件过滤时，第二个是排完序后还得用行指针去读一次，一个优化的方法是，直接读入数据，排序的时候也根据 这个排序，排序完成后，就直接发送到客户端了，过程如下：

           1、读取满足条件的记录

           2、对于每一行，记录排序的key和数据行指针，并且把要查询的列也读出来

           3、根据索引key排序

           4、读取排序完成的文件，并直接根据数据位置读取数据返回客户端，而不是去访问表

这也有一个问题：当获取的列很多的时候，排序起来就很占空间，因此，max_length_for_sort_data变量就决定了是否能使用这个排序算法






mysql两种排序方式：
1.文件排序
2.扫描索引排序

explain type :index|ALL

使用文件，不使用索引:
1.使用两种不同的排序方向，但是索引列都是正序 by c_1 desc ,c_2 asc;

2.引用了不在索引的列

3.无法组合成索引的最左前缀

4.查询索引列是范围条件

5.多个等于条件(范围查询)



5.3.8 压缩前缀索引

myisam使用前缀压缩来减少索引的大小，从而让更多的索引可以放入内存中，这在某些
情况下能极大地提高性能。默认只压缩字符串，但通过参数设置也可以对整数做压缩。
Myisam压缩每个索引快的方法是，先完全保存索引块中的第一个值，然后将其他值和
第一个值进行比较得到相同前缀的字节数和剩余的不同后缀部分，把这部分存储起来即可
。例如，索引块中的第一个值是perform第二个值是performance那么第二个值
的前缀压缩后存储的是类似7,ance这样的形式。myisam对行指针也采用类似的
前缀压缩方式。

压缩块使用更少的空间，代价是某些操作可能更慢。因为每个值的压缩前缀都依赖前面
的值，所以Myiasm查找时无法在索引块使用二分查找而只能从头开始扫描。正序的扫描
速度还不错，但是如果是倒叙扫描-例如orderby desc就不是很好了。所有
在块中查找某一行的操作平均都需要扫描半个索引块。

测试表明，对于CPU密集型的应用，因为扫描需要随机查找，压缩索引使得Mysiam在
索引查找上要慢好几倍。压缩索引的倒叙扫描就更慢了。压缩索引需要在CPU内存资源与
磁盘之前做权衡。压缩索引可能只需要十分之一大小的磁盘空间，如果是IO密集型应用
对某些查询带来的好处会比成本多很多。

可以在create table语句中制定packkeys参数来控制索引压缩的方式。

5.3.9 冗余和重复索引

mysql允许在相同列上创建多个索引，无论是有意的还是无意的。mysql需要单独维护
重复的索引，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能。

重复索引是指在相同的列上按照相同的顺序创建的相同的类型的索引。应该避免这样创建
重复索引，发现以后也应该立即移除。

一个经验不足的用户可能是想创建一个主键，先加上唯一限制，然后再加上索引以供查询使用。
事实上，mysql的唯一限制和主键限制都是通过索引实现的，因此，上面的写法实际上在相同
的列上创建了三个重复的索引。通常并没有理由这样做，除非是在同一列
上创建不同类型的索引来满足不同的查询需求。

冗余索引和重复索引有一些不同。如果创建了索引AB，再创建索引A就是冗余索引，
因为这只是前一个索引的前缀索引。因此索引AB也可以当做索引A来使用这种冗余
只是对Btree索引来说的。但是如果再创建索引BA，则不是容易索引，索引B也不是
，因此B不是索引AB的最左前缀列。另外，其他不同类型的索引，例如哈希索引
或者全文索引也不会是b-ree索引的冗余索引，而无论覆盖的索引列是什么。

冗余索引通常发生在为表添加索引的时候。例如，有人可能会增加一个新的索引AB
而不是拓展已有的索引A。还有一种情况是将一个索引拓展为A，id其中是主键，
对于INNODB来说主键列已经包含在二级索引中了，所以这也是冗余的。

大多数情况下都不需要冗余索引，应该尽量拓展已有的索引而不是创建新索引。但也有时候
处于性能方面的考虑需要冗余索引，因为拓展已经的索引会导致其变得太呆，从而影响其他
使用该索引的查询的性能。

例如，如果在整数列上有一个索引，现在需要额外增加一个很长的varchar列来过站改索引，
那性能可能会急剧下降。特别是有查询把这个索引当作覆盖索引，或者这是
myiasm表并没有很多范围查询的时候。

information schema

5.3.10 未使用的索引
除了冗余索引和重复索引，可能还会有一些服务器永远不用的索引。这样的索引完全是累赘，
建议考虑删除。有两个工具可以帮助定位未使用的索引。最简单有效的版本是
在percona server或者mariadb中先打开userstaes服务器变量 默认是关闭的，然后
让服务器正常运行一段时间，再通过查询infromation schema index statistics就能
查到每个索引的使用频率。

另外，还可以使用percona toolkit 中的pt index usage 该工具可以读取查询日志，并对
日志中的每条查询进程explain操作，然后打印出关于索引和查询的报告。这个工具
不近可以找出那些索引是未使用的，还可以了解查询的执行计划  例如在某些情况
有些类似的查询的执行方式不一样，这可以帮助你定位到那些偶尔服务质量差的查询，
优化他们已得到一直的性能表现。该工具也可以将结果写入到mysql的表中，方便查询结果。

5.3.11索引和锁
索引可以让查询锁定更少的行。如果你的查询从不访问那些不需要的行，那么就会锁定
更少的行，从两个方面来看这对性能都有好处。首先，虽然innodb的行锁效率很高，
内存使用也很少，但是锁定行的时候仍然会带来额外的开销；其次，锁定超过需要的行会
增加锁争用并较少并发性。

innodb只有在访问行的时候才会对其加锁，而索引能够减少innodb访问的行数，从而
减少锁的数量。但这只有当innodb在存储引擎层能够过滤掉所有不需要的行时才有效。
如果索引无法过滤掉无效的行，那么在innodb检索到数据并返回服务层以后，
mysql服务器才能应用where子句。这时已无法避免锁定行了：innodb已经锁住了
这些行，到适当的时候才释放。在




索引的类型

B-Tree索引
有效条件：
1.全值匹配
2.匹配最左前缀
3.匹配列前缀
4.匹配范围值
5.精确匹配某一列并范围匹配另一列
6.只访问索引的查询

哈希索引hash index
1.不是顺序存储，不能排序
2.只支持等值比较=、!=
3.冲突值高，维护很麻烦


全文索引

空间数据索引R-Tree
GIS






高性能策略:

1.独立的列，不能是表达式的一部分
2.前缀索引和索引选择性(字段一部分变索引) add key(city(7))(无法使用前缀索引做orderby和groupby)
3.多列索引
4.选择合适的索引列顺序
5.聚簇索引(有索引有数据默认主键；唯一非空索引)：二级索引存储聚簇索引ID
innodb插入时 
 show variables like 'innodb_autoinc_lock_mode' 
 innodb_autoinc_lock_mode有三个值：
 
     0, traditional  insert语句在开始时都会获得一个表锁autoinc_lock.该锁会一直持有到insert语句执行结束才会被释放。保证了同一条语句插入的行记录的自增ID是连续的。
     1, consecutive 默认 insert语句在开始时会获得一个表锁autoinc_lock, simple insert在获取到需要增加的ID的量后，autoinc_lock就会被释放,不必等到语句执行结束。
     2, interleaved 主从复制的同一张表下的同一行id有可能不一样。


6.覆盖索引:where条件包含返回的值，不需要查询聚簇索引

7.索引扫描排序




mysql两种排序方式：
1.文件排序
2.扫描索引排序

explain type :index|ALL

使用文件，不使用索引:
1.使用两种不同的排序方向，但是索引列都是正序 by c_1 desc ,c_2 asc;

2.引用了不在索引的列

3.无法组合成索引的最左前缀

4.查询索引列是范围条件

5.多个等于条件(范围查询)


8.压缩索引perform、performance>7,ance

9.冗余和重复索引（唯一和主键默认建立索引，不用再建立）

10.查询未使用的索引(Percona Toolkit:pt-index-usage)







6.2 慢查询
1.是否向数据库请求了不需要的数据
2.是否在扫描额外的记录(响应时间、扫描行数、返回行数)


6.3 重构查询

1.一个复杂查询还是多个简单查询
2.切分查询:移除不必要的数据
3.分解关联查询



6.4 查询执行的基础

客户端
通信
查询缓存
(解析器和预处理器)语法解析权限校验
查询优化器(重新定义关联表的顺序、外连接转化成内连接、使用等价变换1=1、优化countminmax、转化为常数表达式
、覆盖索引扫描、子查询优化、提前终止查询、等值传播、列表in比较)
查询执行计划
查询执行引擎
存储引擎


数据和索引的统计信息





第5章 创建高性能的索引

索引在mysql中也叫做键key是存储引擎用于快速找到记录的一种数据结构。
这是索引的基本功能，除此之外，本章还将讨论索引其他一些方面有用的属性。

索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响
愈发重要，在数据量较小且负责较低时，不恰当的索引对性能的影响可能还不明显，但
当数据量逐渐增大时，性能则会急剧下降。

不过，索引却经常被忽略，有时候甚至被误解，所以在实际案例中经常会遇到由糟糕索引
导致的问题。这也是我们把索引优化放在了靠前的章节，甚至比查询优化还靠前的原因。

索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高几个数量级，
最优的索引有时比一个好的，索引性能要好两个数量级。创建一个真正最优
的索引经常需要重写查询，所以，本章和下一张的关系非常密切。


5.1索引基础
要理解mysql中索引是如何工作的，最简单的方法就是去看看一本书的索引部分：
如果想在一本书中找到某个特定主题，一般会先看书的索引，找到对应的页码。

在mysql中，存储引擎类似的方法使用索引，其先在索引找找到对应值，然后根据
匹配的索引记录找到对应的数据行。假如要运行下面的查询：

select firest_name from sakila.actor where actor_id=5;

如果在actor_id列上建有索引，则mysql将使用该索引找到actor_id为5的行，也就是说，
mysql先在索引上按值进行查询，然后返回所有包含改制的数据行。

索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因为
mysql只能高效地使用索引的最左前缀列。创建一个包含两个列的索引，和创建两个
只包含一列的索引是大不相同的，下面将详细介绍。

如果使用的是ORM，是否还需要关心索引？
简而言之：是的，仍然需要理解索引，即使是使用对象关系映射ORM工具。

ORM工具能够生产符合逻辑的、合法的查询 多数时，除非只是生成非常基本
的查询 例如仅是根据主键查询，否则它很难生成适合索引的查询。无论是多么
复杂的orm工具，在精妙和负责的索引面前都是浮云。读完本章后面的内容
以后，你就会同意这个观点！很多时候，即使是查询优化技术专家也很难兼顾到各种情况，更别说
ORM了。

5.1.1 索引的类型
索引有很多种类型，可以为不同的常军提供更好的性能。在mysql中，索引是在存储
引擎层而不是服务器层实现的。所以，并没有统一的索引标准；不同存储引擎的索引的
工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引。即使多个存储引擎
支持同一种类型的索引，其底层的实现也可能不同。

下面我们先来看看mysql支持的索引类型，以及他们的优点和缺点。

B-Tree索引
当人们谈论索引的时候，如果没有特别指明的累心个，那多半说的就是Btree索引，它使用B
-TREE数据结构来存储数据。大多数mysql引擎都支持这种索引。archive引擎是
一个例外:5.1之前archive不支持任何索引，直到5.1才开始支持单个自增列 auto
increment的索引。

我们使用术语b-tree是因为mysql在create table 和其他语句中也使用该关键字。
不过，底层的存储引擎也可能使用不同的存储结构，例如，NDB集群存储引擎内部实际
上使用了T-tree结构存储这种索引，即使其名字是Btree；innodb则使用的是B+tree
各种数据结构和算法的变种不在本书的讨论范围之内。

存储引擎以不同的方式使用B-tree索引，性能也各有不同，个有优劣。例如,myisam
使用前缀压缩技术使得索引更小，但innodb则按照原数据格式进行存储。再如
myisam索引通过数据的屋里位置引用被索引的行，而innodb则根据主键引用被索引的行。


B-tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。图
5-1展示了B-tree索引的抽象标识，大致反应了innodb索引是如何工作的。myisam
使用的结构有所不同，但基本思想是类似的。

B-tree索引能够加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要
的数据，取而代之的是从索引的根节点开始进行搜索。根节点的槽中
存放了指向子节点的指针，存储引擎根据这些指针向下层查找。通过比较节点页的值和
要查找的值可以找到合适的指针进入下层子节点，这些指针实际上定义了子节点页中值
的上限和下限。最终存储引擎要么是找到对应的值，要么该记录不存在。

叶子节点比较特别，它们的指针指向的是被索引的数据，而不是其他的节点页(不同引
擎的指针类型不同)。图5-1中仅绘制了一个节点和其对应的叶子节点，其实在根节点
和叶子节点之间可能有很多层节点页。树的深度和表的大小直接相关。

B-tree对索引列是顺序组织存储的，所以很适合范围数据。例如，在一个基于文本域
的索引树上，按字母顺序传递连续的值进行查找是非常合适的，所以像找出所有以I到K开头的名字
这样的查找效率会非常高。


对于表中的每一行数据，索引中包含了lastname firstname和dob列的值，图5-2 显示了该
索引是如何组织数据的存储的。

请注意，索引对多个值进行排序的依据是creteatable语句中定义索引时列的顺序。看一下
最后两个条目，两个人的姓和名都一样，则根据他们的出生日期来排列顺序。

可以使用btree索引的查询类型。B tree索引适用于全键值 键值范围或键前缀查找。
其中键前缀查找只适用于根据最左前缀的查找。前面所述的索引对如下类型的查询有效。

全值匹配
   全职匹配指的是和索引中的所以列进行匹配，例如前面提到的索引可用于查找姓名
   为cuba allen 出生于1960de ren 
   
匹配最左前缀 

  前面提到的索引可用于查找所有姓为allen的人，即只使用索引的第一列。

匹配列前缀
    也可以只匹配某一列的值的开头部分。例如前面提到的索引可用于查找所有以J开头的
    姓的人。这里也只使用了索引的第一列。
    
匹配范围值
       例如前面提到的索引可用于查找姓在allen和barrymore之间的人。这里也只使用
       了索引的第一列。
       
精确匹配某一列并范围匹配另外一列。
     前面提到的索引也可用于查找所有姓为allen，并且名字是字母k开头kim karl的人。
     及第一列lastname全匹配，第二类firestname范围匹配。
     
     
只访问索引的查询
    btree通常可以支持 只访问索引的查询，即查询只需要访问索引，而无需访问数据行。
    后面我们将单独讨论这种覆盖索引的优化。
    
因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的
order by 操作 按顺序查找。一般来说 如果btree可以按照某种方式查找到值，那么
也可以按照这种方式用于排序。所以，如果orderby子句满足前面列出的集中查询类
型，则这个索引也可以满足对应的排序需求。

下面是一些关于BTREE索引的限制

如果不是按照索引的最左列开始查询，则无法使用索引。例如上面例子中的索引无
法用于查找名字为bill的人，也无法查找某个特定生日的人，因为这两列都不是最左
数据列。类似地，也无法查找姓氏以某个字母结尾的人。
    
不能跳过索引中的列。也就是说，前面所述的索引无法用于查找姓为smith并且在
某个特定日期出生的人。如果不指定名firstname，则mysql只能使用索引的
第一列。

如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。例如
有查询hwre last name smith and firstname like j% and dob =19
这个查询只能使用索引的前两列，因为这里like是一个范围条件 但是服务器
可以把其余列用于其他目的。如果范围查询列值的数量有限，那么可以通过使用
多个等于条件来代替范围条件。在本章的所以你案例学习部分，我们将演示一个详细的案例

到这里读者应该可以明白，前面提到的索引列的顺序是多么的重要：这些限制都和索引列
的顺序有关。在优化性能的时候，可能需要使用相同的列但顺序不同的索引引来满足不同
类型的查询需求。

也有些限制并不是btree本身导致的，而是mysql优化器和存储引擎使用索引的方式
导致的，这部分限制在未来的版本中可能就不再是限制了。




哈希索引
哈希索引 hashindex












共享锁shared lock 也叫 读锁 read lock

排他锁exclusive lock 也叫 写锁 write lock


读锁是共享的，或者说是互相不阻塞的。多个客户在同一时刻可以同时读取同一个资源，互不干扰。


写锁是排他的，也就是说一个写锁会阻塞其他的写锁和读锁。


1.2.2 锁粒度
一种提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分
数据，而不是所有的资源。更理想的方式是，只对会修改的数据片进行精确的锁定。
任何时候，在给定的资源上，锁定的数据量越少，则系统的并发程序越高，只要互相之间
不发生冲突即可。

问题是加锁也需要消耗资源。锁的各种操作，包括获得

row level lock 

mysql存储引擎都可以实现自己的锁策略和锁粒度。

表锁 table lock
表锁是mysql中最基本的锁策略，并且是开销最小的策略。表锁非常类似于前文描述
的邮箱加锁机制：它会锁定整张表。一个用户在对表进行写操作 插入 删除 更新等
前，需要先获得写锁，这回阻塞其他用户对该表的所有读写操作。只有没有写锁时，其他
读取的用户才能获得读锁，读锁之间是不相互阻塞的。

在特定的场景中，表锁也可能有良好的性能。例如 read local表锁支持某些类型的
并发写操作。另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到
读锁队列的前面（写锁可以插入到锁队列中读锁的前面，反之读锁则不能出插入到写锁的前面）

尽管存储引擎可以管理自己的锁，mysql本身还是会使用各种有效的锁来实现不同
的目的。例如，服务器会为诸如 alter table之类的语句使用表锁，而忽略存储引擎的
锁机制。

行级锁row lock
行级锁row lock可以最大程度地支持并发处理同事也带来了最大的锁开销。众所周知，在
innodb和xtardb,以及其他一些存储引擎中实现了行级锁。行级锁只在存储引擎层实现
，而mysql服务层没有实现。服务器层
完全不了解存储引擎中的锁实现。在本章的后续内容以及全书中，所以的存储引擎都以自己
的方式显现了锁机制。


1.3 事务
在理解事务的概念之前,接触数据库系统的其他高级特性还言之过早。事务就是一组原子性
的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用
改组查询的全部语句，那么就执行改组查询。如果其中有任何一条语句因为崩溃或其
他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要全部执行成功
，要么全部执行失败。

事务的ACID
原子性 atomicity
一致性 consistency
隔离性 isolation
持久性 durability

一个运行良好的事务处理系统，必须具备这些标准特性。


原子性atomicity
一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部
提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中一部分的
操作，这就是事务的原子性。

一致性 consistency
数据库总是从一个一致性的状态转换到另外一个一致性的状态。在前面的例子中，
一致性确保了，即使在执行第三四条语句之间时系统崩溃，支票账户中也不会损失
，因此事务最终没有提交，所以事务中锁座的修改也不会报错到数据库中。


隔离性 isolation
通常来说，一个事务锁座的修改在最终提交以前，对其他事务是不可见的。在签名
的例子中，当执行完第三条语句，第四条语句还未开始时，此时有另外一个账户汇总
程序开始运行，则其看到的支票账户的余额并没有被减去200元。后面我们讨论
隔离级别 isolation level的时候，会发现为什么我们要说通常来说是不可见的。


持久性 durability
一旦事务提交，则其所作的修改就会永久保存到数据库中。此时即使系统崩溃，修改
的数据也不会丢失。持久性是个有点模糊的概念，因为实际上持久性也分很多
不同的级别。有些持久性策略能够提供非常强的概念，因为实际上持久性也分很多不同
的级别。有些持久性策略能够提供非常强的安全保障，而有些则未必。而且
不可能有能做到100的持久性保证的策略 如果数据库本身就能做到真正的持久性
那么备份有能增加吃就能呢。

事务的 acid特性可以确保银行不会弄丢你的钱。而在应用逻辑中，要实现这一点非常难，
甚至可以说是不可能完成的任务。一个兼容 acid的数据库系统，需要做很多复杂但可能
yoghurt并没有察觉到的工作，才能确保ACID的实现。

就想锁粒度的升级会增加系统开销一样，这种事务处理过程中额外的安全性，也会需要
数据库系统做更多的额外工作。一个实现了acid的数据库，相比没有实现acitd的数据库
通常会需要更强的CPU处理能力更大的内存和更多的磁盘。正如本章不断
重复的，这也正是mysql的存储引擎架构可以发挥优势的地方。用户可以根据业务是否
需要事务处理，来选择合适的存储引擎。对于一些不需要事务的查询类应用，选择
一个非事务性的存储引擎，可以获得更高的性能。及时存储引擎不支持事务，也可以
通过locktables语句为应用提供一定程度的保护，这些选择用户都可以自助决定。

1.3.1 隔离级别
隔离性其实比想象的要复杂。在SQL标准中定义了四种隔离级别，每一种级别都规定了
一个事务中所做的修改，那些在事务内和事务间是课件的，那些是不可见的。较低级别
的隔离通常可以执行更高的并发，系统的开销也更低。

每种存储引擎实现的隔离级别不尽相同。如果熟悉其他的数据库产品，可能会发现
某些特性和你期望的会有些不一样。读者可以根据所选择的存储引擎，查阅相关手册。

下面简单地介绍一下四种隔离级别。

READ UNCOMMITTED 未提交读
在 ReadUnCommitTed 级别，事务中的修改，即使没有提交，对其他事务也都是可见的。
事务可以读取未提交的数据，这也被称为脏读 dirty read.这个级别会导致
很多问题，从性能上来说，read uncommitted不会比其他的级别好太多，但却缺乏
其他级别的好处，除非真的有非常必要的理由，在实际应用中一般很少使用。

READ COMMITTED 提交读
大多数数据库系统的默认隔离级别都是 ReadCommitTed 但mysql不是。read 
committed满足签名提到的隔离性的简单定义：一个事务开始时，只能看见已经
提交的事务所做的修改。换句话说，一个事务从开始直到提交之前，锁座的任何修改
对其他事务都是不可见的。这个界别有时候也叫做不可重复读 nonrepeatable
read ,因为两次执行同样的查询，可能会得到不一样的结果。

REPEATABLE READ 可重复读
RepeaTableRead 解决了脏读的问题。 该级别保证了在同一个事务中多次读取同样
记录的结果是一致的。但是理论上，可重复读隔离级别还是无法解决另外一个幻读
phantom read的问题。所谓幻读，指的是当某个事务在读取某个范围内的记录时，
另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取改范围的记录时
会产生幻行 phantom row  innodb xtra db 存储引擎通过多版本并发控制MVCC 解决幻读的问题。本章稍后会做进一步的跳楼

可重复读是mysql的默认事务隔离级别



SERIALIZABLE 可串行化
serializable 是最高的隔离级别。它通过强制事务串行执行，避免了前面说的幻读
的问题。简单来说，serializable会在读取的每一行数据上都加锁，所以可能导致
大量的超时和锁争用的问题。实际应用中也很少用到这个隔离级别，只有在非常需要
确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。

1.3.2 死锁
死锁是指两个或者多个事务在同一资源上互相占用，并请求锁定对方占用的资源，从而
导致恶性循环的现象。当多个事务试图以不同的顺序锁定资源时，就可能会产生死锁。

多个事务同时锁定同一个资源时，也会产生死锁。例如


为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，
比如innodb存储引擎，越能检测到死锁的循环依赖，并立即返回一个错误。这种解决
方式很有效，否则死锁会导致出现非常慢的查询。还有一种解决方式，就是当查询的
时间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太好。innodb目前处理
死锁的方法是，将持有最小行级排他锁的事务进行回滚（这是相对比较简单的死锁回滚算法）


锁的行为和顺序是和存储引擎相关的。以同样的顺序执行语句，有些存储引擎会产生死锁，
有些则不会。死锁的产生有双重原因：有些是因为真正的数据冲突，这些情况通常很难
避免，但有些则完全是由于存储引擎的实现方式导致的。

死锁发生以后，只有部分或者完全回滚其中一个事务，才能打破死锁。对于事务型的系统
这是无法避免的，所以应用程序在设计时必须考虑如何处理死锁。大多数情况下只
需要重新执行因死锁回滚的事务即可。


1.3.3事务日志
事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要
修改其内存拷贝，再把改修改行为记录到持久在硬盘上的事务日志中，而不用每次都将
修改的数据本身持久到磁盘。事务日志采用的是追加的方式，因此写日志的操作是磁盘
上一小块区域内的顺序IO ，而不像随机IO需要在磁盘的多个地方移动磁头，所以采用
事务日志的方式相对来说要快的多。事务日志持久以后，内存中被修改的数据在后台可以
慢慢地刷回到磁盘。目前大部分存储引擎都是这样实现的，我们通常称之为与些事日志
write ahead logging，修改数据需要些两次磁盘。

如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统
崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具体的恢复方式则视存储引擎
而定。


 show variables like 'AUTOCOMMIT'
13.4 mysql 中的事务
Mysql 提供了两种事务型的存储引擎 innodb ndb cluster 另外还有一些第三方
存储引擎也支持事务，比较知名的包括xtradb pbxt 后面将详细讨论他们各自的一些特点。


自动提交 autocommit
mysql默认采用自动提交 autocommit 模式。也就是说，如果不是显示地开始一个
事务，则每个查询都被当做一个事务执行提交操作。在当前连接中，可以通过设置
autocommit变量来启用或者禁用自动提交模式：

1或者on表示启用，o或者OFF表示禁用。当autocommit=0时，所有的查询都是在一个
事务中，直到显示地执行commit提交或者 rollback回滚，该事物结束，同时又开始了
另一个新事务。修改autocommit对非事务性的表，比如muyisam或者内存表，不会有
任何影响。对这类表来说，没有commit或者rollback的概念，也可以说是相当于一只
处于autocomiit启用的模式。

另外还有一些命令，在执行之前会强制执行commit提交当前的活动事务。典型的例子
在数据定义语言ddl中，如果是会导致大量数据改变的操作，比如alter table
就是如此。另外还有lock tables等其他语句也会导致同样的结果。如果有需要，请检查
对应版本的官方文档来确认所有可能导致自动提交的语句列表。如果有需要，请检查
对应版本的官方文档来确认所有可能导致自动提交的语句列表。

mysql可以通过执行set transactionisolationlevel命令来设置隔离级别。新的
隔离级别会在下一个事务开始 的时候生效。可以在配置文件中设置整个数据库的隔离级别，
也可以只改变当前会话的隔离级别；

set transaction isolation  lever 隔离级别。

Mysql能够识别所有的四个ansi隔离级别，innodb引擎也支持所有的隔离级别。



在事务中混合使用存储引擎

Mysql服务层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中，
使用多种存储引擎是不可靠的。

如果在事务中混合使用了事务型和非事务性的表 innodb 和myisam 在正常
提交的情况下不会有什么问题。

但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致
的状态，这种情况很难修复，事务的最终结果将无法确定。所以为每张表选择合适的
存储引擎非常重要。

在非事务性的表上执行事务相关操作的时候，mysql通常不会发出提醒，也不会报错。
有时候只有回滚的时候才会发出一个警告：某些非事务型的表上的变更不能被回滚。
但大多数情况下，对非事务性的表的操作都不会有提示。

隐式的显示锁定
innodb 采用的是两阶段锁定协议 two phase locking protocol。在事务执行过程中，随时
都可以执行锁定，锁只有在执行commit或者rollback的时候才会释放，并且所有的
锁是在同一时刻被释放。前面描述的锁定都是隐式锁定，innodb会根据隔离级别在需要的时候自动加锁。

另外，innodb也支持通过特定的语句进行显示锁定，这些语句不属于sql规范

select lock in share mode
select for update

mysql也支持 lock table 和unlock tables 这是在服务器层实现的饿，和
存储引擎无关。他们有自己的用户，但并不能替代事务处理。如果应用需要用到事务，还是
应该选择事务型存储引擎。

经常可以发现，应用已经将表从myisam转换到innodb，但还是显示地使用locak table语句。
这不但没有必要，还会严重影响性能，实际上innodb的行级锁工作得更好。

lock tables 和事务之间互相影响的话，情况会变得非常负责，在某些mysql版本
中甚至会产生无法预料的结果。因此本书建议，除了事务中禁用了 autocomit
可以使用locktables之外，其他任何时候都不要显示地执行locktables，不管使用什么存储情况。



1.4 多版本并发控制 MVCC 
 Multi-Version Concurrency Control 多版本并发控制

Mysql的大多数事务型存储引擎实现的都不是简单的行级锁。基于提升并发性能的考虑
，他们一般都同时实现了多版本并发控制mvcc。不仅是mysql 包括oracle
postgresql等其他数据库系统也都实现了mvcc，但各自的实现机制不尽相同，因为mvcc没有
一个统一的实现标准.

可以认为MVCC是行级锁的一个变种，但是他在很多情况下避免了加锁操作,incident开销
更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。

MVCC的实现，是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行
多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对
同一张表，同一时刻看到的数据可能是不一样的。如果之前没有这方面的概念，这句话
听起来就有点迷糊。熟悉了以后会发现，这句话其实还是很容易理解的。


前面说到不同存储引擎的MVCC实现是不同的，典型的有乐观 optimistic 并发控制
和悲观pessimistic 并发控制。下面我们通过innodb的简化版行为来说明MVCC是如何工作的

innodb的mvcc，是通过在每行记录后面报错两个隐藏的列来实现的。这两个列，一个
保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是实际
的时间值，而是系统版本号system version number 没开始一个新的事务，系统版本
号会自动递增。事务开始时刻的系统版本好会作为事务的版本好，用来和查询到的
每行记录的版本好进行比较。下面看一下在Repeatable read隔离级别下，mvcc具体
是如何操作的。

select 
innodb会根据以下两个条件检查每行记录：
a.innodb只查询版本遭遇当前事务版本的数据行也就是，行的系统版本好晓宇或者等于事务的系统版本号，
这样可以确保事务读取的行，要么是在事务开始前已经存在，要么是事务自身插入或者修改过的。

b.行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的
行，在事务开始之前未被删除。

只有符合上述两个条件的记录，才能返回作为查询结果。

insert
innodb 为新插入的每一行保存当前系统版本号作为行版本号。

delete 
innodb为删除的每一行报错当前系统版本号作为行删除标识

update
innodb为插入一行新记录，保存当前系统版本号作为行版本号,同时保存当前系统
版本号到原来的行作为行删除标识

保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作
很简单，性能很好，并且也能够保证只会读取到符合标准的行。不足之处是每行记录都
需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。

MVCC只在repeatable read 和read committed 两个隔离级别下工作。其他两个隔离
级别都和MVCC不兼容，因为 read uncommitted总是读取最新的数据行，而不是符合当前
事务版本的数据行。而serialiable 则会对所有读取的行都加锁。



Innodb为每行记录都实现了三个隐藏字段
6字节的事务ID DB_TRX_ID
7字节的回滚指针 DB_ROLL_PTR
隐藏的id















1.5 Mysql的存储引擎

本节知识概要地描述mysql的存储引擎，而不会设计太多细节。因为关于观察引擎的
讨论以及其相关特定将会贯穿权术，而且本书也不是存储引擎的完全指南，所以有必要阅
读相关存储引擎的官方文档。

在文件系统中，mysql将每个数据库也可以成为 schema 保存为数据目录下的一个
子目录。创建表时，mysql会在数据库子目录下创建一个和表同名的.frm文件保存表的定义。
例如创建一个名为mytable的表，mysql会在mytable。frm文件中报错该表的定义
。因为mysql使用文件系统的目录和文件来保存数据库和表的定义，大小写明和
具体平台密切相关。在windows大小写不敏感，而在类unix中则是
敏感的。不同的存储引擎保存数据和索引的方式是不同的，但表的定义则是mysql服务层
统一处理的。
show table status like 'phone';


可以使用 show table status 在mysql5以后的版本中，也可以查询
information schema显示表的相关信息。例如，对于mysql数据库中的user表

name 表名

engine 表的存储引擎类型。在旧版本中，该列的名字叫type ，而不是engine
 
row_format
行的格式。对于myisam 表，可选的值为dynamic fixed  compressed

dynamic的行长度是可变的，一般包含可变长度的字段，如varchar或blob.fixed
的行长度则是固定的，只包含固定长度的列，如char 和inieger .compressed的行
则只在压缩表中存在，

rows 表中的行数 innodb改制是估计值
表中的行数。对于myisam和其他的一些存储引擎，改制是精确的，但对于innodb改制是估计值。

avg_row_length
平均每行包含的字节数

data length
表数据的大小以字节为单位

max data length
表数据的最大容量，改制和存储引擎有关。


index_length
索引的大小 以字节为单位

data_free
对于myisam表，表示已分配但目前没有使用的空间。这部分空间包括了之前删除的行，
以及后续可以被insertliyongdao的空间。

auto_increment下一个自增的值
下一个auto increment 的值

create_time
创建时间

updatetime
修改

checktime
使用check table命令或者myisamchk工具最后一次检测表的时间


 check table  phone 
 不加引号，检测表是否有错误
 
 ANALYZE TABLE  phone 分析表
 加一个只读锁只能读取表中的记录，不能更新和插入记录
 
 
 OPTIMIZE TABLE   phone  优化表
  只读锁, 可以消除删除和更新造成的磁盘碎片，从而减少空间的浪费
   TEXT或者BLOB这样的数据类型，那么更新、删除等操作就会造成磁盘空间的浪费
   
   
collation表的默认字符集和字符列排序规则
   
 checksum
 如果启用，保存的是整个表的实时校验和。
 
 create_options
 创建表时指定的其他选项。
 
 commet
 该列包含了一些其他的额外信息。对于myisam表，报错的是表在创建时带的注释。
 对于innodb表，则保存的是innodb表空间的剩余空间信息。如果是一个视图，则
 该列包含view的文本字样。
 
 1.5.1 innodb存储引擎
 innodb是mysql的默认事务型引擎，也是最重要、使用最广泛的存储引擎。他被设计
 用来处理大量的短期short lived事务，短期事务大部分情况是正常提交的，很少会
 被回滚。innodb的性能和自动崩溃恢复特性，使得它在非事务性存储的需求中也很流行。
 触发有非常特别的原因需要使用其他的存储引擎，否则应该优先考虑innodb引擎。
 如果要学习存储引擎，innodb也是一个非常好的指的花最多的时间去深入学习的对象，
 收益肯定比将时间平均花在每个存储引擎的学习上要高得多。
 
 Multi-Version Concurrency Control 多版本并发控制
 
 innodb的历史
 innodb有这复杂的发布历史，了解一下这段历史对于理解innodb很有帮助。2008年，
 发布了所谓的innodb plugin，适用于mysql5.1版本，但这是oracle创建的下一代
 innodb引擎，其拥有者是innodb而不是msql。这基于很多原因，这些原因如果要
 一一道来，恐怕得喝掉好几桶啤酒。msql默认还是选择了集成就得innodb引擎。当然
 用户可以自行选择使用心得性能更好拓展性更加的innodbpulgin来覆盖就得版本。
 直到最后，在oracle收购了sun公司后发布的mysql5.5才彻底使用innodb plugin
 替代了旧版本的innodb  是的，这也意味着innodb plugin已经是原生编译了，而不是
 编译成一个插件，但是名字已经约定俗成很难更改。
 
 这个现代的innodb版本，也就是mysql5.1中所谓的innodb plugin，支持一些新特性，
诸如利用排序创建索引 building index by sorting 删除或者增加索引时不需要复制全表
数据、新的支持压缩的存储格式、新的大型列值如blob的存储方式，以及文件格式管理
等。很多用户在mysql5.1中没有使用innodbplugin或许是因为他们没有注意到
有这个区别。所以如果你使用的是mysql5.1 一定要使用innodbplugin真的比旧
版本的innodb要好很好。
 
innodb是一个很重要的存储引擎，很多个人和公司都对其贡献代码，而不仅仅是
oracle公司的开发团队。一些重要的贡献者包括 谷歌，facebook等
他们的一些改进被直接一直到官方版本，也有一些由innodb团队重新实现。
在过去的几年间，innodb的改进速度大大加快，主要的改进集中在可测量性可拓展性。
可配置化、性能、各种新特性和对windows的支持等方面。mysql5.6实验室预览版里
和里程碑版包含一系列重要的innodb新特性。


为改善innodb的性能，oracle投入了大量的资源，并做了很多桌游成效的工作
。我们注意到在超过四核CPU的系统中
innodb表现不佳，而现在已经可以很好拓展至24核的系统，甚至在某些常军，
32核或者更多的系统也表现良好。很多改进将在即将发布的mysql5.6引入。
当然也还有机会做进一步的改善
 
 
innodb概览
innodb的数据存储在表空间tablespace中，表空间由innodb管理的一个黑盒子，
有一系列的数据文件组成。在4.1以后的版本，innodb可以将每个表的数据
和索引存放在单独的文件中。innodb也可以使用裸设备作为表空间的存储介质，但现代的
文件系统是的裸设备不再是必要的选择。

innodb采用MVCC来支持高并发，并且实现了四个标准的隔离级别。起默认级别是
RepeaTable read可重复读，并且通过间隙锁next key locking防止幻读的出现。
间隙锁是的innodb不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止
幻影行的插入。

innodb表是基于聚簇索引建立的，我们会在后面的张洁详细讨论聚簇索引。innodb的
索引结果和mysql的其他存储引擎有很大的不同，聚簇索引对主键查询有很高的性能。
不过他的二级索引 secondary index非主键索引 中必须包含主键列，所以如果主键
列很大的话，其他的所有索引都会很大。因此，若表上的索引较多的话，主键应当尽可能的小。
innodb的存储格式是平台独立的，也就是说可以将数据和索引文件从intel平台
复制到powerpc或者 sunsparc平台

Innodb内部做了很多优化，包括从磁盘读取数据时采用的可预测性的预读，能够自动在
内存中创建hash索引以加速读操作的自适应哈希索引 adaptive hash index 以及能够
加速插入操作的插入缓冲区 insert buffer 等。本书后面将更详细地址讨论这些内容。

innodb的行为是非常复杂的，不容易理解。如果使用了innodb引擎，笔者强烈建议阅读官方
手册中的 innodb事务模型和锁 一节。如果应用程序基于innodb构建，则事先
了解一下innodb的mvcc架构带来的一些为秒和细节之处是非常有必要的。存储引擎
要为所有用户甚至包括修改数据的用户维持一致性的视图，是非常复杂的工作。

作为事务型的存储引擎，innodb通过一些机制和工具支持真正的热备份，oracle提供
的mysql enterprise backup percona  提供的开源的xtrabackup都可以做到这一点
mysql的其他存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入，
而在读写混合场景中，停止写入可能也意味着停止读取。
 
 
 1.5.2 Mysiam存储引擎
在mysql5.1及之前的版本，myisam是默认的存储引擎。myisam提供了大量的特性
，包括全文索引，压缩、空间函数GIS 等，但myisag不支持事务和行级锁，而
且有一个毫无疑问的缺陷就是崩溃后无法安全恢复。正是由于myisam引擎的缘故，即使
mysql支持事务已经很长时间了，在很多人的概念中mysql还是非事务型的数据库。
尽管myisam引擎不支持事务、不支持崩溃后的安全恢复，但它绝不是一无是处
的。对于只读的数据，或者表比较小，可以忍受修复操作，则依然可以继续使用
myisam

存储
myisam会将表存储在两个文件中：数据文件和索引文件，分别以.myd myi为拓展名
。myiasm表可以包含动态或者静态行。mysql会根据表的定义来
觉得采用何种行格式。myisam表可以存储的行记录数，一般受限于可用的磁盘空间，
或者操作系统中单个文件的最大尺寸。

在5.0中，myisam表如果是变长行，则默认配置只能处理256TB的数据，因为
指向数据记录的指针长度是6个字节。而在更早的版本中，指针长度默认是4字节，
所以只能处理4Gb的数据。而所有的mysql版本都支持8字节的指针。要改变
myisam表指针的长度，可以通过修改表的maxorws和avgrowlength
选项的值来实现，两者相乘就是表可能达到的最大大小。修改这两个参数会导致
重建整个表和表的所有索引，这可能需要更长的时间才能完成。


MyISAM特性
作为mysql最早的存储引擎之一，myisam有一些已经开发出来很多年的特性，可以满足用户的实际需求。

加锁与并发
myisam对整张表加锁，而不是针对行。读取时会需要独到的所有表加共享锁，
写入时则对表加排他锁。但是在表有读取查询的同事，也可以往表中插入新的记录
这被称为并发插入，concurrent insert

修复
  对于myisam表，mysql可以手工或者自动执行检测和修复操作，但这里说的修复和
  事务修复以及崩溃恢复是不同的概念。执行表的修复可能导致一些数据丢失，
  而且修复操作是非常慢的。可以通过 check table mytable 检查表的错误，如果有
  错误可以通过执行repair table mytable进行修复。另外，如果mysql服务器已经
  关闭，也可以通过 myisamchk命令行工具进行检查和修复操作。
  
修复
  对于myisam表，mysql可以手工或者自动执行检查和修复操作，但这里说的修复
  和事务恢复以及崩溃修复是不同的概念。执行表的修复可能导致一些数据丢失，
  而且修复操作是非常慢的。可以通过 check table mytable检查表的错误，如果有
  错误可以通过执行 repair table mytable 进行修复。另外，如果mysql服务器已经
  关闭，也可以通过 命令行工具进行检查和修复操作。
  
索引特性
   对于myisam表，即使是blob 和text等长字段，也可以基于其前500个字符创建
索引。myisam也支持全文索引，这是一种基于分词创建的索引，可以支持复杂的
查询。关于索引的更多信息请参考第五章。

延迟更新索引建 delayed key write
创建myisam表的时候，如果指定了 delay可以write选项，在每次修改执行完成时
，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的减缓冲区 n memory key buffer
只有在清理建缓冲区或者关闭表的时候才会将对应的索引块写入到磁盘。
这种方式可以及大地提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，m需要
执行修复操作。延迟更新索引建的特性，可以在全局设置，也可以为单个表设置。

myisam 压缩表
如果表在创建并导入数据以后，不会在进行修改操作，那么这样的表或许适合采用
myaism压缩表

可以使用myisampack 对myisam表进行压缩也叫做大博鳌 pack.压缩表是不能进行修改的
。压缩表可以及大地煎炒磁盘占用空间。
因此也可以减少磁盘IO 从而提升查询性能。压缩表也支持索引，但索引也是只读的。


以现在的硬件能力，对大多数应用常军，读取压缩包数据时假牙带来的开销影响并不大，
而减少IO带来的好处则是要大的多。压缩表时记录是独立压缩的，所以读取单行的时候
不需要去解压整个表

Myisam性能
myaism引擎设计简单，数据以紧密格式存储，所以在某些常军下的性能很好，
myisam有一些服务器级别的性能拓展显示，比如对索引建缓冲区 keycache的
mutex锁，mariadb基于段segment 的索引建缓冲区机制来避免该问题。但myisam
最典型的性能高问题还是表锁的问题，如果你发现所有的查询都长期处于locked状态
那么毫无疑问表锁就是罪魁祸首。




2.2 
测试指标

吞吐量:单位时间内的事务处理数

响应时间或延迟:任务所需整体时间
 
并发性

 
 
 
 
 
3.3 剖析mysq查询
 
慢查询可以设置 long_query_time为0来捕获所有的查询，
影响性能很小。

慢查询剖析报告工具 pt_query-digest 追踪工作负载到数据库

 
3.3.2 剖析单条查询
1.show profiles;
set profiling=1;
show profile;
show profiles;
show profile for query 1;
 

2.show status;show global status;


3.慢SQL:设置 long_query_time为0来捕获所有的查询

4.performance schema


5.explain|desc 



 



第四章 schema 与数据类型有优化




4.1 优化数据类型原则

1.更小的通常更好
2.简单就好
3.避免null

datetime和timesamp   timesamp存储更小，会根据时区变化。timesamp范围小。

mysql支持别名 integer bool numeric都只是别名。

show create table 


4.1.1整数类型
两种类型的数字:
整数 whole number和 实数 real number

unsigned 无符号;使正数上限提高一倍。
tinyint、smallint、mediumint、int、bigint
-2(n-1)到2(n-1)-1

存储和计算来说int(1)和int(20)相同


4.1.2 实数类型
带小数

float double
decimal(小数的) 存储精确的小数。

CPU不支持decimal直接计算，支持原生浮点计算，所以浮点计算更快。



4.1.3 字符串类型

varchar 和char

varchar用于存储可变长字符串
innodb 把过长的varchar存储为blob

varchar(5)varchar(20)存储hello空间开销一样。更长的列会消耗更多的内存。mysql
会分配固定大小的内存来保存内部值。

char
定长的  存md5最合适

Blob(二进制存储)和text(字符存储)存储很大的数据。 

blob(二进制,无字符集和排序):tinyblob、smallblob、blob、mediumblob、longBlob
text(字符存储，有字符集和排序):tinytext、smalltext、text、mediumtext、longtext

mysql会把blob和text当作一个独立对象处理。


使用枚举类型enum代替字符串类型。



4.1.4 日期和时间类型
datetime和timestamp


datetime 1001年到9999年精度秒
封装格式YYYYMMDDHHMMSS的整数，与时区无关8字节


timestamp 1970年1月1日开始的秒数。和unix时间戳相同，四个字节和时区有关
只能从1970-2038年。时区依赖服务器操作系统和客户端连接时区。


4.1.5
bit位存01不建议用
set



4.2 Mysql schema设计陷阱

1.太多的列


2.太多的关联

3.全能的枚举

4.变相的枚举:枚举enm运行在列中存储一组定义值的单个值。集合set允许在列中存储一组定义






4.3 范式和反范式




第五章 创建高性能的索引



5.1索引基础


5.1.1 索引的类型


B-Tree索引
当人们谈论索引的时候，如果没有特别指明类型，那多半说的是B-tree索引，它使用
B-Tree数据结果来存储数据。大多数mysql引擎都支持这些索引。

实际上很多存储索引使用的是B+tree，即每一个叶子节点都包含指向下一个叶子节点的指针，从而
方便叶子节点的范围遍历。

不过，底层的存储引擎也可能使用不同的存储结构，例如，NDB集群存储引擎内部实际
上使用了T-tree结果存储这种索引，及时其名字是btrr;innodb则使用的b+tree
各种数据结构和算法的变种不在本书的讨论范围之内。

存储引擎以不同的方式使用B-tree索引，性能也个有不同，个有优劣。

可以使用b-tree索引的查询类型
1.全键值
2.键值范围
3.前缀查找



哈希索引 hash index
只有精确匹配索引所有的列的查询才有效。


5.2 如何评价一个索引是否适合某个查询  三星系统

三星系统(three-star system)：
索引将相关的记录放到一起则获得一星。
索引中的数据顺序和查找中的排列顺序一致则获得二星。
索引中的列包含了查询中需要的全部列则获得三星。






5.3 高性能的索引策略

5.3.1 独立的列

独立的列指的是索引列不能是表达式的一部分，也不能是函数的参数

where aa+1=5;
where   TO_DAYS(create_time)-TO_DAYS(update_time)<=10;

5.3.2 前缀索引和索引选择性

反转字符串进行后缀索引



5.3.3 多列索引

常见的错误就是，为每个列创建独立索引，或者按照错误的顺序创建多列索引。

在多个列上建立独立的单列索引大部分情况下并不能提高mysql的查询性能，mysql
5.0和更新版本上引入一种叫做索引合并 index merge 的策略，一定程度上可以使用
表上的多个单列索引来定位指定的行。更早版本的mysql只能使用其中某一个单列索引，
然而这种情况下没有那一个独立的单列索引是非常有效的。例如，表filmactor在
字段

索引合并策略有时候是一种优化的结果，但实际上更多时候说明了表上的索引建的很糟糕：

5.3.4 选择合适的索引列顺序

我们遇到的最容易引起困惑的问题就是索引列的顺序。正确的顺序依赖于使用该索引的
查询，并且同时需要考虑如何更好地满足排序和分组的需要。

在一个多列B tree索引中,索引列的顺序意味着索引首先按照最左列进行排序，其次是
第二列，等等。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的
order by group by  distinct等子句的查询需求。


所以多列索引的列顺序至关重要。在lahdenmaki和leach的三星索引系统中，列
顺序也决定了一个索引是否能够成为一个真正的三星索引，

将选择性最高的列放到索引最前列。



5.3.5 聚簇索引
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体的细节依赖于其
实现方式，但innodb的聚簇索引实际上在同一个结构中报错了Btree和数据行.

当表有聚簇索引时，他的数据行实际上存放在索引的叶子也 leaf page 中。属于 聚簇
表示数据和和相邻的键值紧凑地存储在一起。因为无法同时把数据行存放在两个不同
的地方，所以一个表只能有一个聚簇索引。（不过，覆盖索引可以模拟多个聚簇索引的情况）

因为是存储引擎负责实现索引，一次不是所有的存储引擎都支持聚簇索引。本节我们主要
关注innodb，但是这里讨论的原理对任何支持聚簇索引的存储引擎都是使用的。


图5-3展示了聚簇索引中的记录是如何存放的。注意到，叶子页包含了行的全部数据，
但是节点页只包含了索引列。

一些数据库服务器运行选择那个索引作为聚簇索引，但直到本书写作之际，还没有任何
一个mysql内建的存储引擎支持这一点。innodb将通过主键聚集数据，也就是说图
5-3中的被索引的列就是主键列。


如果没有定义主键,innodb会选择一个唯一的非空索引替代。如果没有这样的索引，
innodb会隐式定义一个主键来座位聚簇索引。innodb只具体在同一个页面中的记录。
包含相邻键值的页面可能会相聚深远。

聚簇主键可能对性能有帮助，但也可能导致严重的性能问题。所有需要仔细地考虑聚簇
索引，尤其是将表的存储引擎从innodb改成其他引擎的时候，反过来也一样。
具体的数据有一些重要的有有点：


1.可以吧相关的数据保存在以前。例如实现电子邮箱时，可以根据用户id来具体数据，
这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用
聚簇素银，则每逢邮件都可能导致一次磁盘IO



2.数据访问更快。聚簇索引将索引和数据保存在同一个B-tree中，因此从聚簇索引中
获取数据通常比在非聚簇索引中查询要快。

3.使用覆盖索引扫描的查询可以直接使用页节点中的主键值。


如果在设计表和查询时能充分利用上面的有点，那就能极大地提升性能。同时聚簇索引
也有一些缺点


1.聚簇数据最大限度地提高了IO密集型应用的性能，但如果数据全部都放在内存中，
则访问的顺序就没那么重要了，聚簇索引也就没有什么优势了。

2.插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到innodb表中速度
最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用
optimize table 命令重新组织一下表。

3.更新聚簇索引列的代价很高，因为会强制innodb将每个被更新的行移动到新的位置

4.基于聚簇索引的表在插入新航，或者主键被更新导致需要移动行的时候，可能面临
页分裂 page split的问题。当行的主键值要求必须将这一行插入到某个已满的
页中时，存储引擎会将该页分裂成两个页面来容乃改行，这就是一次页分裂操作。
也分裂会导致表占用更多的磁盘空间。

5.聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。

6.二级索引(非聚簇索引)可能比想象的更大，因为在二级索引的叶子节点包含了引用行的主键列。

7.二级索引访问需要两次索引查找，而不是一次。

8.二级索引访问需要两次索引查找，而不是一次。



聚簇索引(主键>第一个唯一>自己建立一列隐藏) 

二级索引（辅助索引）:唯一索引、普通索引、前缀索引、全文索引



索引实现:
B-tree
hash


最后一点可能让人有些疑惑，为什么二级索引需要两次索引查找？答案在于二级索引中
保存的行指针的实质。要记住，二级索引叶子结点保存的不是指向行的物理位置的指针，
而是行的主键值。

这意味这通过二级索引查找行，存储引擎需要找到二级索引的叶子节点获得对应的主键值，
然后根据这个值去聚簇索引中查找到对应的行。这里做了重复的工作：两次B-tree
查找而不是一次。对于innodb，资质是哈一索引能够减少这样的重复工作。


MyISAM数据文件，按照数据插入顺序存储在磁盘上

MyISAM索引文件是B-tree每个tree叶子节点保存数据的位置


InnoDB支持聚簇索引
数据和主键列一起存在B-tree上。
每个叶子节点包含(主键列、事务ID、回滚指针、非主键列S)

InnoDB二级索引(辅助索引):叶子节点中存储的不是行指针而是主键值。




在innodb表中按主键顺序插入行
如果正在使用innodb表并没有什么数据需要聚集，那么可以定义一个代理键surrogate key 作为主键。
这种主键的数据应该和应用无关，最简单的方法是使用autoincrement自增列。这样可以保证
数据行是按顺序写入，对于根据主键做关联操作的性能也会更好。

最好避免随机的聚簇索引，特别是对于IO密集型的应用
性能角度用UUID作为聚簇索引会很糟糕：它使得聚簇索引的插入变得完全随机，这是最坏的情况，
使得数据没有任何聚集特性。

UUID作为主键时插入
无法简单地总是把新航插入到索引的最后，而是需要为新的行寻找合适的位置。通常是已有数据的中间位置
并且分配空间。会增加很多额外的工作，并导致数据分布不够优化。

缺点：
1.写入的目标也可能已经刷到磁盘上并从缓存中移除，或者是还没有被加载到缓存中，
innodb在插入之前不得不先找到并从磁盘读取目标也到内存中。这将导致大量的随机IO

2.因为写入是乱序的，innodb不得不频繁地做页分裂操作，以便为细腻的行分配空间。
也分裂会导致移动大量数据，一次插入最少需要修改三个页而不是一个页。

3.由于频繁的页分裂，页会变得稀疏并被不规则地填充，所以最终数据会碎片。








顺序的主键什么时候会造成最坏的结果

对于高并发工作负载，在innodb中按主键顺序插入可能会造成明显的争用。主键
的上界会成为热点。因为所以的插入都发生在这里，所以并发插入可能导致间隙锁
竞争。另一个热点可能是auto_increment锁机制；如果遇到这个问题，则可能
需要考虑重新设计表或者应用，或者更改innodb_autoinc_lock_mode配置。如果
你的服务器版本还不支持 innodb_autoinc_lock_mode 参数，可以升级到最新版本
的innodb，可能对这种场景会工作得更好。



auto_increment  自增列不要改主键的值 
有1、2、3，把1改成4；再插入时就出问题

默认是1:

insert 语句分三种类型：
1.simple insert : insert into t1(id, name) values(1,"shenjian");
2.bulk insert 批量  : insert ... select
3.mixed insert 混合(有的指定ID有的自动生成) :insert into t1(id, name) values (111,"111"),(NULL, "abc"); 



 show variables like 'innodb_autoinc_lock_mode'
 
 innodb_autoinc_lock_mode有三个值：
 
     0, traditional  insert语句在开始时都会获得一个表锁autoinc_lock.该锁会一直持有到insert语句执行结束才会被释放。保证了同一条语句插入的行记录的自增ID是连续的。
     1, consecutive 默认 insert语句在开始时会获得一个表锁autoinc_lock, simple insert在获取到需要增加的ID的量后，autoinc_lock就会被释放,不必等到语句执行结束。
     2, interleaved 主从复制的同一张表下的同一行id有可能不一样。


5.3.6 覆盖索引
通常大家都会根据查询的where条件来创建合适的索引，不过这只是索引优化的一个方面。
设计优秀的索引应该考虑到整个查询，二部丹丹是where条件部分。索引确实是一种
查找数据的高效方法，但是mysql也可以使用索引来直接获取列的数据，这样就不需要
读取数据行。如果索引的叶子节点中已经包含要查询的数据，那么还有什么必要
再回表查询呢？如果一个索引包含所有需要查询的字段的值，我们就称之为覆盖索引。

覆盖索引是非常有用的工具，能够极大地提高性能。考虑一下如果查询只需要扫描索引
而无需回表，会带来很多好处：


1.索引条目通常远小于数据行大小，所以如果只需要读取索引，那mysql就会极大地
减少数据访问量。这对缓存的负载非常重要，因为这种情况下响应时间大部分花费
在数据拷贝上。覆盖索引对于iO密集型的应用也有帮助，因为索引比数据更小，
更容易全部放入内存中

2.因为索引是按照列值顺序存储的，所以对于IO密集型的
范围查询会比随机从磁盘读取每一行数据的IO要少的多。对于某些存储引擎，例如
myisam和percona xtradb，甚至可以通过optimize命令是的索引完全顺序排列
，这让简单的范围查询能使用完全顺序的索引访问。

3.一些存储引擎如myisam在内存中只缓存索引，数据则依赖于操作系统来缓存，因此
要访问数据需要一次系统调用。这可能会导致严重的性能呢问题，尤其是那些系统
调用占用了数据访问中的最大开销的场景。

4.由于innodb的聚簇索引，覆盖索引对innodb表特别有用。innodb的耳机索引在
叶子节点中报错了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键
索引的二次查询。

 

5.3.7 使用索引扫描来做排序
mysql有两种方式可以生成有序的结果：通过排序操作；或者按索引顺序扫描；如果
explain出来的type列的值为index，则说明没有失去了使用了索引扫描来做排序




























